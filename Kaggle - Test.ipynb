{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('train.csv', na_values=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>target</th>\n",
       "      <th>ps_ind_01</th>\n",
       "      <th>ps_ind_02_cat</th>\n",
       "      <th>ps_ind_03</th>\n",
       "      <th>ps_ind_04_cat</th>\n",
       "      <th>ps_ind_05_cat</th>\n",
       "      <th>ps_ind_06_bin</th>\n",
       "      <th>ps_ind_07_bin</th>\n",
       "      <th>ps_ind_08_bin</th>\n",
       "      <th>...</th>\n",
       "      <th>ps_calc_11</th>\n",
       "      <th>ps_calc_12</th>\n",
       "      <th>ps_calc_13</th>\n",
       "      <th>ps_calc_14</th>\n",
       "      <th>ps_calc_15_bin</th>\n",
       "      <th>ps_calc_16_bin</th>\n",
       "      <th>ps_calc_17_bin</th>\n",
       "      <th>ps_calc_18_bin</th>\n",
       "      <th>ps_calc_19_bin</th>\n",
       "      <th>ps_calc_20_bin</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>16</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>17</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 59 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   id  target  ps_ind_01  ps_ind_02_cat  ps_ind_03  ps_ind_04_cat  \\\n",
       "0   7       0          2              2          5              1   \n",
       "1   9       0          1              1          7              0   \n",
       "2  13       0          5              4          9              1   \n",
       "3  16       0          0              1          2              0   \n",
       "4  17       0          0              2          0              1   \n",
       "\n",
       "   ps_ind_05_cat  ps_ind_06_bin  ps_ind_07_bin  ps_ind_08_bin  ...  \\\n",
       "0              0              0              1              0  ...   \n",
       "1              0              0              0              1  ...   \n",
       "2              0              0              0              1  ...   \n",
       "3              0              1              0              0  ...   \n",
       "4              0              1              0              0  ...   \n",
       "\n",
       "   ps_calc_11  ps_calc_12  ps_calc_13  ps_calc_14  ps_calc_15_bin  \\\n",
       "0           9           1           5           8               0   \n",
       "1           3           1           1           9               0   \n",
       "2           4           2           7           7               0   \n",
       "3           2           2           4           9               0   \n",
       "4           3           1           1           3               0   \n",
       "\n",
       "   ps_calc_16_bin  ps_calc_17_bin  ps_calc_18_bin  ps_calc_19_bin  \\\n",
       "0               1               1               0               0   \n",
       "1               1               1               0               1   \n",
       "2               1               1               0               1   \n",
       "3               0               0               0               0   \n",
       "4               0               0               1               1   \n",
       "\n",
       "   ps_calc_20_bin  \n",
       "0               1  \n",
       "1               0  \n",
       "2               0  \n",
       "3               0  \n",
       "4               0  \n",
       "\n",
       "[5 rows x 59 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(595212, 59)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 595212 entries, 0 to 595211\n",
      "Data columns (total 59 columns):\n",
      "id                595212 non-null int64\n",
      "target            595212 non-null int64\n",
      "ps_ind_01         595212 non-null int64\n",
      "ps_ind_02_cat     595212 non-null int64\n",
      "ps_ind_03         595212 non-null int64\n",
      "ps_ind_04_cat     595212 non-null int64\n",
      "ps_ind_05_cat     595212 non-null int64\n",
      "ps_ind_06_bin     595212 non-null int64\n",
      "ps_ind_07_bin     595212 non-null int64\n",
      "ps_ind_08_bin     595212 non-null int64\n",
      "ps_ind_09_bin     595212 non-null int64\n",
      "ps_ind_10_bin     595212 non-null int64\n",
      "ps_ind_11_bin     595212 non-null int64\n",
      "ps_ind_12_bin     595212 non-null int64\n",
      "ps_ind_13_bin     595212 non-null int64\n",
      "ps_ind_14         595212 non-null int64\n",
      "ps_ind_15         595212 non-null int64\n",
      "ps_ind_16_bin     595212 non-null int64\n",
      "ps_ind_17_bin     595212 non-null int64\n",
      "ps_ind_18_bin     595212 non-null int64\n",
      "ps_reg_01         595212 non-null float64\n",
      "ps_reg_02         595212 non-null float64\n",
      "ps_reg_03         595212 non-null float64\n",
      "ps_car_01_cat     595212 non-null int64\n",
      "ps_car_02_cat     595212 non-null int64\n",
      "ps_car_03_cat     595212 non-null int64\n",
      "ps_car_04_cat     595212 non-null int64\n",
      "ps_car_05_cat     595212 non-null int64\n",
      "ps_car_06_cat     595212 non-null int64\n",
      "ps_car_07_cat     595212 non-null int64\n",
      "ps_car_08_cat     595212 non-null int64\n",
      "ps_car_09_cat     595212 non-null int64\n",
      "ps_car_10_cat     595212 non-null int64\n",
      "ps_car_11_cat     595212 non-null int64\n",
      "ps_car_11         595212 non-null int64\n",
      "ps_car_12         595212 non-null float64\n",
      "ps_car_13         595212 non-null float64\n",
      "ps_car_14         595212 non-null float64\n",
      "ps_car_15         595212 non-null float64\n",
      "ps_calc_01        595212 non-null float64\n",
      "ps_calc_02        595212 non-null float64\n",
      "ps_calc_03        595212 non-null float64\n",
      "ps_calc_04        595212 non-null int64\n",
      "ps_calc_05        595212 non-null int64\n",
      "ps_calc_06        595212 non-null int64\n",
      "ps_calc_07        595212 non-null int64\n",
      "ps_calc_08        595212 non-null int64\n",
      "ps_calc_09        595212 non-null int64\n",
      "ps_calc_10        595212 non-null int64\n",
      "ps_calc_11        595212 non-null int64\n",
      "ps_calc_12        595212 non-null int64\n",
      "ps_calc_13        595212 non-null int64\n",
      "ps_calc_14        595212 non-null int64\n",
      "ps_calc_15_bin    595212 non-null int64\n",
      "ps_calc_16_bin    595212 non-null int64\n",
      "ps_calc_17_bin    595212 non-null int64\n",
      "ps_calc_18_bin    595212 non-null int64\n",
      "ps_calc_19_bin    595212 non-null int64\n",
      "ps_calc_20_bin    595212 non-null int64\n",
      "dtypes: float64(10), int64(49)\n",
      "memory usage: 267.9 MB\n"
     ]
    }
   ],
   "source": [
    "train.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = pd.read_csv('test.csv', na_values=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>ps_ind_01</th>\n",
       "      <th>ps_ind_02_cat</th>\n",
       "      <th>ps_ind_03</th>\n",
       "      <th>ps_ind_04_cat</th>\n",
       "      <th>ps_ind_05_cat</th>\n",
       "      <th>ps_ind_06_bin</th>\n",
       "      <th>ps_ind_07_bin</th>\n",
       "      <th>ps_ind_08_bin</th>\n",
       "      <th>ps_ind_09_bin</th>\n",
       "      <th>...</th>\n",
       "      <th>ps_calc_11</th>\n",
       "      <th>ps_calc_12</th>\n",
       "      <th>ps_calc_13</th>\n",
       "      <th>ps_calc_14</th>\n",
       "      <th>ps_calc_15_bin</th>\n",
       "      <th>ps_calc_16_bin</th>\n",
       "      <th>ps_calc_17_bin</th>\n",
       "      <th>ps_calc_18_bin</th>\n",
       "      <th>ps_calc_19_bin</th>\n",
       "      <th>ps_calc_20_bin</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 58 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   id  ps_ind_01  ps_ind_02_cat  ps_ind_03  ps_ind_04_cat  ps_ind_05_cat  \\\n",
       "0   0          0              1          8              1              0   \n",
       "1   1          4              2          5              1              0   \n",
       "2   2          5              1          3              0              0   \n",
       "3   3          0              1          6              0              0   \n",
       "4   4          5              1          7              0              0   \n",
       "\n",
       "   ps_ind_06_bin  ps_ind_07_bin  ps_ind_08_bin  ps_ind_09_bin  ...  \\\n",
       "0              0              1              0              0  ...   \n",
       "1              0              0              0              1  ...   \n",
       "2              0              0              0              1  ...   \n",
       "3              1              0              0              0  ...   \n",
       "4              0              0              0              1  ...   \n",
       "\n",
       "   ps_calc_11  ps_calc_12  ps_calc_13  ps_calc_14  ps_calc_15_bin  \\\n",
       "0           1           1           1          12               0   \n",
       "1           2           0           3          10               0   \n",
       "2           4           0           2           4               0   \n",
       "3           5           1           0           5               1   \n",
       "4           4           0           0           4               0   \n",
       "\n",
       "   ps_calc_16_bin  ps_calc_17_bin  ps_calc_18_bin  ps_calc_19_bin  \\\n",
       "0               1               1               0               0   \n",
       "1               0               1               1               0   \n",
       "2               0               0               0               0   \n",
       "3               0               1               0               0   \n",
       "4               1               1               0               0   \n",
       "\n",
       "   ps_calc_20_bin  \n",
       "0               1  \n",
       "1               1  \n",
       "2               0  \n",
       "3               0  \n",
       "4               1  \n",
       "\n",
       "[5 rows x 58 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(892816, 58)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 892816 entries, 0 to 892815\n",
      "Data columns (total 58 columns):\n",
      "id                892816 non-null int64\n",
      "ps_ind_01         892816 non-null int64\n",
      "ps_ind_02_cat     892816 non-null int64\n",
      "ps_ind_03         892816 non-null int64\n",
      "ps_ind_04_cat     892816 non-null int64\n",
      "ps_ind_05_cat     892816 non-null int64\n",
      "ps_ind_06_bin     892816 non-null int64\n",
      "ps_ind_07_bin     892816 non-null int64\n",
      "ps_ind_08_bin     892816 non-null int64\n",
      "ps_ind_09_bin     892816 non-null int64\n",
      "ps_ind_10_bin     892816 non-null int64\n",
      "ps_ind_11_bin     892816 non-null int64\n",
      "ps_ind_12_bin     892816 non-null int64\n",
      "ps_ind_13_bin     892816 non-null int64\n",
      "ps_ind_14         892816 non-null int64\n",
      "ps_ind_15         892816 non-null int64\n",
      "ps_ind_16_bin     892816 non-null int64\n",
      "ps_ind_17_bin     892816 non-null int64\n",
      "ps_ind_18_bin     892816 non-null int64\n",
      "ps_reg_01         892816 non-null float64\n",
      "ps_reg_02         892816 non-null float64\n",
      "ps_reg_03         892816 non-null float64\n",
      "ps_car_01_cat     892816 non-null int64\n",
      "ps_car_02_cat     892816 non-null int64\n",
      "ps_car_03_cat     892816 non-null int64\n",
      "ps_car_04_cat     892816 non-null int64\n",
      "ps_car_05_cat     892816 non-null int64\n",
      "ps_car_06_cat     892816 non-null int64\n",
      "ps_car_07_cat     892816 non-null int64\n",
      "ps_car_08_cat     892816 non-null int64\n",
      "ps_car_09_cat     892816 non-null int64\n",
      "ps_car_10_cat     892816 non-null int64\n",
      "ps_car_11_cat     892816 non-null int64\n",
      "ps_car_11         892816 non-null int64\n",
      "ps_car_12         892816 non-null float64\n",
      "ps_car_13         892816 non-null float64\n",
      "ps_car_14         892816 non-null float64\n",
      "ps_car_15         892816 non-null float64\n",
      "ps_calc_01        892816 non-null float64\n",
      "ps_calc_02        892816 non-null float64\n",
      "ps_calc_03        892816 non-null float64\n",
      "ps_calc_04        892816 non-null int64\n",
      "ps_calc_05        892816 non-null int64\n",
      "ps_calc_06        892816 non-null int64\n",
      "ps_calc_07        892816 non-null int64\n",
      "ps_calc_08        892816 non-null int64\n",
      "ps_calc_09        892816 non-null int64\n",
      "ps_calc_10        892816 non-null int64\n",
      "ps_calc_11        892816 non-null int64\n",
      "ps_calc_12        892816 non-null int64\n",
      "ps_calc_13        892816 non-null int64\n",
      "ps_calc_14        892816 non-null int64\n",
      "ps_calc_15_bin    892816 non-null int64\n",
      "ps_calc_16_bin    892816 non-null int64\n",
      "ps_calc_17_bin    892816 non-null int64\n",
      "ps_calc_18_bin    892816 non-null int64\n",
      "ps_calc_19_bin    892816 non-null int64\n",
      "ps_calc_20_bin    892816 non-null int64\n",
      "dtypes: float64(10), int64(48)\n",
      "memory usage: 395.1 MB\n"
     ]
    }
   ],
   "source": [
    "test.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Supratik\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:1: FutureWarning: Sorting because non-concatenation axis is not aligned. A future version\n",
      "of pandas will change to not sort by default.\n",
      "\n",
      "To accept the future behavior, pass 'sort=False'.\n",
      "\n",
      "To retain the current behavior and silence the warning, pass 'sort=True'.\n",
      "\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    }
   ],
   "source": [
    "traintest = pd.concat([train,test])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>ps_calc_01</th>\n",
       "      <th>ps_calc_02</th>\n",
       "      <th>ps_calc_03</th>\n",
       "      <th>ps_calc_04</th>\n",
       "      <th>ps_calc_05</th>\n",
       "      <th>ps_calc_06</th>\n",
       "      <th>ps_calc_07</th>\n",
       "      <th>ps_calc_08</th>\n",
       "      <th>ps_calc_09</th>\n",
       "      <th>...</th>\n",
       "      <th>ps_ind_13_bin</th>\n",
       "      <th>ps_ind_14</th>\n",
       "      <th>ps_ind_15</th>\n",
       "      <th>ps_ind_16_bin</th>\n",
       "      <th>ps_ind_17_bin</th>\n",
       "      <th>ps_ind_18_bin</th>\n",
       "      <th>ps_reg_01</th>\n",
       "      <th>ps_reg_02</th>\n",
       "      <th>ps_reg_03</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.2</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.718070</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>9</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.3</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>5</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.766078</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>13</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>16</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.1</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>4</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.580948</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>17</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.840759</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>19</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.4</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>2</td>\n",
       "      <td>11</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.9</td>\n",
       "      <td>1.8</td>\n",
       "      <td>2.332649</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>20</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.5</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.617454</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>22</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>13</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.607248</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>26</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.6</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>9</td>\n",
       "      <td>4</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.901388</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>28</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.8</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "      <td>2</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.9</td>\n",
       "      <td>1.4</td>\n",
       "      <td>2.316652</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>34</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>8</td>\n",
       "      <td>2</td>\n",
       "      <td>9</td>\n",
       "      <td>4</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.795692</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>35</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.5</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.378319</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>36</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.9</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>4</td>\n",
       "      <td>11</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.548293</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>43</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.6</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.684197</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>46</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.6</td>\n",
       "      <td>1.052972</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>48</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>5</td>\n",
       "      <td>10</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.3</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>50</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.3</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>6</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.699553</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>58</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>8</td>\n",
       "      <td>2</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.810864</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>61</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.3</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>3</td>\n",
       "      <td>11</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.3</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>64</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.402337</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>65</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.8</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>8</td>\n",
       "      <td>3</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.7</td>\n",
       "      <td>1.372725</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>66</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.1</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>9</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.955903</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>72</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.6</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>11</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.742041</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>74</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.6</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.2</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>77</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.3</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>4</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.587367</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>78</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.6</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>9</td>\n",
       "      <td>4</td>\n",
       "      <td>10</td>\n",
       "      <td>4</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>13</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.2</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>79</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.2</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.666146</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>80</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.5</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>4</td>\n",
       "      <td>10</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.8</td>\n",
       "      <td>1.034408</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>84</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>3</td>\n",
       "      <td>9</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.3</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>85</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.6</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>12</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.9</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.155692</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>892786</th>\n",
       "      <td>1487982</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.2</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.649519</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>892787</th>\n",
       "      <td>1487984</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.490535</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>892788</th>\n",
       "      <td>1487985</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>5</td>\n",
       "      <td>10</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.9</td>\n",
       "      <td>1.2</td>\n",
       "      <td>1.022252</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>892789</th>\n",
       "      <td>1487986</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.6</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>9</td>\n",
       "      <td>3</td>\n",
       "      <td>9</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.609816</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>892790</th>\n",
       "      <td>1487987</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.2</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>4</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.9</td>\n",
       "      <td>1.027436</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>892791</th>\n",
       "      <td>1487989</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.8</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>8</td>\n",
       "      <td>3</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.752080</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>892792</th>\n",
       "      <td>1487991</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>9</td>\n",
       "      <td>3</td>\n",
       "      <td>9</td>\n",
       "      <td>4</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.637868</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>892793</th>\n",
       "      <td>1487993</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.8</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>9</td>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.791360</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>892794</th>\n",
       "      <td>1487995</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>4</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.9</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.108772</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>892795</th>\n",
       "      <td>1487997</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.6</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.942404</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>892796</th>\n",
       "      <td>1487998</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.6</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.456207</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>892797</th>\n",
       "      <td>1487999</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>4</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.3</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>892798</th>\n",
       "      <td>1488000</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.8</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>11</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.9</td>\n",
       "      <td>1.2</td>\n",
       "      <td>2.077709</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>892799</th>\n",
       "      <td>1488002</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.7</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>4</td>\n",
       "      <td>11</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>11</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.748331</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>892800</th>\n",
       "      <td>1488003</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.4</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>9</td>\n",
       "      <td>2</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>11</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.2</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>892801</th>\n",
       "      <td>1488004</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.6</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "      <td>4</td>\n",
       "      <td>8</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.856227</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>892802</th>\n",
       "      <td>1488006</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.1</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>9</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.707107</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>892803</th>\n",
       "      <td>1488007</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>9</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.656696</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>892804</th>\n",
       "      <td>1488010</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>13</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.4</td>\n",
       "      <td>1.022558</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>892805</th>\n",
       "      <td>1488012</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.6</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>9</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.754155</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>892806</th>\n",
       "      <td>1488014</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.4</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>11</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.1</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>892807</th>\n",
       "      <td>1488015</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>9</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.1</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>892808</th>\n",
       "      <td>1488018</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.1</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.603635</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>892809</th>\n",
       "      <td>1488019</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>9</td>\n",
       "      <td>4</td>\n",
       "      <td>8</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.606218</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>892810</th>\n",
       "      <td>1488020</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.9</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>4</td>\n",
       "      <td>8</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.862772</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>892811</th>\n",
       "      <td>1488022</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.9</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.3</td>\n",
       "      <td>1.048809</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>892812</th>\n",
       "      <td>1488023</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.6</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>4</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>11</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.7</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.246495</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>892813</th>\n",
       "      <td>1488024</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.9</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>4</td>\n",
       "      <td>8</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.609303</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>892814</th>\n",
       "      <td>1488025</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>13</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.920937</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>892815</th>\n",
       "      <td>1488026</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "      <td>4</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.992157</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1488028 rows Ã— 59 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             id  ps_calc_01  ps_calc_02  ps_calc_03  ps_calc_04  ps_calc_05  \\\n",
       "0             7         0.6         0.5         0.2           3           1   \n",
       "1             9         0.3         0.1         0.3           2           1   \n",
       "2            13         0.5         0.7         0.1           2           2   \n",
       "3            16         0.6         0.9         0.1           2           4   \n",
       "4            17         0.4         0.6         0.0           2           2   \n",
       "5            19         0.7         0.8         0.4           3           1   \n",
       "6            20         0.2         0.6         0.5           2           2   \n",
       "7            22         0.1         0.5         0.1           1           2   \n",
       "8            26         0.9         0.8         0.6           3           1   \n",
       "9            28         0.7         0.8         0.8           2           2   \n",
       "10           34         0.8         0.1         0.0           2           3   \n",
       "11           35         0.3         0.7         0.5           2           2   \n",
       "12           36         0.7         0.8         0.9           4           1   \n",
       "13           43         0.8         0.7         0.6           2           1   \n",
       "14           46         0.4         0.4         0.1           3           1   \n",
       "15           48         0.5         0.4         0.2           2           1   \n",
       "16           50         0.3         0.0         0.3           2           1   \n",
       "17           58         0.2         0.6         0.1           1           3   \n",
       "18           61         0.4         0.3         0.3           3           1   \n",
       "19           64         0.7         0.3         0.2           2           2   \n",
       "20           65         0.8         0.6         0.8           1           4   \n",
       "21           66         0.3         0.7         0.1           3           2   \n",
       "22           72         0.0         0.6         0.6           3           2   \n",
       "23           74         0.3         0.7         0.6           2           1   \n",
       "24           77         0.2         0.2         0.3           2           1   \n",
       "25           78         0.5         0.7         0.6           2           2   \n",
       "26           79         0.9         0.5         0.2           4           2   \n",
       "27           80         0.7         0.1         0.5           2           1   \n",
       "28           84         0.8         0.4         0.1           2           2   \n",
       "29           85         0.9         0.3         0.6           2           3   \n",
       "...         ...         ...         ...         ...         ...         ...   \n",
       "892786  1487982         0.8         0.5         0.2           3           3   \n",
       "892787  1487984         0.9         0.1         0.1           3           1   \n",
       "892788  1487985         0.5         0.4         0.0           4           1   \n",
       "892789  1487986         0.9         0.9         0.6           2           3   \n",
       "892790  1487987         0.0         0.5         0.2           3           1   \n",
       "892791  1487989         0.3         0.8         0.8           4           3   \n",
       "892792  1487991         0.5         0.5         0.5           2           4   \n",
       "892793  1487993         0.5         0.0         0.8           4           2   \n",
       "892794  1487995         0.2         0.5         0.5           2           2   \n",
       "892795  1487997         0.8         0.2         0.6           2           3   \n",
       "892796  1487998         0.6         0.8         0.6           2           1   \n",
       "892797  1487999         0.2         0.8         0.0           2           2   \n",
       "892798  1488000         0.9         0.2         0.8           1           2   \n",
       "892799  1488002         0.8         0.4         0.7           3           1   \n",
       "892800  1488003         0.2         0.6         0.4           2           3   \n",
       "892801  1488004         0.0         0.2         0.6           2           2   \n",
       "892802  1488006         0.8         0.3         0.1           3           3   \n",
       "892803  1488007         0.9         0.0         0.1           1           2   \n",
       "892804  1488010         0.2         0.4         0.2           3           1   \n",
       "892805  1488012         0.4         0.7         0.6           1           1   \n",
       "892806  1488014         0.0         0.4         0.4           3           3   \n",
       "892807  1488015         0.8         0.8         0.1           1           3   \n",
       "892808  1488018         0.9         0.8         0.1           5           3   \n",
       "892809  1488019         0.5         0.8         0.1           2           2   \n",
       "892810  1488020         0.4         0.5         0.9           1           1   \n",
       "892811  1488022         0.3         0.4         0.9           1           1   \n",
       "892812  1488023         0.3         0.2         0.6           1           3   \n",
       "892813  1488024         0.3         0.3         0.9           2           1   \n",
       "892814  1488025         0.1         0.1         0.3           1           1   \n",
       "892815  1488026         0.4         0.4         0.2           3           4   \n",
       "\n",
       "        ps_calc_06  ps_calc_07  ps_calc_08  ps_calc_09  ...  ps_ind_13_bin  \\\n",
       "0               10           1          10           1  ...              0   \n",
       "1                9           5           8           1  ...              0   \n",
       "2                9           1           8           2  ...              0   \n",
       "3                7           1           8           4  ...              0   \n",
       "4                6           3          10           2  ...              0   \n",
       "5                8           2          11           3  ...              0   \n",
       "6                8           1           8           3  ...              0   \n",
       "7                7           1           6           1  ...              0   \n",
       "8                7           3           9           4  ...              0   \n",
       "9                8           2           9           1  ...              0   \n",
       "10               8           2           9           4  ...              0   \n",
       "11               8           2          10           1  ...              0   \n",
       "12               8           4          11           1  ...              0   \n",
       "13              10           1           8           3  ...              0   \n",
       "14               8           2           6           3  ...              0   \n",
       "15               9           5          10           2  ...              0   \n",
       "16              10           6           7           3  ...              0   \n",
       "17               8           2           9           1  ...              0   \n",
       "18               8           3          11           2  ...              0   \n",
       "19               8           2           5           2  ...              0   \n",
       "20               8           3           8           1  ...              0   \n",
       "21               9           3           7           3  ...              0   \n",
       "22               8           0           9           0  ...              0   \n",
       "23               8           3          10           2  ...              0   \n",
       "24               7           4           7           2  ...              0   \n",
       "25               9           4          10           4  ...              0   \n",
       "26               7           2          10           0  ...              0   \n",
       "27               7           4          10           2  ...              0   \n",
       "28              10           3           9           2  ...              0   \n",
       "29               7           3          12           2  ...              0   \n",
       "...            ...         ...         ...         ...  ...            ...   \n",
       "892786           8           1           8           0  ...              0   \n",
       "892787           6           2          10           2  ...              0   \n",
       "892788           8           5          10           3  ...              0   \n",
       "892789           9           3           9           2  ...              0   \n",
       "892790           7           2          10           4  ...              0   \n",
       "892791           8           3           8           0  ...              0   \n",
       "892792           9           3           9           4  ...              0   \n",
       "892793           9           2           8           3  ...              0   \n",
       "892794           8           1          10           4  ...              0   \n",
       "892795           6           2           9           0  ...              0   \n",
       "892796           9           2           7           1  ...              0   \n",
       "892797          10           4           8           1  ...              0   \n",
       "892798           8           2          10           1  ...              0   \n",
       "892799           8           4          11           2  ...              0   \n",
       "892800           9           2           9           0  ...              0   \n",
       "892801           8           4           8           3  ...              0   \n",
       "892802           5           2           9           2  ...              0   \n",
       "892803           7           2           9           3  ...              0   \n",
       "892804           9           1           9           0  ...              0   \n",
       "892805           6           3           9           2  ...              0   \n",
       "892806           7           1          11           2  ...              0   \n",
       "892807           6           2           9           3  ...              0   \n",
       "892808           5           1          10           2  ...              0   \n",
       "892809           9           4           8           2  ...              0   \n",
       "892810           7           4           8           2  ...              0   \n",
       "892811           7           3          10           3  ...              0   \n",
       "892812           7           3          10           4  ...              0   \n",
       "892813          10           4           8           2  ...              0   \n",
       "892814           9           2          10           1  ...              0   \n",
       "892815           7           2           8           4  ...              0   \n",
       "\n",
       "        ps_ind_14  ps_ind_15  ps_ind_16_bin  ps_ind_17_bin  ps_ind_18_bin  \\\n",
       "0               0         11              0              1              0   \n",
       "1               0          3              0              0              1   \n",
       "2               0         12              1              0              0   \n",
       "3               0          8              1              0              0   \n",
       "4               0          9              1              0              0   \n",
       "5               0          6              1              0              0   \n",
       "6               0          8              1              0              0   \n",
       "7               0         13              1              0              0   \n",
       "8               0          6              1              0              0   \n",
       "9               0          4              0              0              1   \n",
       "10              0          3              1              0              0   \n",
       "11              0          9              1              0              0   \n",
       "12              0         10              1              0              0   \n",
       "13              0         12              1              0              0   \n",
       "14              0         10              0              0              1   \n",
       "15              0          5              0              0              1   \n",
       "16              0          9              1              0              0   \n",
       "17              0          4              1              0              0   \n",
       "18              0         12              1              0              0   \n",
       "19              0          8              1              0              0   \n",
       "20              0          3              0              0              1   \n",
       "21              0          8              1              0              0   \n",
       "22              0         11              1              0              0   \n",
       "23              0          3              1              0              0   \n",
       "24              0          9              0              0              1   \n",
       "25              0         13              1              0              0   \n",
       "26              0          8              1              0              0   \n",
       "27              0         12              1              0              0   \n",
       "28              0          8              1              0              0   \n",
       "29              0          8              1              0              0   \n",
       "...           ...        ...            ...            ...            ...   \n",
       "892786          0          2              1              0              0   \n",
       "892787          0         10              0              1              0   \n",
       "892788          0          8              1              0              0   \n",
       "892789          0          7              1              0              0   \n",
       "892790          0          9              0              1              0   \n",
       "892791          0         10              0              0              0   \n",
       "892792          0          3              0              0              1   \n",
       "892793          0          8              1              0              0   \n",
       "892794          0         12              1              0              0   \n",
       "892795          0          7              0              0              1   \n",
       "892796          0          2              0              0              1   \n",
       "892797          0          3              0              0              1   \n",
       "892798          0         11              1              0              0   \n",
       "892799          0         11              1              0              0   \n",
       "892800          0         11              1              0              0   \n",
       "892801          0          4              0              0              1   \n",
       "892802          0          4              0              0              1   \n",
       "892803          0          4              1              0              0   \n",
       "892804          0         13              1              0              0   \n",
       "892805          0         11              0              1              0   \n",
       "892806          0          2              0              0              0   \n",
       "892807          0          2              0              0              1   \n",
       "892808          0          9              1              0              0   \n",
       "892809          0          8              1              0              0   \n",
       "892810          0          9              0              0              0   \n",
       "892811          0          2              0              0              1   \n",
       "892812          0         11              1              0              0   \n",
       "892813          0          5              0              0              1   \n",
       "892814          0         13              1              0              0   \n",
       "892815          0         12              1              0              0   \n",
       "\n",
       "        ps_reg_01  ps_reg_02  ps_reg_03  target  \n",
       "0             0.7        0.2   0.718070     0.0  \n",
       "1             0.8        0.4   0.766078     0.0  \n",
       "2             0.0        0.0  -1.000000     0.0  \n",
       "3             0.9        0.2   0.580948     0.0  \n",
       "4             0.7        0.6   0.840759     0.0  \n",
       "5             0.9        1.8   2.332649     0.0  \n",
       "6             0.6        0.1   0.617454     0.0  \n",
       "7             0.7        0.4   0.607248     0.0  \n",
       "8             0.9        0.7   0.901388     0.0  \n",
       "9             0.9        1.4   2.316652     1.0  \n",
       "10            0.5        0.4   0.795692     0.0  \n",
       "11            0.9        0.1   0.378319     0.0  \n",
       "12            0.5        0.2   0.548293     0.0  \n",
       "13            0.7        0.9   0.684197     0.0  \n",
       "14            0.8        0.6   1.052972     0.0  \n",
       "15            0.4        0.3  -1.000000     0.0  \n",
       "16            0.6        0.3   0.699553     0.0  \n",
       "17            0.9        0.5   0.810864     0.0  \n",
       "18            0.3        0.3  -1.000000     0.0  \n",
       "19            0.9        0.3   0.402337     1.0  \n",
       "20            0.4        0.7   1.372725     0.0  \n",
       "21            0.7        0.4   0.955903     0.0  \n",
       "22            0.6        0.4   0.742041     0.0  \n",
       "23            0.2        0.2  -1.000000     0.0  \n",
       "24            0.4        0.2   0.587367     0.0  \n",
       "25            0.1        0.2  -1.000000     0.0  \n",
       "26            0.6        0.2   0.666146     0.0  \n",
       "27            0.9        0.8   1.034408     0.0  \n",
       "28            0.2        0.3  -1.000000     1.0  \n",
       "29            0.9        1.0   1.155692     0.0  \n",
       "...           ...        ...        ...     ...  \n",
       "892786        0.8        0.3   0.649519     NaN  \n",
       "892787        0.9        0.2   0.490535     NaN  \n",
       "892788        0.9        1.2   1.022252     NaN  \n",
       "892789        0.8        0.2   0.609816     NaN  \n",
       "892790        0.6        0.9   1.027436     NaN  \n",
       "892791        0.0        0.0   0.752080     NaN  \n",
       "892792        0.0        0.0   0.637868     NaN  \n",
       "892793        0.8        0.4   0.791360     NaN  \n",
       "892794        0.9        1.0   1.108772     NaN  \n",
       "892795        0.9        0.2   0.942404     NaN  \n",
       "892796        0.7        0.0   0.456207     NaN  \n",
       "892797        0.1        0.3  -1.000000     NaN  \n",
       "892798        0.9        1.2   2.077709     NaN  \n",
       "892799        0.4        0.4   0.748331     NaN  \n",
       "892800        0.1        0.2  -1.000000     NaN  \n",
       "892801        0.4        0.7   0.856227     NaN  \n",
       "892802        0.6        0.1   0.707107     NaN  \n",
       "892803        0.9        0.2   0.656696     NaN  \n",
       "892804        0.7        0.4   1.022558     NaN  \n",
       "892805        0.4        0.0   0.754155     NaN  \n",
       "892806        0.1        0.1  -1.000000     NaN  \n",
       "892807        0.2        0.1  -1.000000     NaN  \n",
       "892808        0.9        0.4   0.603635     NaN  \n",
       "892809        0.8        0.2   0.606218     NaN  \n",
       "892810        0.8        0.4   0.862772     NaN  \n",
       "892811        0.5        0.3   1.048809     NaN  \n",
       "892812        0.7        1.0   1.246495     NaN  \n",
       "892813        0.4        0.0   0.609303     NaN  \n",
       "892814        0.6        0.6   0.920937     NaN  \n",
       "892815        0.9        0.8   0.992157     NaN  \n",
       "\n",
       "[1488028 rows x 59 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "traintest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1488028, 59)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "traintest.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 1488028 entries, 0 to 892815\n",
      "Data columns (total 59 columns):\n",
      "id                1488028 non-null int64\n",
      "ps_calc_01        1488028 non-null float64\n",
      "ps_calc_02        1488028 non-null float64\n",
      "ps_calc_03        1488028 non-null float64\n",
      "ps_calc_04        1488028 non-null int64\n",
      "ps_calc_05        1488028 non-null int64\n",
      "ps_calc_06        1488028 non-null int64\n",
      "ps_calc_07        1488028 non-null int64\n",
      "ps_calc_08        1488028 non-null int64\n",
      "ps_calc_09        1488028 non-null int64\n",
      "ps_calc_10        1488028 non-null int64\n",
      "ps_calc_11        1488028 non-null int64\n",
      "ps_calc_12        1488028 non-null int64\n",
      "ps_calc_13        1488028 non-null int64\n",
      "ps_calc_14        1488028 non-null int64\n",
      "ps_calc_15_bin    1488028 non-null int64\n",
      "ps_calc_16_bin    1488028 non-null int64\n",
      "ps_calc_17_bin    1488028 non-null int64\n",
      "ps_calc_18_bin    1488028 non-null int64\n",
      "ps_calc_19_bin    1488028 non-null int64\n",
      "ps_calc_20_bin    1488028 non-null int64\n",
      "ps_car_01_cat     1488028 non-null int64\n",
      "ps_car_02_cat     1488028 non-null int64\n",
      "ps_car_03_cat     1488028 non-null int64\n",
      "ps_car_04_cat     1488028 non-null int64\n",
      "ps_car_05_cat     1488028 non-null int64\n",
      "ps_car_06_cat     1488028 non-null int64\n",
      "ps_car_07_cat     1488028 non-null int64\n",
      "ps_car_08_cat     1488028 non-null int64\n",
      "ps_car_09_cat     1488028 non-null int64\n",
      "ps_car_10_cat     1488028 non-null int64\n",
      "ps_car_11         1488028 non-null int64\n",
      "ps_car_11_cat     1488028 non-null int64\n",
      "ps_car_12         1488028 non-null float64\n",
      "ps_car_13         1488028 non-null float64\n",
      "ps_car_14         1488028 non-null float64\n",
      "ps_car_15         1488028 non-null float64\n",
      "ps_ind_01         1488028 non-null int64\n",
      "ps_ind_02_cat     1488028 non-null int64\n",
      "ps_ind_03         1488028 non-null int64\n",
      "ps_ind_04_cat     1488028 non-null int64\n",
      "ps_ind_05_cat     1488028 non-null int64\n",
      "ps_ind_06_bin     1488028 non-null int64\n",
      "ps_ind_07_bin     1488028 non-null int64\n",
      "ps_ind_08_bin     1488028 non-null int64\n",
      "ps_ind_09_bin     1488028 non-null int64\n",
      "ps_ind_10_bin     1488028 non-null int64\n",
      "ps_ind_11_bin     1488028 non-null int64\n",
      "ps_ind_12_bin     1488028 non-null int64\n",
      "ps_ind_13_bin     1488028 non-null int64\n",
      "ps_ind_14         1488028 non-null int64\n",
      "ps_ind_15         1488028 non-null int64\n",
      "ps_ind_16_bin     1488028 non-null int64\n",
      "ps_ind_17_bin     1488028 non-null int64\n",
      "ps_ind_18_bin     1488028 non-null int64\n",
      "ps_reg_01         1488028 non-null float64\n",
      "ps_reg_02         1488028 non-null float64\n",
      "ps_reg_03         1488028 non-null float64\n",
      "target            595212 non-null float64\n",
      "dtypes: float64(11), int64(48)\n",
      "memory usage: 681.2 MB\n"
     ]
    }
   ],
   "source": [
    "traintest.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>ps_calc_01</th>\n",
       "      <th>ps_calc_02</th>\n",
       "      <th>ps_calc_03</th>\n",
       "      <th>ps_calc_04</th>\n",
       "      <th>ps_calc_05</th>\n",
       "      <th>ps_calc_06</th>\n",
       "      <th>ps_calc_07</th>\n",
       "      <th>ps_calc_08</th>\n",
       "      <th>ps_calc_09</th>\n",
       "      <th>...</th>\n",
       "      <th>ps_ind_13_bin</th>\n",
       "      <th>ps_ind_14</th>\n",
       "      <th>ps_ind_15</th>\n",
       "      <th>ps_ind_16_bin</th>\n",
       "      <th>ps_ind_17_bin</th>\n",
       "      <th>ps_ind_18_bin</th>\n",
       "      <th>ps_reg_01</th>\n",
       "      <th>ps_reg_02</th>\n",
       "      <th>ps_reg_03</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>1.488028e+06</td>\n",
       "      <td>1.488028e+06</td>\n",
       "      <td>1.488028e+06</td>\n",
       "      <td>1.488028e+06</td>\n",
       "      <td>1.488028e+06</td>\n",
       "      <td>1.488028e+06</td>\n",
       "      <td>1.488028e+06</td>\n",
       "      <td>1.488028e+06</td>\n",
       "      <td>1.488028e+06</td>\n",
       "      <td>1.488028e+06</td>\n",
       "      <td>...</td>\n",
       "      <td>1.488028e+06</td>\n",
       "      <td>1.488028e+06</td>\n",
       "      <td>1.488028e+06</td>\n",
       "      <td>1.488028e+06</td>\n",
       "      <td>1.488028e+06</td>\n",
       "      <td>1.488028e+06</td>\n",
       "      <td>1.488028e+06</td>\n",
       "      <td>1.488028e+06</td>\n",
       "      <td>1.488028e+06</td>\n",
       "      <td>595212.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>7.440135e+05</td>\n",
       "      <td>4.496817e-01</td>\n",
       "      <td>4.501073e-01</td>\n",
       "      <td>4.499718e-01</td>\n",
       "      <td>2.371666e+00</td>\n",
       "      <td>1.885551e+00</td>\n",
       "      <td>7.688461e+00</td>\n",
       "      <td>3.008052e+00</td>\n",
       "      <td>9.225874e+00</td>\n",
       "      <td>2.338736e+00</td>\n",
       "      <td>...</td>\n",
       "      <td>1.002669e-03</td>\n",
       "      <td>1.241038e-02</td>\n",
       "      <td>7.298086e+00</td>\n",
       "      <td>6.606838e-01</td>\n",
       "      <td>1.206718e-01</td>\n",
       "      <td>1.543620e-01</td>\n",
       "      <td>6.110305e-01</td>\n",
       "      <td>4.395943e-01</td>\n",
       "      <td>5.514848e-01</td>\n",
       "      <td>0.036448</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>4.295568e+05</td>\n",
       "      <td>2.872071e-01</td>\n",
       "      <td>2.871817e-01</td>\n",
       "      <td>2.872136e-01</td>\n",
       "      <td>1.117059e+00</td>\n",
       "      <td>1.136029e+00</td>\n",
       "      <td>1.333837e+00</td>\n",
       "      <td>1.414919e+00</td>\n",
       "      <td>1.460205e+00</td>\n",
       "      <td>1.247940e+00</td>\n",
       "      <td>...</td>\n",
       "      <td>3.164909e-02</td>\n",
       "      <td>1.273684e-01</td>\n",
       "      <td>3.543585e+00</td>\n",
       "      <td>4.734774e-01</td>\n",
       "      <td>3.257456e-01</td>\n",
       "      <td>3.612955e-01</td>\n",
       "      <td>2.876763e-01</td>\n",
       "      <td>4.045123e-01</td>\n",
       "      <td>7.938159e-01</td>\n",
       "      <td>0.187401</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>-1.000000e+00</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>3.720068e+05</td>\n",
       "      <td>2.000000e-01</td>\n",
       "      <td>2.000000e-01</td>\n",
       "      <td>2.000000e-01</td>\n",
       "      <td>2.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>7.000000e+00</td>\n",
       "      <td>2.000000e+00</td>\n",
       "      <td>8.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>5.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>4.000000e-01</td>\n",
       "      <td>2.000000e-01</td>\n",
       "      <td>5.250000e-01</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>7.440135e+05</td>\n",
       "      <td>4.000000e-01</td>\n",
       "      <td>5.000000e-01</td>\n",
       "      <td>5.000000e-01</td>\n",
       "      <td>2.000000e+00</td>\n",
       "      <td>2.000000e+00</td>\n",
       "      <td>8.000000e+00</td>\n",
       "      <td>3.000000e+00</td>\n",
       "      <td>9.000000e+00</td>\n",
       "      <td>2.000000e+00</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>7.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>7.000000e-01</td>\n",
       "      <td>3.000000e-01</td>\n",
       "      <td>7.211103e-01</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>1.116020e+06</td>\n",
       "      <td>7.000000e-01</td>\n",
       "      <td>7.000000e-01</td>\n",
       "      <td>7.000000e-01</td>\n",
       "      <td>3.000000e+00</td>\n",
       "      <td>3.000000e+00</td>\n",
       "      <td>9.000000e+00</td>\n",
       "      <td>4.000000e+00</td>\n",
       "      <td>1.000000e+01</td>\n",
       "      <td>3.000000e+00</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>1.000000e+01</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>9.000000e-01</td>\n",
       "      <td>6.000000e-01</td>\n",
       "      <td>1.001561e+00</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.488027e+06</td>\n",
       "      <td>9.000000e-01</td>\n",
       "      <td>9.000000e-01</td>\n",
       "      <td>9.000000e-01</td>\n",
       "      <td>5.000000e+00</td>\n",
       "      <td>6.000000e+00</td>\n",
       "      <td>1.000000e+01</td>\n",
       "      <td>9.000000e+00</td>\n",
       "      <td>1.200000e+01</td>\n",
       "      <td>7.000000e+00</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>4.000000e+00</td>\n",
       "      <td>1.300000e+01</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>9.000000e-01</td>\n",
       "      <td>1.800000e+00</td>\n",
       "      <td>4.423517e+00</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows Ã— 59 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                 id    ps_calc_01    ps_calc_02    ps_calc_03    ps_calc_04  \\\n",
       "count  1.488028e+06  1.488028e+06  1.488028e+06  1.488028e+06  1.488028e+06   \n",
       "mean   7.440135e+05  4.496817e-01  4.501073e-01  4.499718e-01  2.371666e+00   \n",
       "std    4.295568e+05  2.872071e-01  2.871817e-01  2.872136e-01  1.117059e+00   \n",
       "min    0.000000e+00  0.000000e+00  0.000000e+00  0.000000e+00  0.000000e+00   \n",
       "25%    3.720068e+05  2.000000e-01  2.000000e-01  2.000000e-01  2.000000e+00   \n",
       "50%    7.440135e+05  4.000000e-01  5.000000e-01  5.000000e-01  2.000000e+00   \n",
       "75%    1.116020e+06  7.000000e-01  7.000000e-01  7.000000e-01  3.000000e+00   \n",
       "max    1.488027e+06  9.000000e-01  9.000000e-01  9.000000e-01  5.000000e+00   \n",
       "\n",
       "         ps_calc_05    ps_calc_06    ps_calc_07    ps_calc_08    ps_calc_09  \\\n",
       "count  1.488028e+06  1.488028e+06  1.488028e+06  1.488028e+06  1.488028e+06   \n",
       "mean   1.885551e+00  7.688461e+00  3.008052e+00  9.225874e+00  2.338736e+00   \n",
       "std    1.136029e+00  1.333837e+00  1.414919e+00  1.460205e+00  1.247940e+00   \n",
       "min    0.000000e+00  0.000000e+00  0.000000e+00  1.000000e+00  0.000000e+00   \n",
       "25%    1.000000e+00  7.000000e+00  2.000000e+00  8.000000e+00  1.000000e+00   \n",
       "50%    2.000000e+00  8.000000e+00  3.000000e+00  9.000000e+00  2.000000e+00   \n",
       "75%    3.000000e+00  9.000000e+00  4.000000e+00  1.000000e+01  3.000000e+00   \n",
       "max    6.000000e+00  1.000000e+01  9.000000e+00  1.200000e+01  7.000000e+00   \n",
       "\n",
       "       ...  ps_ind_13_bin     ps_ind_14     ps_ind_15  ps_ind_16_bin  \\\n",
       "count  ...   1.488028e+06  1.488028e+06  1.488028e+06   1.488028e+06   \n",
       "mean   ...   1.002669e-03  1.241038e-02  7.298086e+00   6.606838e-01   \n",
       "std    ...   3.164909e-02  1.273684e-01  3.543585e+00   4.734774e-01   \n",
       "min    ...   0.000000e+00  0.000000e+00  0.000000e+00   0.000000e+00   \n",
       "25%    ...   0.000000e+00  0.000000e+00  5.000000e+00   0.000000e+00   \n",
       "50%    ...   0.000000e+00  0.000000e+00  7.000000e+00   1.000000e+00   \n",
       "75%    ...   0.000000e+00  0.000000e+00  1.000000e+01   1.000000e+00   \n",
       "max    ...   1.000000e+00  4.000000e+00  1.300000e+01   1.000000e+00   \n",
       "\n",
       "       ps_ind_17_bin  ps_ind_18_bin     ps_reg_01     ps_reg_02     ps_reg_03  \\\n",
       "count   1.488028e+06   1.488028e+06  1.488028e+06  1.488028e+06  1.488028e+06   \n",
       "mean    1.206718e-01   1.543620e-01  6.110305e-01  4.395943e-01  5.514848e-01   \n",
       "std     3.257456e-01   3.612955e-01  2.876763e-01  4.045123e-01  7.938159e-01   \n",
       "min     0.000000e+00   0.000000e+00  0.000000e+00  0.000000e+00 -1.000000e+00   \n",
       "25%     0.000000e+00   0.000000e+00  4.000000e-01  2.000000e-01  5.250000e-01   \n",
       "50%     0.000000e+00   0.000000e+00  7.000000e-01  3.000000e-01  7.211103e-01   \n",
       "75%     0.000000e+00   0.000000e+00  9.000000e-01  6.000000e-01  1.001561e+00   \n",
       "max     1.000000e+00   1.000000e+00  9.000000e-01  1.800000e+00  4.423517e+00   \n",
       "\n",
       "              target  \n",
       "count  595212.000000  \n",
       "mean        0.036448  \n",
       "std         0.187401  \n",
       "min         0.000000  \n",
       "25%         0.000000  \n",
       "50%         0.000000  \n",
       "75%         0.000000  \n",
       "max         1.000000  \n",
       "\n",
       "[8 rows x 59 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "traintest.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    573518\n",
       "1     21694\n",
       "Name: target, dtype: int64"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train['target'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ps_car_03_cat, ps_car_05_cat & ps_reg_03 have too many missing values (-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6    149327\n",
       "0.0    149227\n",
       "0.2    149157\n",
       "0.5    149148\n",
       "0.1    148797\n",
       "0.8    148635\n",
       "0.4    148527\n",
       "0.3    148476\n",
       "0.9    148411\n",
       "0.7    148323\n",
       "Name: ps_calc_01, dtype: int64"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "traintest['ps_calc_01'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "target           1.000000\n",
       "ps_ind_06_bin   -0.034017\n",
       "ps_ind_07_bin    0.034218\n",
       "ps_ind_17_bin    0.037053\n",
       "ps_reg_02        0.034800\n",
       "ps_reg_03        0.030888\n",
       "ps_car_02_cat   -0.031534\n",
       "ps_car_03_cat    0.032401\n",
       "ps_car_04_cat    0.032900\n",
       "ps_car_07_cat   -0.036395\n",
       "ps_car_12        0.038790\n",
       "ps_car_13        0.053899\n",
       "Name: target, dtype: float64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.corr().loc['target',] [abs(train.corr().loc['target',]) > 0.03]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['target', 'ps_ind_06_bin', 'ps_ind_07_bin', 'ps_ind_17_bin',\n",
       "       'ps_reg_02', 'ps_reg_03', 'ps_car_02_cat', 'ps_car_03_cat',\n",
       "       'ps_car_04_cat', 'ps_car_07_cat', 'ps_car_12', 'ps_car_13'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.corr().loc['target',] [abs(train.corr().loc['target',]) > 0.03].index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imputing median in variables with missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, feature in enumerate(list(train)):\n",
    "    if train[feature].isnull().sum() > 0:\n",
    "         train[feature+\"_mod\"] = train[feature].fillna(traintest[feature].median())\n",
    " \n",
    "for i, feature in enumerate(list(test)):\n",
    "    if test[feature].isnull().sum() > 0:\n",
    "        test[feature+\"_mod\"]= test[feature].fillna(traintest[feature].median())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing variables for significant chi-squared"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['ps_ind_05_cat_mod', 'ps_car_04_cat', 'ps_car_06_cat', 'ps_car_11_cat']\n"
     ]
    }
   ],
   "source": [
    "train['target_mod'] = train['target'].map(lambda x: 2 if x==0 else x)\n",
    "prob = 0.95\n",
    "list_imp_features = []\n",
    "for feature in cat_and_bin_features:\n",
    "    f_obs = np.array([train[feature].values,train['target_mod'].values])\n",
    "    stat, p, dof = stats.chi2_contingency(f_obs)[0:3]\n",
    "    critical = stats.chi2.ppf(prob, dof)\n",
    "    if abs(stat) >= critical:\n",
    "        list_imp_features.append(feature)\n",
    "print(list_imp_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Upsampling positive Tragets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(43388, 69)\n",
      "1    21694\n",
      "0    21694\n",
      "Name: target, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "train_pos = train[train['target'] == 1]\n",
    "train_neg = train[train['target'] == 0]\n",
    "train_neg_sampled = train_neg.sample(n=21694)\n",
    "train_upsampled = pd.concat([train_neg_sampled,train_pos])\n",
    "print(train_upsampled.shape)\n",
    "print(train_upsampled['target'].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using all variables except ones with too many missing values and the original unimputed variables with missings in them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Variables ps_reg_03, ps_car_03_cat and ps_car_05_cat are being dropped as they have too many missing values\n",
    "#Other variables are being replced with the same variables augmented by imputing values for missings\n",
    "X = train_upsampled.drop(['id','ps_car_01_cat','ps_car_02_cat','ps_car_03_cat','ps_car_05_cat',\n",
    "                          'ps_car_07_cat','ps_car_09_cat','ps_car_11','ps_car_12','ps_car_14','ps_ind_02_cat',\n",
    "                          'ps_ind_04_cat','ps_ind_05_cat','ps_reg_03'], axis=1)\n",
    "y = train_upsampled['target']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(43388, 55)\n",
      "(43388,)\n"
     ]
    }
   ],
   "source": [
    "print(X.shape)\n",
    "print(y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Standard Scaling Continous Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['target', 'ps_ind_01', 'ps_ind_03', 'ps_ind_06_bin', 'ps_ind_07_bin',\n",
       "       'ps_ind_08_bin', 'ps_ind_09_bin', 'ps_ind_10_bin', 'ps_ind_11_bin',\n",
       "       'ps_ind_12_bin', 'ps_ind_13_bin', 'ps_ind_14', 'ps_ind_15',\n",
       "       'ps_ind_16_bin', 'ps_ind_17_bin', 'ps_ind_18_bin', 'ps_reg_01',\n",
       "       'ps_reg_02', 'ps_car_04_cat', 'ps_car_06_cat', 'ps_car_08_cat',\n",
       "       'ps_car_10_cat', 'ps_car_11_cat', 'ps_car_13', 'ps_car_15',\n",
       "       'ps_calc_01', 'ps_calc_02', 'ps_calc_03', 'ps_calc_04', 'ps_calc_05',\n",
       "       'ps_calc_06', 'ps_calc_07', 'ps_calc_08', 'ps_calc_09', 'ps_calc_10',\n",
       "       'ps_calc_11', 'ps_calc_12', 'ps_calc_13', 'ps_calc_14',\n",
       "       'ps_calc_15_bin', 'ps_calc_16_bin', 'ps_calc_17_bin', 'ps_calc_18_bin',\n",
       "       'ps_calc_19_bin', 'ps_calc_20_bin', 'ps_car_01_cat_mod',\n",
       "       'ps_car_02_cat_mod', 'ps_car_07_cat_mod', 'ps_car_09_cat_mod',\n",
       "       'ps_car_11_mod', 'ps_car_12_mod', 'ps_car_14_mod', 'ps_ind_02_cat_mod',\n",
       "       'ps_ind_04_cat_mod', 'ps_ind_05_cat_mod'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(43388, 25)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Supratik\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\data.py:645: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by StandardScaler.\n",
      "  return self.partial_fit(X, y)\n",
      "C:\\Users\\Supratik\\Anaconda3\\lib\\site-packages\\sklearn\\base.py:464: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by StandardScaler.\n",
      "  return self.fit(X, **fit_params).transform(X)\n"
     ]
    }
   ],
   "source": [
    "sc = StandardScaler()\n",
    "\n",
    "scaled_X = pd.DataFrame(sc.fit_transform(X[['ps_ind_01', 'ps_ind_03', \n",
    "       'ps_ind_14', 'ps_ind_15', 'ps_reg_01','ps_reg_02', 'ps_car_13', 'ps_car_15',\n",
    "       'ps_calc_01', 'ps_calc_02', 'ps_calc_03', 'ps_calc_04', 'ps_calc_05',\n",
    "       'ps_calc_06', 'ps_calc_07', 'ps_calc_08', 'ps_calc_09', 'ps_calc_10',\n",
    "       'ps_calc_11', 'ps_calc_12', 'ps_calc_13', 'ps_calc_14',\n",
    "       'ps_car_11_mod', 'ps_car_12_mod', 'ps_car_14_mod']]))\n",
    "\n",
    "scaled_X.columns = ['ps_ind_01', 'ps_ind_03', \n",
    "       'ps_ind_14', 'ps_ind_15', 'ps_reg_01','ps_reg_02', 'ps_car_13', 'ps_car_15',\n",
    "       'ps_calc_01', 'ps_calc_02', 'ps_calc_03', 'ps_calc_04', 'ps_calc_05',\n",
    "       'ps_calc_06', 'ps_calc_07', 'ps_calc_08', 'ps_calc_09', 'ps_calc_10',\n",
    "       'ps_calc_11', 'ps_calc_12', 'ps_calc_13', 'ps_calc_14',\n",
    "       'ps_car_11_mod', 'ps_car_12_mod', 'ps_car_14_mod']\n",
    "\n",
    "scaled_X = scaled_X.reset_index(drop=True)\n",
    "\n",
    "print(scaled_X.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Supratik\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:6: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by StandardScaler.\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "scaled_test_X = pd.DataFrame(sc.transform(test[['ps_ind_01', 'ps_ind_03', \n",
    "       'ps_ind_14', 'ps_ind_15', 'ps_reg_01','ps_reg_02', 'ps_car_13', 'ps_car_15',\n",
    "       'ps_calc_01', 'ps_calc_02', 'ps_calc_03', 'ps_calc_04', 'ps_calc_05',\n",
    "       'ps_calc_06', 'ps_calc_07', 'ps_calc_08', 'ps_calc_09', 'ps_calc_10',\n",
    "       'ps_calc_11', 'ps_calc_12', 'ps_calc_13', 'ps_calc_14',\n",
    "       'ps_car_11_mod', 'ps_car_12_mod', 'ps_car_14_mod']]))\n",
    "\n",
    "scaled_test_X.columns = ['ps_ind_01', 'ps_ind_03', \n",
    "       'ps_ind_14', 'ps_ind_15', 'ps_reg_01','ps_reg_02', 'ps_car_13', 'ps_car_15',\n",
    "       'ps_calc_01', 'ps_calc_02', 'ps_calc_03', 'ps_calc_04', 'ps_calc_05',\n",
    "       'ps_calc_06', 'ps_calc_07', 'ps_calc_08', 'ps_calc_09', 'ps_calc_10',\n",
    "       'ps_calc_11', 'ps_calc_12', 'ps_calc_13', 'ps_calc_14',\n",
    "       'ps_car_11_mod', 'ps_car_12_mod', 'ps_car_14_mod']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(892816, 25)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scaled_test_X.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# One Hot Encoding Binary Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Supratik\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\_encoders.py:371: FutureWarning: The handling of integer data will change in version 0.22. Currently, the categories are determined based on the range [0, max(values)], while in the future they will be determined based on the unique values.\n",
      "If you want the future behaviour and silence this warning, you can specify \"categories='auto'\".\n",
      "In case you used a LabelEncoder before this OneHotEncoder to convert the categories to integers, then you can now use the OneHotEncoder directly.\n",
      "  warnings.warn(msg, FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "oh = OneHotEncoder()\n",
    "ohencoded_x = oh.fit_transform(X[['ps_ind_06_bin', 'ps_ind_07_bin',\n",
    "       'ps_ind_08_bin', 'ps_ind_09_bin', 'ps_ind_10_bin', 'ps_ind_11_bin',\n",
    "       'ps_ind_12_bin', 'ps_ind_13_bin','ps_ind_16_bin', 'ps_ind_17_bin', 'ps_ind_18_bin',\n",
    "       'ps_calc_15_bin', 'ps_calc_16_bin', 'ps_calc_17_bin', 'ps_calc_18_bin',\n",
    "       'ps_calc_19_bin', 'ps_calc_20_bin']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "ohencoded_test_x = oh.transform(test[['ps_ind_06_bin', 'ps_ind_07_bin',\n",
    "       'ps_ind_08_bin', 'ps_ind_09_bin', 'ps_ind_10_bin', 'ps_ind_11_bin',\n",
    "       'ps_ind_12_bin', 'ps_ind_13_bin','ps_ind_16_bin', 'ps_ind_17_bin', 'ps_ind_18_bin',\n",
    "       'ps_calc_15_bin', 'ps_calc_16_bin', 'ps_calc_17_bin', 'ps_calc_18_bin',\n",
    "       'ps_calc_19_bin', 'ps_calc_20_bin']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(43388, 34)\n",
      "(892816, 34)\n"
     ]
    }
   ],
   "source": [
    "oh_df = pd.DataFrame(ohencoded_x.toarray())\n",
    "oh_df_test = pd.DataFrame(ohencoded_test_x.toarray())\n",
    "print(oh_df.shape)\n",
    "print(oh_df_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Mean Encoding Categorical Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "X['ps_car_04_cat_enc'] = X['ps_car_04_cat'].map(X.groupby('ps_car_04_cat').target.mean())\n",
    "X['ps_car_06_cat_enc'] = X['ps_car_06_cat'].map(X.groupby('ps_car_06_cat').target.mean())\n",
    "X['ps_car_08_cat_enc'] = X['ps_car_08_cat'].map(X.groupby('ps_car_08_cat').target.mean())\n",
    "X['ps_car_10_cat_enc'] = X['ps_car_10_cat'].map(X.groupby('ps_car_10_cat').target.mean())\n",
    "X['ps_car_11_cat_enc'] = X['ps_car_11_cat'].map(X.groupby('ps_car_11_cat').target.mean())\n",
    "X['ps_car_01_cat_mod_enc'] = X['ps_car_01_cat_mod'].map(X.groupby('ps_car_01_cat_mod').target.mean())\n",
    "X['ps_car_02_cat_mod_enc'] = X['ps_car_02_cat_mod'].map(X.groupby('ps_car_02_cat_mod').target.mean())\n",
    "X['ps_car_07_cat_mod_enc'] = X['ps_car_07_cat_mod'].map(X.groupby('ps_car_07_cat_mod').target.mean())\n",
    "X['ps_car_09_cat_mod_enc'] = X['ps_car_09_cat_mod'].map(X.groupby('ps_car_09_cat_mod').target.mean())\n",
    "X['ps_ind_02_cat_mod_enc'] = X['ps_ind_02_cat_mod'].map(X.groupby('ps_ind_02_cat_mod').target.mean())\n",
    "X['ps_ind_04_cat_mod_enc'] = X['ps_ind_04_cat_mod'].map(X.groupby('ps_ind_04_cat_mod').target.mean())\n",
    "X['ps_ind_05_cat_mod_enc'] = X['ps_ind_05_cat_mod'].map(X.groupby('ps_ind_05_cat_mod').target.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "test['ps_car_04_cat_enc'] = test['ps_car_04_cat'].map(X.groupby('ps_car_04_cat').target.mean())\n",
    "test['ps_car_06_cat_enc'] = test['ps_car_06_cat'].map(X.groupby('ps_car_06_cat').target.mean())\n",
    "test['ps_car_08_cat_enc'] = test['ps_car_08_cat'].map(X.groupby('ps_car_08_cat').target.mean())\n",
    "test['ps_car_10_cat_enc'] = test['ps_car_10_cat'].map(X.groupby('ps_car_10_cat').target.mean())\n",
    "test['ps_car_11_cat_enc'] = test['ps_car_11_cat'].map(X.groupby('ps_car_11_cat').target.mean())\n",
    "test['ps_car_01_cat_mod_enc'] = test['ps_car_01_cat_mod'].map(X.groupby('ps_car_01_cat_mod').target.mean())\n",
    "test['ps_car_02_cat_mod_enc'] = test['ps_car_02_cat_mod'].map(X.groupby('ps_car_02_cat_mod').target.mean())\n",
    "test['ps_car_07_cat_mod_enc'] = test['ps_car_07_cat_mod'].map(X.groupby('ps_car_07_cat_mod').target.mean())\n",
    "test['ps_car_09_cat_mod_enc'] = test['ps_car_09_cat_mod'].map(X.groupby('ps_car_09_cat_mod').target.mean())\n",
    "test['ps_ind_02_cat_mod_enc'] = test['ps_ind_02_cat_mod'].map(X.groupby('ps_ind_02_cat_mod').target.mean())\n",
    "test['ps_ind_04_cat_mod_enc'] = test['ps_ind_04_cat_mod'].map(X.groupby('ps_ind_04_cat_mod').target.mean())\n",
    "test['ps_ind_05_cat_mod_enc'] = test['ps_ind_05_cat_mod'].map(X.groupby('ps_ind_05_cat_mod').target.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_encoded = X[['ps_car_04_cat_enc','ps_car_06_cat_enc',\n",
    "                                               'ps_car_08_cat_enc','ps_car_10_cat_enc','ps_car_11_cat_enc',\n",
    "                                               'ps_car_01_cat_mod_enc','ps_car_02_cat_mod_enc',\n",
    "                                              'ps_car_07_cat_mod_enc','ps_car_09_cat_mod_enc',\n",
    "                                              'ps_ind_02_cat_mod_enc','ps_ind_04_cat_mod_enc',\n",
    "                                              'ps_ind_05_cat_mod_enc']].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(43388, 12)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_encoded.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_mean_encoded = test[['ps_car_04_cat_enc','ps_car_06_cat_enc',\n",
    "                                               'ps_car_08_cat_enc','ps_car_10_cat_enc','ps_car_11_cat_enc',\n",
    "                                               'ps_car_01_cat_mod_enc','ps_car_02_cat_mod_enc',\n",
    "                                              'ps_car_07_cat_mod_enc','ps_car_09_cat_mod_enc',\n",
    "                                              'ps_ind_02_cat_mod_enc','ps_ind_04_cat_mod_enc',\n",
    "                                              'ps_ind_05_cat_mod_enc']].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(892816, 12)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_mean_encoded.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_new = pd.concat([scaled_X, oh_df, mean_encoded], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(43388, 71)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_new.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_new = pd.concat([scaled_test_X, oh_df_test, test_mean_encoded], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "y=y.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X_new, y, test_size = 0.2, random_state = 123)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Also using a set of unscaled and unencoded values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_orig =train.drop(['id','target','ps_car_01_cat','ps_car_02_cat','ps_car_03_cat','ps_car_05_cat',\n",
    "                          'ps_car_07_cat','ps_car_09_cat','ps_car_11','ps_car_12','ps_car_14','ps_ind_02_cat',\n",
    "                          'ps_ind_04_cat','ps_ind_05_cat','ps_reg_03'], axis=1)\n",
    "y_orig = train['target']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dropping 'ps_calc' features which do not show any relationship with other features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "col_to_drop = list(X_orig.columns[X_orig.columns.str.startswith('ps_calc_')])\n",
    "X_orig = X_orig.drop(col_to_drop, axis=1)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_orig, X_test_orig, y_train_orig, y_test_orig = \\\n",
    "    train_test_split(X_orig, y_orig, test_size = 0.2, random_state = 123)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define Normalized Gini Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gini(actual, pred):\n",
    "    assert (len(actual) == len(pred))\n",
    "    all = np.asarray(np.c_[actual, pred, np.arange(len(actual))], dtype=np.float)\n",
    "    all = all[np.lexsort((all[:, 2], -1 * all[:, 1]))]\n",
    "    totalLosses = all[:, 0].sum()\n",
    "    giniSum = all[:, 0].cumsum().sum() / totalLosses\n",
    "\n",
    "    giniSum -= (len(actual) + 1) / 2.\n",
    "    return giniSum / len(actual)\n",
    "\n",
    "\n",
    "def gini_normalized(actual, pred):\n",
    "    return gini(actual, pred) / gini(actual, actual)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using predict method of sklearn Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = LogisticRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Supratik\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='warn',\n",
       "          n_jobs=None, penalty='l2', random_state=None, solver='warn',\n",
       "          tol=0.0001, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = lr.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    4515\n",
       "1    4163\n",
       "dtype: int64"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.Series(predictions).value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy_score:  0.5800875777828993\n",
      "confusion_matrix: \n",
      " [[2556 1685]\n",
      " [1959 2478]]\n",
      "classification_report: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.57      0.60      0.58      4241\n",
      "           1       0.60      0.56      0.58      4437\n",
      "\n",
      "   micro avg       0.58      0.58      0.58      8678\n",
      "   macro avg       0.58      0.58      0.58      8678\n",
      "weighted avg       0.58      0.58      0.58      8678\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"accuracy_score: \", accuracy_score(y_test, predictions))\n",
    "print(\"confusion_matrix: \\n\", confusion_matrix(y_test, predictions))\n",
    "print(\"classification_report: \\n\", classification_report(y_test, predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gini: 0.041, Max. Gini: 0.244, Normalized Gini: 0.166\n"
     ]
    }
   ],
   "source": [
    "gini_predictions = gini(y_test, predictions)\n",
    "gini_max = gini(y_test, y_test)\n",
    "ngini= gini_normalized(y_test, predictions)\n",
    "print('Gini: %.3f, Max. Gini: %.3f, Normalized Gini: %.3f' % (gini_predictions, gini_max, ngini))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using predict_proba method of sklearn Logistic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_probs = list(map(lambda x: x[1],lr.predict_proba(X_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_curve\n",
    "fpr, tpr, thresholds =roc_curve(y_test, predicted_probs)\n",
    "\n",
    "def cutoff_youdens_j(fpr,tpr,thresholds):\n",
    "    j_scores = tpr-fpr\n",
    "    j_ordered = sorted(zip(j_scores,thresholds))\n",
    "    return j_ordered[-1][1]\n",
    "\n",
    "threshold=cutoff_youdens_j(fpr,tpr,thresholds)\n",
    "\n",
    "print(threshold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions_new = list(map(lambda x: 1 if x > threshold else 0,predicted_probs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy_score:  0.5873473150495506\n",
      "confusion_matrix: \n",
      " [[2405 1836]\n",
      " [1745 2692]]\n",
      "classification_report: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.58      0.57      0.57      4241\n",
      "           1       0.59      0.61      0.60      4437\n",
      "\n",
      "   micro avg       0.59      0.59      0.59      8678\n",
      "   macro avg       0.59      0.59      0.59      8678\n",
      "weighted avg       0.59      0.59      0.59      8678\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"accuracy_score: \", accuracy_score(y_test, predictions_new))\n",
    "print(\"confusion_matrix: \\n\", confusion_matrix(y_test, predictions_new))\n",
    "print(\"classification_report: \\n\", classification_report(y_test, predictions_new))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gini: 0.057, Max. Gini: 0.244, Normalized Gini: 0.233\n"
     ]
    }
   ],
   "source": [
    "gini_predictions = gini(y_test, predicted_probs)\n",
    "gini_max = gini(y_test, y_test)\n",
    "ngini= gini_normalized(y_test, predicted_probs)\n",
    "print('Gini: %.3f, Max. Gini: %.3f, Normalized Gini: %.3f' % (gini_predictions, gini_max, ngini))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using predict method of statsmodels Logistic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "import statsmodels.formula.api as smf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.columns = ['psind01','psind03','psind14','psind15','psreg01','psreg02','pscar13','pscar15',\n",
    "                   'pscalc01','pscalc02','pscalc03','pscalc04','pscalc05','pscalc06','pscalc07',\n",
    "                   'pscalc08','pscalc09','pscalc10','pscalc11','pscalc12','pscalc13','pscalc14',\n",
    "                   'pscar11mod','pscar12mod','pscar14mod','OH0','OH1','OH2','OH3','OH4','OH5','OH6','OH7','OH8',\n",
    "                   'OH9','OH10','OH11','OH12','OH13','OH14','OH15','OH16','OH17','OH18','OH19','OH20','OH21',\n",
    "                   'OH22','OH23','OH24','OH25','OH26','OH27','OH28','OH29','OH30','OH31','OH32','OH33',\n",
    "                   'pscar04catenc','pscar06catenc','pscar08catenc','pscar10catenc','pscar11catenc',\n",
    "                   'pscar01catmodenc','pscar02catmodenc','pscar07catmodenc','pscar09catmodenc','psind02catmodenc',\n",
    "                   'psind04catmodenc','psind05catmodenc']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test.columns = ['psind01','psind03','psind14','psind15','psreg01','psreg02','pscar13','pscar15',\n",
    "                   'pscalc01','pscalc02','pscalc03','pscalc04','pscalc05','pscalc06','pscalc07',\n",
    "                   'pscalc08','pscalc09','pscalc10','pscalc11','pscalc12','pscalc13','pscalc14',\n",
    "                   'pscar11mod','pscar12mod','pscar14mod','OH0','OH1','OH2','OH3','OH4','OH5','OH6','OH7','OH8',\n",
    "                   'OH9','OH10','OH11','OH12','OH13','OH14','OH15','OH16','OH17','OH18','OH19','OH20','OH21',\n",
    "                   'OH22','OH23','OH24','OH25','OH26','OH27','OH28','OH29','OH30','OH31','OH32','OH33',\n",
    "                   'pscar04catenc','pscar06catenc','pscar08catenc','pscar10catenc','pscar11catenc',\n",
    "                   'pscar01catmodenc','pscar02catmodenc','pscar07catmodenc','pscar09catmodenc','psind02catmodenc',\n",
    "                   'psind04catmodenc','psind05catmodenc']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_new.columns = ['psind01','psind03','psind14','psind15','psreg01','psreg02','pscar13','pscar15',\n",
    "                   'pscalc01','pscalc02','pscalc03','pscalc04','pscalc05','pscalc06','pscalc07',\n",
    "                   'pscalc08','pscalc09','pscalc10','pscalc11','pscalc12','pscalc13','pscalc14',\n",
    "                   'pscar11mod','pscar12mod','pscar14mod','OH0','OH1','OH2','OH3','OH4','OH5','OH6','OH7','OH8',\n",
    "                   'OH9','OH10','OH11','OH12','OH13','OH14','OH15','OH16','OH17','OH18','OH19','OH20','OH21',\n",
    "                   'OH22','OH23','OH24','OH25','OH26','OH27','OH28','OH29','OH30','OH31','OH32','OH33',\n",
    "                   'pscar04catenc','pscar06catenc','pscar08catenc','pscar10catenc','pscar11catenc',\n",
    "                   'pscar01catmodenc','pscar02catmodenc','pscar07catmodenc','pscar09catmodenc','psind02catmodenc',\n",
    "                   'psind04catmodenc','psind05catmodenc']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_logistic = X_train.copy()\n",
    "X_train_logistic['target']=y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Maximum number of iterations has been exceeded.\n",
      "         Current function value: 0.666286\n",
      "         Iterations: 35\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Supratik\\Anaconda3\\lib\\site-packages\\statsmodels\\base\\model.py:508: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
      "  \"Check mle_retvals\", ConvergenceWarning)\n"
     ]
    }
   ],
   "source": [
    "model = '''target ~ psind01+psind03+psind14+psind15+psreg01+psreg02+pscar13+pscar15+\n",
    "                   pscalc01+pscalc02+pscalc03+pscalc04+pscalc05+pscalc06+pscalc07+\n",
    "                   pscalc08+pscalc09+pscalc10+pscalc11+pscalc12+pscalc13+pscalc14+\n",
    "                   pscar11mod+pscar12mod+pscar14mod+OH0+OH1+OH2+OH3+OH4+OH5+OH6+OH7+OH8+OH9+OH10+\n",
    "                   OH11+OH12+OH13+OH14+OH15+OH16+OH17+OH18+OH19+OH20+OH21+OH22+OH23+OH24+OH25+OH26+OH27+OH28+OH29+\n",
    "                   OH30+OH31+OH32+OH33+pscar04catenc+pscar06catenc+pscar08catenc+\n",
    "                   pscar10catenc+pscar11catenc+pscar01catmodenc+pscar02catmodenc+\n",
    "                   pscar07catmodenc+pscar09catmodenc+psind02catmodenc+psind04catmodenc+\n",
    "                   psind05catmodenc'''\n",
    "results = smf.logit(formula = model, data=X_train_logistic, missing='drop').fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                           Logit Regression Results                           \n",
      "==============================================================================\n",
      "Dep. Variable:                 target   No. Observations:                34710\n",
      "Model:                          Logit   Df Residuals:                    34657\n",
      "Method:                           MLE   Df Model:                           52\n",
      "Date:                Wed, 03 Jul 2019   Pseudo R-squ.:                 0.03873\n",
      "Time:                        21:42:14   Log-Likelihood:                -23127.\n",
      "converged:                      False   LL-Null:                       -24059.\n",
      "                                        LLR p-value:                     0.000\n",
      "====================================================================================\n",
      "                       coef    std err          z      P>|z|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------------\n",
      "Intercept           -1.0287        nan        nan        nan         nan         nan\n",
      "psind01              0.0341      0.012      2.754      0.006       0.010       0.058\n",
      "psind03              0.0445      0.012      3.744      0.000       0.021       0.068\n",
      "psind14             -0.1544        nan        nan        nan         nan         nan\n",
      "psind15             -0.1026      0.013     -7.976      0.000      -0.128      -0.077\n",
      "psreg01              0.0811      0.013      6.206      0.000       0.055       0.107\n",
      "psreg02              0.0551      0.013      4.102      0.000       0.029       0.082\n",
      "pscar13              0.0927      0.026      3.515      0.000       0.041       0.144\n",
      "pscar15              0.0425      0.016      2.711      0.007       0.012       0.073\n",
      "pscalc01             0.0199      0.011      1.798      0.072      -0.002       0.042\n",
      "pscalc02             0.0096      0.011      0.872      0.383      -0.012       0.031\n",
      "pscalc03             0.0066      0.011      0.600      0.549      -0.015       0.028\n",
      "pscalc04             0.0050      0.011      0.450      0.652      -0.017       0.027\n",
      "pscalc05             0.0047      0.011      0.427      0.669      -0.017       0.026\n",
      "pscalc06            -0.0003      0.011     -0.023      0.981      -0.022       0.021\n",
      "pscalc07             0.0023      0.011      0.206      0.837      -0.019       0.024\n",
      "pscalc08            -0.0091      0.011     -0.829      0.407      -0.031       0.012\n",
      "pscalc09            -0.0046      0.011     -0.413      0.679      -0.026       0.017\n",
      "pscalc10             0.0003      0.011      0.031      0.976      -0.021       0.022\n",
      "pscalc11            -0.0006      0.011     -0.052      0.959      -0.022       0.021\n",
      "pscalc12            -0.0058      0.011     -0.525      0.599      -0.027       0.016\n",
      "pscalc13            -0.0024      0.011     -0.215      0.830      -0.024       0.019\n",
      "pscalc14             0.0172      0.011      1.560      0.119      -0.004       0.039\n",
      "pscar11mod          -0.0151      0.012     -1.242      0.214      -0.039       0.009\n",
      "pscar12mod           0.0092      0.020      0.452      0.651      -0.031       0.049\n",
      "pscar14mod          -0.0762      0.015     -5.219      0.000      -0.105      -0.048\n",
      "OH0                 -0.7158   4.57e+05  -1.57e-06      1.000   -8.96e+05    8.96e+05\n",
      "OH1                 -0.3129        nan        nan        nan         nan         nan\n",
      "OH2                 -0.8322        nan        nan        nan         nan         nan\n",
      "OH3                 -0.1965        nan        nan        nan         nan         nan\n",
      "OH4                 -0.8069   5.58e+05  -1.45e-06      1.000   -1.09e+06    1.09e+06\n",
      "OH5                 -0.2218        nan        nan        nan         nan         nan\n",
      "OH6                 -0.7312        nan        nan        nan         nan         nan\n",
      "OH7                 -0.2975        nan        nan        nan         nan         nan\n",
      "OH8                 -0.6661    5.7e+05  -1.17e-06      1.000   -1.12e+06    1.12e+06\n",
      "OH9                 -0.3626        nan        nan        nan         nan         nan\n",
      "OH10                -0.9183   2.56e+04  -3.58e-05      1.000   -5.03e+04    5.03e+04\n",
      "OH11                -0.1104        nan        nan        nan         nan         nan\n",
      "OH12                -1.0800   2.39e+05  -4.53e-06      1.000   -4.68e+05    4.68e+05\n",
      "OH13                 0.0513        nan        nan        nan         nan         nan\n",
      "OH14                -1.4133    3.2e+05  -4.41e-06      1.000   -6.28e+05    6.28e+05\n",
      "OH15                 0.3846        nan        nan        nan         nan         nan\n",
      "OH16                -0.4614        nan        nan        nan         nan         nan\n",
      "OH17                -0.5673        nan        nan        nan         nan         nan\n",
      "OH18                -0.6563   7.95e+04  -8.26e-06      1.000   -1.56e+05    1.56e+05\n",
      "OH19                -0.3724   8.97e+04  -4.15e-06      1.000   -1.76e+05    1.76e+05\n",
      "OH20                -0.4982   1.54e+05  -3.23e-06      1.000   -3.02e+05    3.02e+05\n",
      "OH21                -0.5305   1.58e+05  -3.37e-06      1.000   -3.09e+05    3.09e+05\n",
      "OH22                -0.5228        nan        nan        nan         nan         nan\n",
      "OH23                -0.5058        nan        nan        nan         nan         nan\n",
      "OH24                -0.5109   3.25e+05  -1.57e-06      1.000   -6.38e+05    6.38e+05\n",
      "OH25                -0.5177   3.24e+05   -1.6e-06      1.000   -6.35e+05    6.35e+05\n",
      "OH26                -0.5045        nan        nan        nan         nan         nan\n",
      "OH27                -0.5242        nan        nan        nan         nan         nan\n",
      "OH28                -0.5038   1.16e+06  -4.34e-07      1.000   -2.28e+06    2.28e+06\n",
      "OH29                -0.5248   1.16e+06  -4.53e-07      1.000   -2.27e+06    2.27e+06\n",
      "OH30                -0.5082   3.85e+05  -1.32e-06      1.000   -7.55e+05    7.55e+05\n",
      "OH31                -0.5205   3.85e+05  -1.35e-06      1.000   -7.55e+05    7.55e+05\n",
      "OH32                -0.4869        nan        nan        nan         nan         nan\n",
      "OH33                -0.5418        nan        nan        nan         nan         nan\n",
      "pscar04catenc        0.1135      0.380      0.299      0.765      -0.631       0.858\n",
      "pscar06catenc       -0.3063      0.346     -0.886      0.376      -0.984       0.371\n",
      "pscar08catenc        0.7245      0.462      1.568      0.117      -0.181       1.630\n",
      "pscar10catenc        3.3555      2.245      1.495      0.135      -1.044       7.755\n",
      "pscar11catenc        2.1887      0.236      9.290      0.000       1.727       2.650\n",
      "pscar01catmodenc     1.8977      0.250      7.580      0.000       1.407       2.388\n",
      "pscar02catmodenc     0.4772      0.359      1.330      0.184      -0.226       1.181\n",
      "pscar07catmodenc     2.8331      0.566      5.006      0.000       1.724       3.942\n",
      "pscar09catmodenc     2.0042      0.373      5.379      0.000       1.274       2.734\n",
      "psind02catmodenc     5.7824      1.346      4.297      0.000       3.145       8.420\n",
      "psind04catmodenc     1.5421      0.901      1.712      0.087      -0.223       3.308\n",
      "psind05catmodenc     4.1369      0.285     14.517      0.000       3.578       4.695\n",
      "====================================================================================\n"
     ]
    }
   ],
   "source": [
    "print(results.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5002111834572159\n"
     ]
    }
   ],
   "source": [
    "pred_prob_stat = results.predict(X_test)\n",
    "\n",
    "fpr, tpr, thresholds =roc_curve(y_test, pred_prob_stat)\n",
    "\n",
    "threshold=cutoff_youdens_j(fpr,tpr,thresholds)\n",
    "\n",
    "print(threshold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions_stats = list(map(lambda x: 1 if x > threshold else 0,pred_prob_stat))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy_score:  0.5858492740262733\n",
      "confusion_matrix: \n",
      " [[2596 1645]\n",
      " [1949 2488]]\n",
      "classification_report: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.57      0.61      0.59      4241\n",
      "           1       0.60      0.56      0.58      4437\n",
      "\n",
      "   micro avg       0.59      0.59      0.59      8678\n",
      "   macro avg       0.59      0.59      0.59      8678\n",
      "weighted avg       0.59      0.59      0.59      8678\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"accuracy_score: \", accuracy_score(y_test, predictions_stats))\n",
    "print(\"confusion_matrix: \\n\", confusion_matrix(y_test, predictions_stats))\n",
    "print(\"classification_report: \\n\", classification_report(y_test, predictions_stats))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gini: 0.043, Max. Gini: 0.244, Normalized Gini: 0.178\n"
     ]
    }
   ],
   "source": [
    "# Gini with target 1/0\n",
    "gini_predictions = gini(y_test, predictions_stats)\n",
    "gini_max = gini(y_test, y_test)\n",
    "ngini= gini_normalized(y_test, predictions_stats)\n",
    "print('Gini: %.3f, Max. Gini: %.3f, Normalized Gini: %.3f' % (gini_predictions, gini_max, ngini))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gini: 0.057, Max. Gini: 0.244, Normalized Gini: 0.235\n"
     ]
    }
   ],
   "source": [
    "# Gini with predicted probabilities\n",
    "gini_predictions = gini(y_test, pred_prob_stat)\n",
    "gini_max = gini(y_test, y_test)\n",
    "ngini= gini_normalized(y_test, pred_prob_stat)\n",
    "print('Gini: %.3f, Max. Gini: %.3f, Normalized Gini: %.3f' % (gini_predictions, gini_max, ngini))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_pred = results.predict(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission = pd.concat([test['id'], pd.DataFrame({'target':test_pred})], axis=1)\n",
    "submission.to_csv('submission.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using Random Forest Classifier on all variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [],
   "source": [
    "RF = RandomForestClassifier(\n",
    "    n_estimators=1000,\n",
    "    criterion='gini',\n",
    "    max_depth=2**10,\n",
    "    min_samples_split=2,\n",
    "    min_samples_leaf=0.02,\n",
    "    min_weight_fraction_leaf=0.0,\n",
    "    max_features=0.8,\n",
    "    max_leaf_nodes=None,\n",
    "    n_jobs=-1,\n",
    "    random_state=123,\n",
    "    verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  42 tasks      | elapsed:    2.6s\n",
      "[Parallel(n_jobs=-1)]: Done 192 tasks      | elapsed:   13.6s\n",
      "[Parallel(n_jobs=-1)]: Done 442 tasks      | elapsed:   34.3s\n",
      "[Parallel(n_jobs=-1)]: Done 792 tasks      | elapsed:   56.1s\n",
      "[Parallel(n_jobs=-1)]: Done 1000 out of 1000 | elapsed:  1.1min finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=1024, max_features=0.8, max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=0.02, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, n_estimators=1000, n_jobs=-1,\n",
       "            oob_score=False, random_state=123, verbose=1, warm_start=False)"
      ]
     },
     "execution_count": 197,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "RF.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=4)]: Using backend ThreadingBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=4)]: Done 442 tasks      | elapsed:    0.2s\n",
      "[Parallel(n_jobs=4)]: Done 792 tasks      | elapsed:    0.4s\n",
      "[Parallel(n_jobs=4)]: Done 1000 out of 1000 | elapsed:    0.5s finished\n"
     ]
    }
   ],
   "source": [
    "RF_preds = RF.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy_score:  0.5795114081585618\n",
      "confusion_matrix: \n",
      " [[2549 1692]\n",
      " [1957 2480]]\n",
      "classification_report: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.57      0.60      0.58      4241\n",
      "           1       0.59      0.56      0.58      4437\n",
      "\n",
      "   micro avg       0.58      0.58      0.58      8678\n",
      "   macro avg       0.58      0.58      0.58      8678\n",
      "weighted avg       0.58      0.58      0.58      8678\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"accuracy_score: \", accuracy_score(y_test, RF_preds))\n",
    "print(\"confusion_matrix: \\n\", confusion_matrix(y_test, RF_preds))\n",
    "print(\"classification_report: \\n\", classification_report(y_test, RF_preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gini: 0.040, Max. Gini: 0.244, Normalized Gini: 0.166\n"
     ]
    }
   ],
   "source": [
    "gini_predictions = gini(y_test, RF_preds)\n",
    "gini_max = gini(y_test, y_test)\n",
    "ngini= gini_normalized(y_test, RF_preds)\n",
    "print('Gini: %.3f, Max. Gini: %.3f, Normalized Gini: %.3f' % (gini_predictions, gini_max, ngini))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=4)]: Using backend ThreadingBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 442 tasks      | elapsed:    0.2s\n",
      "[Parallel(n_jobs=4)]: Done 792 tasks      | elapsed:    0.4s\n",
      "[Parallel(n_jobs=4)]: Done 1000 out of 1000 | elapsed:    0.5s finished\n"
     ]
    }
   ],
   "source": [
    "RF_pred_prob = list(map(lambda x: x[1],RF.predict_proba(X_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gini: 0.056, Max. Gini: 0.244, Normalized Gini: 0.229\n"
     ]
    }
   ],
   "source": [
    "gini_predictions = gini(y_test, RF_pred_prob)\n",
    "gini_max = gini(y_test, y_test)\n",
    "ngini= gini_normalized(y_test, RF_pred_prob)\n",
    "print('Gini: %.3f, Max. Gini: %.3f, Normalized Gini: %.3f' % (gini_predictions, gini_max, ngini))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=4)]: Using backend ThreadingBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    2.0s\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:    9.2s\n",
      "[Parallel(n_jobs=4)]: Done 442 tasks      | elapsed:   22.0s\n",
      "[Parallel(n_jobs=4)]: Done 792 tasks      | elapsed:   39.2s\n",
      "[Parallel(n_jobs=4)]: Done 1000 out of 1000 | elapsed:   50.2s finished\n"
     ]
    }
   ],
   "source": [
    "test_pred = RF.predict(test.drop(['id','ps_car_01_cat','ps_car_02_cat','ps_car_03_cat','ps_car_05_cat',\n",
    "                          'ps_car_07_cat','ps_car_09_cat','ps_car_11','ps_car_12','ps_car_14','ps_ind_02_cat',\n",
    "                          'ps_ind_04_cat','ps_ind_05_cat','ps_reg_03'], axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission = pd.concat([test['id'], pd.DataFrame({'target':test_pred})], axis=1)\n",
    "submission.to_csv('submission.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using XGBoost Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install xgboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost as xgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up classifier\n",
    "xg_cl = xgb.XGBClassifier(    \n",
    "                        n_estimators=500, #172\n",
    "                        max_depth=4,\n",
    "                        objective=\"binary:logistic\",\n",
    "                        learning_rate=0.07, \n",
    "                        subsample=.8,\n",
    "                        min_child_weight=6,\n",
    "                        colsample_bytree=.8,\n",
    "                        scale_pos_weight=1,\n",
    "                        gamma=10,\n",
    "                        reg_alpha=8,\n",
    "                        reg_lambda=1.3,\n",
    "                        random_state=123\n",
    "                        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'xg_cl = xgb.XGBClassifier(n_estimators=200,\\n                        max_depth=4,\\n                        objective=\"binary:logistic\",\\n                        learning_rate=.1, \\n                        subsample=.8, \\n                        colsample_bytree=.8,\\n                        gamma=1,\\n                        reg_alpha=0,\\n                        reg_lambda=1,\\n                        nthread=2)'"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''xg_cl = xgb.XGBClassifier(n_estimators=200,\n",
    "                        max_depth=4,\n",
    "                        objective=\"binary:logistic\",\n",
    "                        learning_rate=.1, \n",
    "                        subsample=.8, \n",
    "                        colsample_bytree=.8,\n",
    "                        gamma=1,\n",
    "                        reg_alpha=0,\n",
    "                        reg_lambda=1,\n",
    "                        nthread=2)'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gini_xgb(preds, dtrain):\n",
    "    labels = dtrain.get_label()\n",
    "    gini_score = 1 - gini_normalized(labels, preds)\n",
    "    return [('gini', gini_score)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\tvalidation_0-error:0.036197\tvalidation_1-error:0.037449\tvalidation_0-gini:0.934294\tvalidation_1-gini:0.903067\n",
      "Multiple eval metrics have been passed: 'validation_1-gini' will be used for early stopping.\n",
      "\n",
      "Will train until validation_1-gini hasn't improved in 50 rounds.\n",
      "[1]\tvalidation_0-error:0.036197\tvalidation_1-error:0.037449\tvalidation_0-gini:0.891728\tvalidation_1-gini:0.861215\n",
      "[2]\tvalidation_0-error:0.036197\tvalidation_1-error:0.037449\tvalidation_0-gini:0.830153\tvalidation_1-gini:0.813576\n",
      "[3]\tvalidation_0-error:0.036197\tvalidation_1-error:0.037449\tvalidation_0-gini:0.820547\tvalidation_1-gini:0.805174\n",
      "[4]\tvalidation_0-error:0.036197\tvalidation_1-error:0.037449\tvalidation_0-gini:0.815579\tvalidation_1-gini:0.805589\n",
      "[5]\tvalidation_0-error:0.036197\tvalidation_1-error:0.037449\tvalidation_0-gini:0.805036\tvalidation_1-gini:0.795314\n",
      "[6]\tvalidation_0-error:0.036197\tvalidation_1-error:0.037449\tvalidation_0-gini:0.805701\tvalidation_1-gini:0.795406\n",
      "[7]\tvalidation_0-error:0.036197\tvalidation_1-error:0.037449\tvalidation_0-gini:0.797709\tvalidation_1-gini:0.78892\n",
      "[8]\tvalidation_0-error:0.036197\tvalidation_1-error:0.037449\tvalidation_0-gini:0.792718\tvalidation_1-gini:0.78504\n",
      "[9]\tvalidation_0-error:0.036197\tvalidation_1-error:0.037449\tvalidation_0-gini:0.793514\tvalidation_1-gini:0.786943\n",
      "[10]\tvalidation_0-error:0.036197\tvalidation_1-error:0.037449\tvalidation_0-gini:0.796133\tvalidation_1-gini:0.789096\n",
      "[11]\tvalidation_0-error:0.036197\tvalidation_1-error:0.037449\tvalidation_0-gini:0.796343\tvalidation_1-gini:0.789751\n",
      "[12]\tvalidation_0-error:0.036197\tvalidation_1-error:0.037449\tvalidation_0-gini:0.796781\tvalidation_1-gini:0.790183\n",
      "[13]\tvalidation_0-error:0.036197\tvalidation_1-error:0.037449\tvalidation_0-gini:0.794758\tvalidation_1-gini:0.787011\n",
      "[14]\tvalidation_0-error:0.036197\tvalidation_1-error:0.037449\tvalidation_0-gini:0.787791\tvalidation_1-gini:0.782176\n",
      "[15]\tvalidation_0-error:0.036197\tvalidation_1-error:0.037449\tvalidation_0-gini:0.785377\tvalidation_1-gini:0.78044\n",
      "[16]\tvalidation_0-error:0.036197\tvalidation_1-error:0.037449\tvalidation_0-gini:0.784609\tvalidation_1-gini:0.781135\n",
      "[17]\tvalidation_0-error:0.036197\tvalidation_1-error:0.037449\tvalidation_0-gini:0.783989\tvalidation_1-gini:0.781419\n",
      "[18]\tvalidation_0-error:0.036197\tvalidation_1-error:0.037449\tvalidation_0-gini:0.781821\tvalidation_1-gini:0.7797\n",
      "[19]\tvalidation_0-error:0.036197\tvalidation_1-error:0.037449\tvalidation_0-gini:0.780432\tvalidation_1-gini:0.778013\n",
      "[20]\tvalidation_0-error:0.036197\tvalidation_1-error:0.037449\tvalidation_0-gini:0.780153\tvalidation_1-gini:0.779059\n",
      "[21]\tvalidation_0-error:0.036197\tvalidation_1-error:0.037449\tvalidation_0-gini:0.780641\tvalidation_1-gini:0.778889\n",
      "[22]\tvalidation_0-error:0.036197\tvalidation_1-error:0.037449\tvalidation_0-gini:0.779875\tvalidation_1-gini:0.779201\n",
      "[23]\tvalidation_0-error:0.036197\tvalidation_1-error:0.037449\tvalidation_0-gini:0.774092\tvalidation_1-gini:0.774827\n",
      "[24]\tvalidation_0-error:0.036197\tvalidation_1-error:0.037449\tvalidation_0-gini:0.773885\tvalidation_1-gini:0.773975\n",
      "[25]\tvalidation_0-error:0.036197\tvalidation_1-error:0.037449\tvalidation_0-gini:0.774095\tvalidation_1-gini:0.774618\n",
      "[26]\tvalidation_0-error:0.036197\tvalidation_1-error:0.037449\tvalidation_0-gini:0.77293\tvalidation_1-gini:0.774945\n",
      "[27]\tvalidation_0-error:0.036197\tvalidation_1-error:0.037449\tvalidation_0-gini:0.771342\tvalidation_1-gini:0.773949\n",
      "[28]\tvalidation_0-error:0.036197\tvalidation_1-error:0.037449\tvalidation_0-gini:0.769192\tvalidation_1-gini:0.772353\n",
      "[29]\tvalidation_0-error:0.036197\tvalidation_1-error:0.037449\tvalidation_0-gini:0.768924\tvalidation_1-gini:0.771942\n",
      "[30]\tvalidation_0-error:0.036197\tvalidation_1-error:0.037449\tvalidation_0-gini:0.767586\tvalidation_1-gini:0.771164\n",
      "[31]\tvalidation_0-error:0.036197\tvalidation_1-error:0.037449\tvalidation_0-gini:0.766126\tvalidation_1-gini:0.769759\n",
      "[32]\tvalidation_0-error:0.036197\tvalidation_1-error:0.037449\tvalidation_0-gini:0.763276\tvalidation_1-gini:0.767253\n",
      "[33]\tvalidation_0-error:0.036197\tvalidation_1-error:0.037449\tvalidation_0-gini:0.761822\tvalidation_1-gini:0.765448\n",
      "[34]\tvalidation_0-error:0.036197\tvalidation_1-error:0.037449\tvalidation_0-gini:0.761432\tvalidation_1-gini:0.765395\n",
      "[35]\tvalidation_0-error:0.036197\tvalidation_1-error:0.037449\tvalidation_0-gini:0.759971\tvalidation_1-gini:0.76422\n",
      "[36]\tvalidation_0-error:0.036197\tvalidation_1-error:0.037449\tvalidation_0-gini:0.759659\tvalidation_1-gini:0.764267\n",
      "[37]\tvalidation_0-error:0.036197\tvalidation_1-error:0.037449\tvalidation_0-gini:0.759559\tvalidation_1-gini:0.764706\n",
      "[38]\tvalidation_0-error:0.036197\tvalidation_1-error:0.037449\tvalidation_0-gini:0.759225\tvalidation_1-gini:0.764617\n",
      "[39]\tvalidation_0-error:0.036197\tvalidation_1-error:0.037449\tvalidation_0-gini:0.75865\tvalidation_1-gini:0.764735\n",
      "[40]\tvalidation_0-error:0.036197\tvalidation_1-error:0.037449\tvalidation_0-gini:0.756295\tvalidation_1-gini:0.76167\n",
      "[41]\tvalidation_0-error:0.036197\tvalidation_1-error:0.037449\tvalidation_0-gini:0.755843\tvalidation_1-gini:0.761368\n",
      "[42]\tvalidation_0-error:0.036197\tvalidation_1-error:0.037449\tvalidation_0-gini:0.754632\tvalidation_1-gini:0.760056\n",
      "[43]\tvalidation_0-error:0.036197\tvalidation_1-error:0.037449\tvalidation_0-gini:0.754096\tvalidation_1-gini:0.759466\n",
      "[44]\tvalidation_0-error:0.036197\tvalidation_1-error:0.037449\tvalidation_0-gini:0.753085\tvalidation_1-gini:0.758786\n",
      "[45]\tvalidation_0-error:0.036197\tvalidation_1-error:0.037449\tvalidation_0-gini:0.751497\tvalidation_1-gini:0.757706\n",
      "[46]\tvalidation_0-error:0.036197\tvalidation_1-error:0.037449\tvalidation_0-gini:0.751483\tvalidation_1-gini:0.757247\n",
      "[47]\tvalidation_0-error:0.036197\tvalidation_1-error:0.037449\tvalidation_0-gini:0.750431\tvalidation_1-gini:0.756645\n",
      "[48]\tvalidation_0-error:0.036197\tvalidation_1-error:0.037449\tvalidation_0-gini:0.74983\tvalidation_1-gini:0.756539\n",
      "[49]\tvalidation_0-error:0.036197\tvalidation_1-error:0.037449\tvalidation_0-gini:0.748763\tvalidation_1-gini:0.756023\n",
      "[50]\tvalidation_0-error:0.036197\tvalidation_1-error:0.037449\tvalidation_0-gini:0.747521\tvalidation_1-gini:0.755428\n",
      "[51]\tvalidation_0-error:0.036197\tvalidation_1-error:0.037449\tvalidation_0-gini:0.74624\tvalidation_1-gini:0.754427\n",
      "[52]\tvalidation_0-error:0.036197\tvalidation_1-error:0.037449\tvalidation_0-gini:0.744501\tvalidation_1-gini:0.752877\n",
      "[53]\tvalidation_0-error:0.036197\tvalidation_1-error:0.037449\tvalidation_0-gini:0.743056\tvalidation_1-gini:0.751365\n",
      "[54]\tvalidation_0-error:0.036197\tvalidation_1-error:0.037449\tvalidation_0-gini:0.741861\tvalidation_1-gini:0.750346\n",
      "[55]\tvalidation_0-error:0.036197\tvalidation_1-error:0.037449\tvalidation_0-gini:0.74022\tvalidation_1-gini:0.748502\n",
      "[56]\tvalidation_0-error:0.036197\tvalidation_1-error:0.037449\tvalidation_0-gini:0.739373\tvalidation_1-gini:0.74797\n",
      "[57]\tvalidation_0-error:0.036197\tvalidation_1-error:0.037449\tvalidation_0-gini:0.737888\tvalidation_1-gini:0.746725\n",
      "[58]\tvalidation_0-error:0.036197\tvalidation_1-error:0.037449\tvalidation_0-gini:0.737454\tvalidation_1-gini:0.746593\n",
      "[59]\tvalidation_0-error:0.036197\tvalidation_1-error:0.037449\tvalidation_0-gini:0.736849\tvalidation_1-gini:0.745951\n",
      "[60]\tvalidation_0-error:0.036197\tvalidation_1-error:0.037449\tvalidation_0-gini:0.735072\tvalidation_1-gini:0.744207\n",
      "[61]\tvalidation_0-error:0.036197\tvalidation_1-error:0.037449\tvalidation_0-gini:0.734403\tvalidation_1-gini:0.743969\n",
      "[62]\tvalidation_0-error:0.036197\tvalidation_1-error:0.037449\tvalidation_0-gini:0.733771\tvalidation_1-gini:0.743394\n",
      "[63]\tvalidation_0-error:0.036197\tvalidation_1-error:0.037449\tvalidation_0-gini:0.733177\tvalidation_1-gini:0.742751\n",
      "[64]\tvalidation_0-error:0.036197\tvalidation_1-error:0.037449\tvalidation_0-gini:0.732133\tvalidation_1-gini:0.741724\n",
      "[65]\tvalidation_0-error:0.036197\tvalidation_1-error:0.037449\tvalidation_0-gini:0.730533\tvalidation_1-gini:0.740642\n",
      "[66]\tvalidation_0-error:0.036197\tvalidation_1-error:0.037449\tvalidation_0-gini:0.729811\tvalidation_1-gini:0.740049\n",
      "[67]\tvalidation_0-error:0.036197\tvalidation_1-error:0.037449\tvalidation_0-gini:0.729236\tvalidation_1-gini:0.739765\n",
      "[68]\tvalidation_0-error:0.036197\tvalidation_1-error:0.037449\tvalidation_0-gini:0.728813\tvalidation_1-gini:0.739242\n",
      "[69]\tvalidation_0-error:0.036197\tvalidation_1-error:0.037449\tvalidation_0-gini:0.728052\tvalidation_1-gini:0.73877\n",
      "[70]\tvalidation_0-error:0.036197\tvalidation_1-error:0.037449\tvalidation_0-gini:0.727503\tvalidation_1-gini:0.738317\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[71]\tvalidation_0-error:0.036197\tvalidation_1-error:0.037449\tvalidation_0-gini:0.726664\tvalidation_1-gini:0.737385\n",
      "[72]\tvalidation_0-error:0.036197\tvalidation_1-error:0.037449\tvalidation_0-gini:0.725593\tvalidation_1-gini:0.736604\n",
      "[73]\tvalidation_0-error:0.036197\tvalidation_1-error:0.037449\tvalidation_0-gini:0.724843\tvalidation_1-gini:0.73609\n",
      "[74]\tvalidation_0-error:0.036197\tvalidation_1-error:0.037449\tvalidation_0-gini:0.724296\tvalidation_1-gini:0.736099\n",
      "[75]\tvalidation_0-error:0.036197\tvalidation_1-error:0.037449\tvalidation_0-gini:0.723468\tvalidation_1-gini:0.73552\n",
      "[76]\tvalidation_0-error:0.036197\tvalidation_1-error:0.037449\tvalidation_0-gini:0.723172\tvalidation_1-gini:0.735327\n",
      "[77]\tvalidation_0-error:0.036197\tvalidation_1-error:0.037449\tvalidation_0-gini:0.722626\tvalidation_1-gini:0.734761\n",
      "[78]\tvalidation_0-error:0.036197\tvalidation_1-error:0.037449\tvalidation_0-gini:0.722406\tvalidation_1-gini:0.734541\n",
      "[79]\tvalidation_0-error:0.036197\tvalidation_1-error:0.037449\tvalidation_0-gini:0.721929\tvalidation_1-gini:0.734041\n",
      "[80]\tvalidation_0-error:0.036197\tvalidation_1-error:0.037449\tvalidation_0-gini:0.7209\tvalidation_1-gini:0.73353\n",
      "[81]\tvalidation_0-error:0.036197\tvalidation_1-error:0.037449\tvalidation_0-gini:0.720681\tvalidation_1-gini:0.733501\n",
      "[82]\tvalidation_0-error:0.036197\tvalidation_1-error:0.037449\tvalidation_0-gini:0.720409\tvalidation_1-gini:0.733142\n",
      "[83]\tvalidation_0-error:0.036197\tvalidation_1-error:0.037449\tvalidation_0-gini:0.719752\tvalidation_1-gini:0.732267\n",
      "[84]\tvalidation_0-error:0.036197\tvalidation_1-error:0.037449\tvalidation_0-gini:0.719498\tvalidation_1-gini:0.731967\n",
      "[85]\tvalidation_0-error:0.036197\tvalidation_1-error:0.037449\tvalidation_0-gini:0.719156\tvalidation_1-gini:0.73161\n",
      "[86]\tvalidation_0-error:0.036197\tvalidation_1-error:0.037449\tvalidation_0-gini:0.718337\tvalidation_1-gini:0.731116\n",
      "[87]\tvalidation_0-error:0.036197\tvalidation_1-error:0.037449\tvalidation_0-gini:0.718034\tvalidation_1-gini:0.730797\n",
      "[88]\tvalidation_0-error:0.036197\tvalidation_1-error:0.037449\tvalidation_0-gini:0.717629\tvalidation_1-gini:0.730296\n",
      "[89]\tvalidation_0-error:0.036197\tvalidation_1-error:0.037449\tvalidation_0-gini:0.717334\tvalidation_1-gini:0.729983\n",
      "[90]\tvalidation_0-error:0.036197\tvalidation_1-error:0.037449\tvalidation_0-gini:0.716638\tvalidation_1-gini:0.729589\n",
      "[91]\tvalidation_0-error:0.036197\tvalidation_1-error:0.037449\tvalidation_0-gini:0.716596\tvalidation_1-gini:0.729556\n",
      "[92]\tvalidation_0-error:0.036197\tvalidation_1-error:0.037449\tvalidation_0-gini:0.716387\tvalidation_1-gini:0.729524\n",
      "[93]\tvalidation_0-error:0.036197\tvalidation_1-error:0.037449\tvalidation_0-gini:0.715771\tvalidation_1-gini:0.729179\n",
      "[94]\tvalidation_0-error:0.036197\tvalidation_1-error:0.037449\tvalidation_0-gini:0.71522\tvalidation_1-gini:0.728937\n",
      "[95]\tvalidation_0-error:0.036197\tvalidation_1-error:0.037449\tvalidation_0-gini:0.714946\tvalidation_1-gini:0.728888\n",
      "[96]\tvalidation_0-error:0.036197\tvalidation_1-error:0.037449\tvalidation_0-gini:0.714934\tvalidation_1-gini:0.728807\n",
      "[97]\tvalidation_0-error:0.036197\tvalidation_1-error:0.037449\tvalidation_0-gini:0.714275\tvalidation_1-gini:0.728196\n",
      "[98]\tvalidation_0-error:0.036197\tvalidation_1-error:0.037449\tvalidation_0-gini:0.713919\tvalidation_1-gini:0.727792\n",
      "[99]\tvalidation_0-error:0.036197\tvalidation_1-error:0.037449\tvalidation_0-gini:0.713743\tvalidation_1-gini:0.727878\n",
      "[100]\tvalidation_0-error:0.036197\tvalidation_1-error:0.037449\tvalidation_0-gini:0.713649\tvalidation_1-gini:0.727782\n",
      "[101]\tvalidation_0-error:0.036197\tvalidation_1-error:0.037449\tvalidation_0-gini:0.713539\tvalidation_1-gini:0.727724\n",
      "[102]\tvalidation_0-error:0.036197\tvalidation_1-error:0.037449\tvalidation_0-gini:0.713101\tvalidation_1-gini:0.727444\n",
      "[103]\tvalidation_0-error:0.036197\tvalidation_1-error:0.037449\tvalidation_0-gini:0.712715\tvalidation_1-gini:0.727071\n",
      "[104]\tvalidation_0-error:0.036197\tvalidation_1-error:0.037449\tvalidation_0-gini:0.71242\tvalidation_1-gini:0.726667\n",
      "[105]\tvalidation_0-error:0.036197\tvalidation_1-error:0.037449\tvalidation_0-gini:0.71242\tvalidation_1-gini:0.726632\n",
      "[106]\tvalidation_0-error:0.036197\tvalidation_1-error:0.037449\tvalidation_0-gini:0.712048\tvalidation_1-gini:0.726349\n",
      "[107]\tvalidation_0-error:0.036197\tvalidation_1-error:0.037449\tvalidation_0-gini:0.71188\tvalidation_1-gini:0.72607\n",
      "[108]\tvalidation_0-error:0.036197\tvalidation_1-error:0.037449\tvalidation_0-gini:0.711608\tvalidation_1-gini:0.725869\n",
      "[109]\tvalidation_0-error:0.036197\tvalidation_1-error:0.037449\tvalidation_0-gini:0.711493\tvalidation_1-gini:0.725804\n",
      "[110]\tvalidation_0-error:0.036197\tvalidation_1-error:0.037449\tvalidation_0-gini:0.711208\tvalidation_1-gini:0.725556\n",
      "[111]\tvalidation_0-error:0.036197\tvalidation_1-error:0.037449\tvalidation_0-gini:0.711008\tvalidation_1-gini:0.725472\n",
      "[112]\tvalidation_0-error:0.036197\tvalidation_1-error:0.037449\tvalidation_0-gini:0.710746\tvalidation_1-gini:0.725149\n",
      "[113]\tvalidation_0-error:0.036197\tvalidation_1-error:0.037449\tvalidation_0-gini:0.710317\tvalidation_1-gini:0.724783\n",
      "[114]\tvalidation_0-error:0.036197\tvalidation_1-error:0.037449\tvalidation_0-gini:0.710035\tvalidation_1-gini:0.724451\n",
      "[115]\tvalidation_0-error:0.036197\tvalidation_1-error:0.037449\tvalidation_0-gini:0.709886\tvalidation_1-gini:0.724412\n",
      "[116]\tvalidation_0-error:0.036197\tvalidation_1-error:0.037449\tvalidation_0-gini:0.709797\tvalidation_1-gini:0.724405\n",
      "[117]\tvalidation_0-error:0.036197\tvalidation_1-error:0.037449\tvalidation_0-gini:0.709631\tvalidation_1-gini:0.724165\n",
      "[118]\tvalidation_0-error:0.036197\tvalidation_1-error:0.037449\tvalidation_0-gini:0.709414\tvalidation_1-gini:0.723953\n",
      "[119]\tvalidation_0-error:0.036197\tvalidation_1-error:0.037449\tvalidation_0-gini:0.709144\tvalidation_1-gini:0.723601\n",
      "[120]\tvalidation_0-error:0.036197\tvalidation_1-error:0.037449\tvalidation_0-gini:0.709025\tvalidation_1-gini:0.72337\n",
      "[121]\tvalidation_0-error:0.036197\tvalidation_1-error:0.037449\tvalidation_0-gini:0.708705\tvalidation_1-gini:0.723238\n",
      "[122]\tvalidation_0-error:0.036197\tvalidation_1-error:0.037449\tvalidation_0-gini:0.708653\tvalidation_1-gini:0.723138\n",
      "[123]\tvalidation_0-error:0.036197\tvalidation_1-error:0.037449\tvalidation_0-gini:0.708653\tvalidation_1-gini:0.723138\n",
      "[124]\tvalidation_0-error:0.036197\tvalidation_1-error:0.037449\tvalidation_0-gini:0.708562\tvalidation_1-gini:0.723101\n",
      "[125]\tvalidation_0-error:0.036197\tvalidation_1-error:0.037449\tvalidation_0-gini:0.708432\tvalidation_1-gini:0.722939\n",
      "[126]\tvalidation_0-error:0.036197\tvalidation_1-error:0.037449\tvalidation_0-gini:0.70841\tvalidation_1-gini:0.722887\n",
      "[127]\tvalidation_0-error:0.036197\tvalidation_1-error:0.037449\tvalidation_0-gini:0.708324\tvalidation_1-gini:0.722854\n",
      "[128]\tvalidation_0-error:0.036197\tvalidation_1-error:0.037449\tvalidation_0-gini:0.708189\tvalidation_1-gini:0.722629\n",
      "[129]\tvalidation_0-error:0.036197\tvalidation_1-error:0.037449\tvalidation_0-gini:0.708132\tvalidation_1-gini:0.722586\n",
      "[130]\tvalidation_0-error:0.036197\tvalidation_1-error:0.037449\tvalidation_0-gini:0.708056\tvalidation_1-gini:0.722581\n",
      "[131]\tvalidation_0-error:0.036197\tvalidation_1-error:0.037449\tvalidation_0-gini:0.707936\tvalidation_1-gini:0.72243\n",
      "[132]\tvalidation_0-error:0.036197\tvalidation_1-error:0.037449\tvalidation_0-gini:0.707731\tvalidation_1-gini:0.72238\n",
      "[133]\tvalidation_0-error:0.036197\tvalidation_1-error:0.037449\tvalidation_0-gini:0.707685\tvalidation_1-gini:0.722407\n",
      "[134]\tvalidation_0-error:0.036197\tvalidation_1-error:0.037449\tvalidation_0-gini:0.707566\tvalidation_1-gini:0.722235\n",
      "[135]\tvalidation_0-error:0.036197\tvalidation_1-error:0.037449\tvalidation_0-gini:0.707435\tvalidation_1-gini:0.722239\n",
      "[136]\tvalidation_0-error:0.036197\tvalidation_1-error:0.037449\tvalidation_0-gini:0.707222\tvalidation_1-gini:0.722164\n",
      "[137]\tvalidation_0-error:0.036197\tvalidation_1-error:0.037449\tvalidation_0-gini:0.706964\tvalidation_1-gini:0.721995\n",
      "[138]\tvalidation_0-error:0.036197\tvalidation_1-error:0.037449\tvalidation_0-gini:0.706799\tvalidation_1-gini:0.721732\n",
      "[139]\tvalidation_0-error:0.036197\tvalidation_1-error:0.037449\tvalidation_0-gini:0.706732\tvalidation_1-gini:0.721823\n",
      "[140]\tvalidation_0-error:0.036197\tvalidation_1-error:0.037449\tvalidation_0-gini:0.706559\tvalidation_1-gini:0.721678\n",
      "[141]\tvalidation_0-error:0.036197\tvalidation_1-error:0.037449\tvalidation_0-gini:0.706524\tvalidation_1-gini:0.721643\n",
      "[142]\tvalidation_0-error:0.036197\tvalidation_1-error:0.037449\tvalidation_0-gini:0.706342\tvalidation_1-gini:0.721542\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[143]\tvalidation_0-error:0.036197\tvalidation_1-error:0.037449\tvalidation_0-gini:0.705944\tvalidation_1-gini:0.721121\n",
      "[144]\tvalidation_0-error:0.036197\tvalidation_1-error:0.037449\tvalidation_0-gini:0.705679\tvalidation_1-gini:0.720957\n",
      "[145]\tvalidation_0-error:0.036197\tvalidation_1-error:0.037449\tvalidation_0-gini:0.705679\tvalidation_1-gini:0.720957\n",
      "[146]\tvalidation_0-error:0.036197\tvalidation_1-error:0.037449\tvalidation_0-gini:0.705679\tvalidation_1-gini:0.720957\n",
      "[147]\tvalidation_0-error:0.036197\tvalidation_1-error:0.037449\tvalidation_0-gini:0.705679\tvalidation_1-gini:0.720957\n",
      "[148]\tvalidation_0-error:0.036197\tvalidation_1-error:0.037449\tvalidation_0-gini:0.705565\tvalidation_1-gini:0.720851\n",
      "[149]\tvalidation_0-error:0.036197\tvalidation_1-error:0.037449\tvalidation_0-gini:0.705565\tvalidation_1-gini:0.720851\n",
      "[150]\tvalidation_0-error:0.036197\tvalidation_1-error:0.037449\tvalidation_0-gini:0.705565\tvalidation_1-gini:0.720851\n",
      "[151]\tvalidation_0-error:0.036197\tvalidation_1-error:0.037449\tvalidation_0-gini:0.705565\tvalidation_1-gini:0.720851\n",
      "[152]\tvalidation_0-error:0.036197\tvalidation_1-error:0.037449\tvalidation_0-gini:0.705565\tvalidation_1-gini:0.720851\n",
      "[153]\tvalidation_0-error:0.036197\tvalidation_1-error:0.037449\tvalidation_0-gini:0.705565\tvalidation_1-gini:0.720851\n",
      "[154]\tvalidation_0-error:0.036197\tvalidation_1-error:0.037449\tvalidation_0-gini:0.705565\tvalidation_1-gini:0.720851\n",
      "[155]\tvalidation_0-error:0.036197\tvalidation_1-error:0.037449\tvalidation_0-gini:0.70554\tvalidation_1-gini:0.720891\n",
      "[156]\tvalidation_0-error:0.036197\tvalidation_1-error:0.037449\tvalidation_0-gini:0.705487\tvalidation_1-gini:0.720866\n",
      "[157]\tvalidation_0-error:0.036197\tvalidation_1-error:0.037449\tvalidation_0-gini:0.705354\tvalidation_1-gini:0.720886\n",
      "[158]\tvalidation_0-error:0.036197\tvalidation_1-error:0.037449\tvalidation_0-gini:0.705354\tvalidation_1-gini:0.720886\n",
      "[159]\tvalidation_0-error:0.036197\tvalidation_1-error:0.037449\tvalidation_0-gini:0.705354\tvalidation_1-gini:0.720886\n",
      "[160]\tvalidation_0-error:0.036197\tvalidation_1-error:0.037449\tvalidation_0-gini:0.705218\tvalidation_1-gini:0.720822\n",
      "[161]\tvalidation_0-error:0.036197\tvalidation_1-error:0.037449\tvalidation_0-gini:0.705106\tvalidation_1-gini:0.720736\n",
      "[162]\tvalidation_0-error:0.036197\tvalidation_1-error:0.037449\tvalidation_0-gini:0.705106\tvalidation_1-gini:0.720736\n",
      "[163]\tvalidation_0-error:0.036197\tvalidation_1-error:0.037449\tvalidation_0-gini:0.705106\tvalidation_1-gini:0.720736\n",
      "[164]\tvalidation_0-error:0.036197\tvalidation_1-error:0.037449\tvalidation_0-gini:0.705106\tvalidation_1-gini:0.720736\n",
      "[165]\tvalidation_0-error:0.036197\tvalidation_1-error:0.037449\tvalidation_0-gini:0.705106\tvalidation_1-gini:0.720736\n",
      "[166]\tvalidation_0-error:0.036197\tvalidation_1-error:0.037449\tvalidation_0-gini:0.705106\tvalidation_1-gini:0.720736\n",
      "[167]\tvalidation_0-error:0.036197\tvalidation_1-error:0.037449\tvalidation_0-gini:0.705106\tvalidation_1-gini:0.720736\n",
      "[168]\tvalidation_0-error:0.036197\tvalidation_1-error:0.037449\tvalidation_0-gini:0.705106\tvalidation_1-gini:0.720736\n",
      "[169]\tvalidation_0-error:0.036197\tvalidation_1-error:0.037449\tvalidation_0-gini:0.705046\tvalidation_1-gini:0.720735\n",
      "[170]\tvalidation_0-error:0.036197\tvalidation_1-error:0.037449\tvalidation_0-gini:0.705013\tvalidation_1-gini:0.72073\n",
      "[171]\tvalidation_0-error:0.036197\tvalidation_1-error:0.037449\tvalidation_0-gini:0.705013\tvalidation_1-gini:0.72073\n",
      "[172]\tvalidation_0-error:0.036197\tvalidation_1-error:0.037449\tvalidation_0-gini:0.704811\tvalidation_1-gini:0.720706\n",
      "[173]\tvalidation_0-error:0.036197\tvalidation_1-error:0.037449\tvalidation_0-gini:0.704646\tvalidation_1-gini:0.720498\n",
      "[174]\tvalidation_0-error:0.036197\tvalidation_1-error:0.037449\tvalidation_0-gini:0.704646\tvalidation_1-gini:0.720498\n",
      "[175]\tvalidation_0-error:0.036197\tvalidation_1-error:0.037449\tvalidation_0-gini:0.704511\tvalidation_1-gini:0.720506\n",
      "[176]\tvalidation_0-error:0.036197\tvalidation_1-error:0.037449\tvalidation_0-gini:0.704511\tvalidation_1-gini:0.720506\n",
      "[177]\tvalidation_0-error:0.036197\tvalidation_1-error:0.037449\tvalidation_0-gini:0.704511\tvalidation_1-gini:0.720506\n",
      "[178]\tvalidation_0-error:0.036197\tvalidation_1-error:0.037449\tvalidation_0-gini:0.704414\tvalidation_1-gini:0.720479\n",
      "[179]\tvalidation_0-error:0.036197\tvalidation_1-error:0.037449\tvalidation_0-gini:0.704414\tvalidation_1-gini:0.720479\n",
      "[180]\tvalidation_0-error:0.036197\tvalidation_1-error:0.037449\tvalidation_0-gini:0.704414\tvalidation_1-gini:0.720479\n",
      "[181]\tvalidation_0-error:0.036197\tvalidation_1-error:0.037449\tvalidation_0-gini:0.704414\tvalidation_1-gini:0.720479\n",
      "[182]\tvalidation_0-error:0.036197\tvalidation_1-error:0.037449\tvalidation_0-gini:0.704374\tvalidation_1-gini:0.720403\n",
      "[183]\tvalidation_0-error:0.036197\tvalidation_1-error:0.037449\tvalidation_0-gini:0.704374\tvalidation_1-gini:0.720403\n",
      "[184]\tvalidation_0-error:0.036197\tvalidation_1-error:0.037449\tvalidation_0-gini:0.704374\tvalidation_1-gini:0.720403\n",
      "[185]\tvalidation_0-error:0.036197\tvalidation_1-error:0.037449\tvalidation_0-gini:0.704299\tvalidation_1-gini:0.72024\n",
      "[186]\tvalidation_0-error:0.036197\tvalidation_1-error:0.037449\tvalidation_0-gini:0.704299\tvalidation_1-gini:0.72024\n",
      "[187]\tvalidation_0-error:0.036197\tvalidation_1-error:0.037449\tvalidation_0-gini:0.704299\tvalidation_1-gini:0.72024\n",
      "[188]\tvalidation_0-error:0.036197\tvalidation_1-error:0.037449\tvalidation_0-gini:0.704299\tvalidation_1-gini:0.72024\n",
      "[189]\tvalidation_0-error:0.036197\tvalidation_1-error:0.037449\tvalidation_0-gini:0.704299\tvalidation_1-gini:0.72024\n",
      "[190]\tvalidation_0-error:0.036197\tvalidation_1-error:0.037449\tvalidation_0-gini:0.704299\tvalidation_1-gini:0.72024\n",
      "[191]\tvalidation_0-error:0.036197\tvalidation_1-error:0.037449\tvalidation_0-gini:0.704299\tvalidation_1-gini:0.72024\n",
      "[192]\tvalidation_0-error:0.036197\tvalidation_1-error:0.037449\tvalidation_0-gini:0.704299\tvalidation_1-gini:0.72024\n",
      "[193]\tvalidation_0-error:0.036197\tvalidation_1-error:0.037449\tvalidation_0-gini:0.704182\tvalidation_1-gini:0.720197\n",
      "[194]\tvalidation_0-error:0.036197\tvalidation_1-error:0.037449\tvalidation_0-gini:0.704182\tvalidation_1-gini:0.720197\n",
      "[195]\tvalidation_0-error:0.036197\tvalidation_1-error:0.037449\tvalidation_0-gini:0.704182\tvalidation_1-gini:0.720197\n",
      "[196]\tvalidation_0-error:0.036197\tvalidation_1-error:0.037449\tvalidation_0-gini:0.704091\tvalidation_1-gini:0.720064\n",
      "[197]\tvalidation_0-error:0.036197\tvalidation_1-error:0.037449\tvalidation_0-gini:0.70404\tvalidation_1-gini:0.720029\n",
      "[198]\tvalidation_0-error:0.036197\tvalidation_1-error:0.037449\tvalidation_0-gini:0.703873\tvalidation_1-gini:0.719996\n",
      "[199]\tvalidation_0-error:0.036197\tvalidation_1-error:0.037449\tvalidation_0-gini:0.703873\tvalidation_1-gini:0.719996\n",
      "[200]\tvalidation_0-error:0.036197\tvalidation_1-error:0.037449\tvalidation_0-gini:0.703873\tvalidation_1-gini:0.719996\n",
      "[201]\tvalidation_0-error:0.036197\tvalidation_1-error:0.037449\tvalidation_0-gini:0.703873\tvalidation_1-gini:0.719996\n",
      "[202]\tvalidation_0-error:0.036197\tvalidation_1-error:0.037449\tvalidation_0-gini:0.703873\tvalidation_1-gini:0.719996\n",
      "[203]\tvalidation_0-error:0.036197\tvalidation_1-error:0.037449\tvalidation_0-gini:0.703749\tvalidation_1-gini:0.719981\n",
      "[204]\tvalidation_0-error:0.036197\tvalidation_1-error:0.037449\tvalidation_0-gini:0.703617\tvalidation_1-gini:0.719911\n",
      "[205]\tvalidation_0-error:0.036197\tvalidation_1-error:0.037449\tvalidation_0-gini:0.703617\tvalidation_1-gini:0.719911\n",
      "[206]\tvalidation_0-error:0.036197\tvalidation_1-error:0.037449\tvalidation_0-gini:0.703617\tvalidation_1-gini:0.719911\n",
      "[207]\tvalidation_0-error:0.036197\tvalidation_1-error:0.037449\tvalidation_0-gini:0.703617\tvalidation_1-gini:0.719911\n",
      "[208]\tvalidation_0-error:0.036197\tvalidation_1-error:0.037449\tvalidation_0-gini:0.703617\tvalidation_1-gini:0.719911\n",
      "[209]\tvalidation_0-error:0.036197\tvalidation_1-error:0.037449\tvalidation_0-gini:0.703617\tvalidation_1-gini:0.719911\n",
      "[210]\tvalidation_0-error:0.036197\tvalidation_1-error:0.037449\tvalidation_0-gini:0.703617\tvalidation_1-gini:0.719911\n",
      "[211]\tvalidation_0-error:0.036197\tvalidation_1-error:0.037449\tvalidation_0-gini:0.703617\tvalidation_1-gini:0.719911\n",
      "[212]\tvalidation_0-error:0.036197\tvalidation_1-error:0.037449\tvalidation_0-gini:0.703617\tvalidation_1-gini:0.719911\n",
      "[213]\tvalidation_0-error:0.036197\tvalidation_1-error:0.037449\tvalidation_0-gini:0.703476\tvalidation_1-gini:0.719874\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[214]\tvalidation_0-error:0.036197\tvalidation_1-error:0.037449\tvalidation_0-gini:0.703476\tvalidation_1-gini:0.719874\n",
      "[215]\tvalidation_0-error:0.036197\tvalidation_1-error:0.037449\tvalidation_0-gini:0.703476\tvalidation_1-gini:0.719874\n",
      "[216]\tvalidation_0-error:0.036197\tvalidation_1-error:0.037449\tvalidation_0-gini:0.703423\tvalidation_1-gini:0.719812\n",
      "[217]\tvalidation_0-error:0.036197\tvalidation_1-error:0.037449\tvalidation_0-gini:0.703423\tvalidation_1-gini:0.719812\n",
      "[218]\tvalidation_0-error:0.036197\tvalidation_1-error:0.037449\tvalidation_0-gini:0.703423\tvalidation_1-gini:0.719812\n",
      "[219]\tvalidation_0-error:0.036197\tvalidation_1-error:0.037449\tvalidation_0-gini:0.703321\tvalidation_1-gini:0.71983\n",
      "[220]\tvalidation_0-error:0.036197\tvalidation_1-error:0.037449\tvalidation_0-gini:0.703321\tvalidation_1-gini:0.71983\n",
      "[221]\tvalidation_0-error:0.036197\tvalidation_1-error:0.037449\tvalidation_0-gini:0.703238\tvalidation_1-gini:0.719859\n",
      "[222]\tvalidation_0-error:0.036197\tvalidation_1-error:0.037449\tvalidation_0-gini:0.703238\tvalidation_1-gini:0.719859\n",
      "[223]\tvalidation_0-error:0.036197\tvalidation_1-error:0.037449\tvalidation_0-gini:0.703238\tvalidation_1-gini:0.719859\n",
      "[224]\tvalidation_0-error:0.036197\tvalidation_1-error:0.037449\tvalidation_0-gini:0.703238\tvalidation_1-gini:0.719859\n",
      "[225]\tvalidation_0-error:0.036197\tvalidation_1-error:0.037449\tvalidation_0-gini:0.703238\tvalidation_1-gini:0.719859\n",
      "[226]\tvalidation_0-error:0.036197\tvalidation_1-error:0.037449\tvalidation_0-gini:0.703238\tvalidation_1-gini:0.719859\n",
      "[227]\tvalidation_0-error:0.036197\tvalidation_1-error:0.037449\tvalidation_0-gini:0.703238\tvalidation_1-gini:0.719859\n",
      "[228]\tvalidation_0-error:0.036197\tvalidation_1-error:0.037449\tvalidation_0-gini:0.703238\tvalidation_1-gini:0.719859\n",
      "[229]\tvalidation_0-error:0.036197\tvalidation_1-error:0.037449\tvalidation_0-gini:0.703122\tvalidation_1-gini:0.719928\n",
      "[230]\tvalidation_0-error:0.036197\tvalidation_1-error:0.037449\tvalidation_0-gini:0.703122\tvalidation_1-gini:0.719928\n",
      "[231]\tvalidation_0-error:0.036197\tvalidation_1-error:0.037449\tvalidation_0-gini:0.703122\tvalidation_1-gini:0.719928\n",
      "[232]\tvalidation_0-error:0.036197\tvalidation_1-error:0.037449\tvalidation_0-gini:0.703122\tvalidation_1-gini:0.719928\n",
      "[233]\tvalidation_0-error:0.036197\tvalidation_1-error:0.037449\tvalidation_0-gini:0.703122\tvalidation_1-gini:0.719928\n",
      "[234]\tvalidation_0-error:0.036197\tvalidation_1-error:0.037449\tvalidation_0-gini:0.703122\tvalidation_1-gini:0.719928\n",
      "[235]\tvalidation_0-error:0.036197\tvalidation_1-error:0.037449\tvalidation_0-gini:0.703122\tvalidation_1-gini:0.719928\n",
      "[236]\tvalidation_0-error:0.036197\tvalidation_1-error:0.037449\tvalidation_0-gini:0.703122\tvalidation_1-gini:0.719928\n",
      "[237]\tvalidation_0-error:0.036197\tvalidation_1-error:0.037449\tvalidation_0-gini:0.703122\tvalidation_1-gini:0.719928\n",
      "[238]\tvalidation_0-error:0.036197\tvalidation_1-error:0.037449\tvalidation_0-gini:0.702944\tvalidation_1-gini:0.719767\n",
      "[239]\tvalidation_0-error:0.036197\tvalidation_1-error:0.037449\tvalidation_0-gini:0.702862\tvalidation_1-gini:0.719679\n",
      "[240]\tvalidation_0-error:0.036197\tvalidation_1-error:0.037449\tvalidation_0-gini:0.702797\tvalidation_1-gini:0.719598\n",
      "[241]\tvalidation_0-error:0.036197\tvalidation_1-error:0.037449\tvalidation_0-gini:0.702797\tvalidation_1-gini:0.719598\n",
      "[242]\tvalidation_0-error:0.036197\tvalidation_1-error:0.037449\tvalidation_0-gini:0.702797\tvalidation_1-gini:0.719598\n",
      "[243]\tvalidation_0-error:0.036197\tvalidation_1-error:0.037449\tvalidation_0-gini:0.702797\tvalidation_1-gini:0.719598\n",
      "[244]\tvalidation_0-error:0.036197\tvalidation_1-error:0.037449\tvalidation_0-gini:0.702797\tvalidation_1-gini:0.719598\n",
      "[245]\tvalidation_0-error:0.036197\tvalidation_1-error:0.037449\tvalidation_0-gini:0.702797\tvalidation_1-gini:0.719598\n",
      "[246]\tvalidation_0-error:0.036197\tvalidation_1-error:0.037449\tvalidation_0-gini:0.702797\tvalidation_1-gini:0.719598\n",
      "[247]\tvalidation_0-error:0.036197\tvalidation_1-error:0.037449\tvalidation_0-gini:0.702797\tvalidation_1-gini:0.719598\n",
      "[248]\tvalidation_0-error:0.036197\tvalidation_1-error:0.037449\tvalidation_0-gini:0.702755\tvalidation_1-gini:0.719588\n",
      "[249]\tvalidation_0-error:0.036197\tvalidation_1-error:0.037449\tvalidation_0-gini:0.702545\tvalidation_1-gini:0.719451\n",
      "[250]\tvalidation_0-error:0.036197\tvalidation_1-error:0.037449\tvalidation_0-gini:0.702545\tvalidation_1-gini:0.719451\n",
      "[251]\tvalidation_0-error:0.036197\tvalidation_1-error:0.037449\tvalidation_0-gini:0.702408\tvalidation_1-gini:0.719459\n",
      "[252]\tvalidation_0-error:0.036197\tvalidation_1-error:0.037449\tvalidation_0-gini:0.702317\tvalidation_1-gini:0.719459\n",
      "[253]\tvalidation_0-error:0.036197\tvalidation_1-error:0.037449\tvalidation_0-gini:0.702317\tvalidation_1-gini:0.719459\n",
      "[254]\tvalidation_0-error:0.036197\tvalidation_1-error:0.037449\tvalidation_0-gini:0.702138\tvalidation_1-gini:0.719478\n",
      "[255]\tvalidation_0-error:0.036197\tvalidation_1-error:0.037449\tvalidation_0-gini:0.702108\tvalidation_1-gini:0.719384\n",
      "[256]\tvalidation_0-error:0.036197\tvalidation_1-error:0.037449\tvalidation_0-gini:0.702108\tvalidation_1-gini:0.719384\n",
      "[257]\tvalidation_0-error:0.036197\tvalidation_1-error:0.037449\tvalidation_0-gini:0.702108\tvalidation_1-gini:0.719384\n",
      "[258]\tvalidation_0-error:0.036197\tvalidation_1-error:0.037449\tvalidation_0-gini:0.702108\tvalidation_1-gini:0.719384\n",
      "[259]\tvalidation_0-error:0.036197\tvalidation_1-error:0.037449\tvalidation_0-gini:0.702108\tvalidation_1-gini:0.719384\n",
      "[260]\tvalidation_0-error:0.036197\tvalidation_1-error:0.037449\tvalidation_0-gini:0.702031\tvalidation_1-gini:0.719315\n",
      "[261]\tvalidation_0-error:0.036197\tvalidation_1-error:0.037449\tvalidation_0-gini:0.702031\tvalidation_1-gini:0.719315\n",
      "[262]\tvalidation_0-error:0.036197\tvalidation_1-error:0.037449\tvalidation_0-gini:0.702031\tvalidation_1-gini:0.719315\n",
      "[263]\tvalidation_0-error:0.036197\tvalidation_1-error:0.037449\tvalidation_0-gini:0.702031\tvalidation_1-gini:0.719315\n",
      "[264]\tvalidation_0-error:0.036197\tvalidation_1-error:0.037449\tvalidation_0-gini:0.702031\tvalidation_1-gini:0.719315\n",
      "[265]\tvalidation_0-error:0.036197\tvalidation_1-error:0.037449\tvalidation_0-gini:0.702031\tvalidation_1-gini:0.719315\n",
      "[266]\tvalidation_0-error:0.036197\tvalidation_1-error:0.037449\tvalidation_0-gini:0.702031\tvalidation_1-gini:0.719315\n",
      "[267]\tvalidation_0-error:0.036197\tvalidation_1-error:0.037449\tvalidation_0-gini:0.702031\tvalidation_1-gini:0.719315\n",
      "[268]\tvalidation_0-error:0.036197\tvalidation_1-error:0.037449\tvalidation_0-gini:0.702031\tvalidation_1-gini:0.719315\n",
      "[269]\tvalidation_0-error:0.036197\tvalidation_1-error:0.037449\tvalidation_0-gini:0.702031\tvalidation_1-gini:0.719315\n",
      "[270]\tvalidation_0-error:0.036197\tvalidation_1-error:0.037449\tvalidation_0-gini:0.702031\tvalidation_1-gini:0.719315\n",
      "[271]\tvalidation_0-error:0.036197\tvalidation_1-error:0.037449\tvalidation_0-gini:0.702031\tvalidation_1-gini:0.719315\n",
      "[272]\tvalidation_0-error:0.036197\tvalidation_1-error:0.037449\tvalidation_0-gini:0.701917\tvalidation_1-gini:0.719316\n",
      "[273]\tvalidation_0-error:0.036197\tvalidation_1-error:0.037449\tvalidation_0-gini:0.701917\tvalidation_1-gini:0.719316\n",
      "[274]\tvalidation_0-error:0.036197\tvalidation_1-error:0.037449\tvalidation_0-gini:0.701917\tvalidation_1-gini:0.719316\n",
      "[275]\tvalidation_0-error:0.036197\tvalidation_1-error:0.037449\tvalidation_0-gini:0.701917\tvalidation_1-gini:0.719316\n",
      "[276]\tvalidation_0-error:0.036197\tvalidation_1-error:0.037449\tvalidation_0-gini:0.701917\tvalidation_1-gini:0.719316\n",
      "[277]\tvalidation_0-error:0.036197\tvalidation_1-error:0.037449\tvalidation_0-gini:0.701917\tvalidation_1-gini:0.719316\n",
      "[278]\tvalidation_0-error:0.036197\tvalidation_1-error:0.037449\tvalidation_0-gini:0.701917\tvalidation_1-gini:0.719316\n",
      "[279]\tvalidation_0-error:0.036197\tvalidation_1-error:0.037449\tvalidation_0-gini:0.701917\tvalidation_1-gini:0.719316\n",
      "[280]\tvalidation_0-error:0.036197\tvalidation_1-error:0.037449\tvalidation_0-gini:0.701917\tvalidation_1-gini:0.719316\n",
      "[281]\tvalidation_0-error:0.036197\tvalidation_1-error:0.037449\tvalidation_0-gini:0.701917\tvalidation_1-gini:0.719316\n",
      "[282]\tvalidation_0-error:0.036197\tvalidation_1-error:0.037449\tvalidation_0-gini:0.701917\tvalidation_1-gini:0.719316\n",
      "[283]\tvalidation_0-error:0.036197\tvalidation_1-error:0.037449\tvalidation_0-gini:0.701917\tvalidation_1-gini:0.719316\n",
      "[284]\tvalidation_0-error:0.036197\tvalidation_1-error:0.037449\tvalidation_0-gini:0.701917\tvalidation_1-gini:0.719316\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[285]\tvalidation_0-error:0.036197\tvalidation_1-error:0.037449\tvalidation_0-gini:0.701917\tvalidation_1-gini:0.719316\n",
      "[286]\tvalidation_0-error:0.036197\tvalidation_1-error:0.037449\tvalidation_0-gini:0.701847\tvalidation_1-gini:0.719183\n",
      "[287]\tvalidation_0-error:0.036197\tvalidation_1-error:0.037449\tvalidation_0-gini:0.701847\tvalidation_1-gini:0.719183\n",
      "[288]\tvalidation_0-error:0.036197\tvalidation_1-error:0.037449\tvalidation_0-gini:0.701768\tvalidation_1-gini:0.719149\n",
      "[289]\tvalidation_0-error:0.036197\tvalidation_1-error:0.037449\tvalidation_0-gini:0.701768\tvalidation_1-gini:0.719149\n",
      "[290]\tvalidation_0-error:0.036197\tvalidation_1-error:0.037449\tvalidation_0-gini:0.701768\tvalidation_1-gini:0.719149\n",
      "[291]\tvalidation_0-error:0.036197\tvalidation_1-error:0.037449\tvalidation_0-gini:0.701768\tvalidation_1-gini:0.719149\n",
      "[292]\tvalidation_0-error:0.036197\tvalidation_1-error:0.037449\tvalidation_0-gini:0.701768\tvalidation_1-gini:0.719149\n",
      "[293]\tvalidation_0-error:0.036197\tvalidation_1-error:0.037449\tvalidation_0-gini:0.701768\tvalidation_1-gini:0.719149\n",
      "[294]\tvalidation_0-error:0.036197\tvalidation_1-error:0.037449\tvalidation_0-gini:0.701752\tvalidation_1-gini:0.719113\n",
      "[295]\tvalidation_0-error:0.036197\tvalidation_1-error:0.037449\tvalidation_0-gini:0.701752\tvalidation_1-gini:0.719113\n",
      "[296]\tvalidation_0-error:0.036197\tvalidation_1-error:0.037449\tvalidation_0-gini:0.701752\tvalidation_1-gini:0.719113\n",
      "[297]\tvalidation_0-error:0.036197\tvalidation_1-error:0.037449\tvalidation_0-gini:0.701752\tvalidation_1-gini:0.719113\n",
      "[298]\tvalidation_0-error:0.036197\tvalidation_1-error:0.037449\tvalidation_0-gini:0.701752\tvalidation_1-gini:0.719113\n",
      "[299]\tvalidation_0-error:0.036197\tvalidation_1-error:0.037449\tvalidation_0-gini:0.701752\tvalidation_1-gini:0.719113\n",
      "[300]\tvalidation_0-error:0.036197\tvalidation_1-error:0.037449\tvalidation_0-gini:0.701752\tvalidation_1-gini:0.719113\n",
      "[301]\tvalidation_0-error:0.036197\tvalidation_1-error:0.037449\tvalidation_0-gini:0.701752\tvalidation_1-gini:0.719113\n",
      "[302]\tvalidation_0-error:0.036197\tvalidation_1-error:0.037449\tvalidation_0-gini:0.701752\tvalidation_1-gini:0.719113\n",
      "[303]\tvalidation_0-error:0.036197\tvalidation_1-error:0.037449\tvalidation_0-gini:0.701752\tvalidation_1-gini:0.719113\n",
      "[304]\tvalidation_0-error:0.036197\tvalidation_1-error:0.037449\tvalidation_0-gini:0.701752\tvalidation_1-gini:0.719113\n",
      "[305]\tvalidation_0-error:0.036197\tvalidation_1-error:0.037449\tvalidation_0-gini:0.701752\tvalidation_1-gini:0.719113\n",
      "[306]\tvalidation_0-error:0.036197\tvalidation_1-error:0.037449\tvalidation_0-gini:0.701752\tvalidation_1-gini:0.719113\n",
      "[307]\tvalidation_0-error:0.036197\tvalidation_1-error:0.037449\tvalidation_0-gini:0.701752\tvalidation_1-gini:0.719113\n",
      "[308]\tvalidation_0-error:0.036197\tvalidation_1-error:0.037449\tvalidation_0-gini:0.701752\tvalidation_1-gini:0.719113\n",
      "[309]\tvalidation_0-error:0.036197\tvalidation_1-error:0.037449\tvalidation_0-gini:0.701752\tvalidation_1-gini:0.719113\n",
      "[310]\tvalidation_0-error:0.036197\tvalidation_1-error:0.037449\tvalidation_0-gini:0.701752\tvalidation_1-gini:0.719113\n",
      "[311]\tvalidation_0-error:0.036197\tvalidation_1-error:0.037449\tvalidation_0-gini:0.701752\tvalidation_1-gini:0.719113\n",
      "[312]\tvalidation_0-error:0.036197\tvalidation_1-error:0.037449\tvalidation_0-gini:0.701752\tvalidation_1-gini:0.719113\n",
      "[313]\tvalidation_0-error:0.036197\tvalidation_1-error:0.037449\tvalidation_0-gini:0.701703\tvalidation_1-gini:0.719025\n",
      "[314]\tvalidation_0-error:0.036197\tvalidation_1-error:0.037449\tvalidation_0-gini:0.701703\tvalidation_1-gini:0.719025\n",
      "[315]\tvalidation_0-error:0.036197\tvalidation_1-error:0.037449\tvalidation_0-gini:0.701703\tvalidation_1-gini:0.719025\n",
      "[316]\tvalidation_0-error:0.036197\tvalidation_1-error:0.037449\tvalidation_0-gini:0.701703\tvalidation_1-gini:0.719025\n",
      "[317]\tvalidation_0-error:0.036197\tvalidation_1-error:0.037449\tvalidation_0-gini:0.701574\tvalidation_1-gini:0.718924\n",
      "[318]\tvalidation_0-error:0.036197\tvalidation_1-error:0.037449\tvalidation_0-gini:0.701574\tvalidation_1-gini:0.718924\n",
      "[319]\tvalidation_0-error:0.036197\tvalidation_1-error:0.037449\tvalidation_0-gini:0.701574\tvalidation_1-gini:0.718924\n",
      "[320]\tvalidation_0-error:0.036197\tvalidation_1-error:0.037449\tvalidation_0-gini:0.701574\tvalidation_1-gini:0.718924\n",
      "[321]\tvalidation_0-error:0.036197\tvalidation_1-error:0.037449\tvalidation_0-gini:0.70147\tvalidation_1-gini:0.718876\n",
      "[322]\tvalidation_0-error:0.036197\tvalidation_1-error:0.037449\tvalidation_0-gini:0.70147\tvalidation_1-gini:0.718876\n",
      "[323]\tvalidation_0-error:0.036197\tvalidation_1-error:0.037449\tvalidation_0-gini:0.70147\tvalidation_1-gini:0.718876\n",
      "[324]\tvalidation_0-error:0.036197\tvalidation_1-error:0.037449\tvalidation_0-gini:0.70147\tvalidation_1-gini:0.718876\n",
      "[325]\tvalidation_0-error:0.036197\tvalidation_1-error:0.037449\tvalidation_0-gini:0.70147\tvalidation_1-gini:0.718876\n",
      "[326]\tvalidation_0-error:0.036197\tvalidation_1-error:0.037449\tvalidation_0-gini:0.70147\tvalidation_1-gini:0.718876\n",
      "[327]\tvalidation_0-error:0.036197\tvalidation_1-error:0.037449\tvalidation_0-gini:0.70134\tvalidation_1-gini:0.718858\n",
      "[328]\tvalidation_0-error:0.036197\tvalidation_1-error:0.037449\tvalidation_0-gini:0.70134\tvalidation_1-gini:0.718858\n",
      "[329]\tvalidation_0-error:0.036197\tvalidation_1-error:0.037449\tvalidation_0-gini:0.70134\tvalidation_1-gini:0.718858\n",
      "[330]\tvalidation_0-error:0.036197\tvalidation_1-error:0.037449\tvalidation_0-gini:0.70134\tvalidation_1-gini:0.718858\n",
      "[331]\tvalidation_0-error:0.036197\tvalidation_1-error:0.037449\tvalidation_0-gini:0.70134\tvalidation_1-gini:0.718858\n",
      "[332]\tvalidation_0-error:0.036197\tvalidation_1-error:0.037449\tvalidation_0-gini:0.70121\tvalidation_1-gini:0.718786\n",
      "[333]\tvalidation_0-error:0.036197\tvalidation_1-error:0.037449\tvalidation_0-gini:0.70121\tvalidation_1-gini:0.718786\n",
      "[334]\tvalidation_0-error:0.036197\tvalidation_1-error:0.037449\tvalidation_0-gini:0.70121\tvalidation_1-gini:0.718786\n",
      "[335]\tvalidation_0-error:0.036197\tvalidation_1-error:0.037449\tvalidation_0-gini:0.70121\tvalidation_1-gini:0.718786\n",
      "[336]\tvalidation_0-error:0.036197\tvalidation_1-error:0.037449\tvalidation_0-gini:0.70121\tvalidation_1-gini:0.718786\n",
      "[337]\tvalidation_0-error:0.036197\tvalidation_1-error:0.037449\tvalidation_0-gini:0.70121\tvalidation_1-gini:0.718786\n",
      "[338]\tvalidation_0-error:0.036197\tvalidation_1-error:0.037449\tvalidation_0-gini:0.701159\tvalidation_1-gini:0.718751\n",
      "[339]\tvalidation_0-error:0.036197\tvalidation_1-error:0.037449\tvalidation_0-gini:0.701159\tvalidation_1-gini:0.718751\n",
      "[340]\tvalidation_0-error:0.036197\tvalidation_1-error:0.037449\tvalidation_0-gini:0.701159\tvalidation_1-gini:0.718751\n",
      "[341]\tvalidation_0-error:0.036197\tvalidation_1-error:0.037449\tvalidation_0-gini:0.701159\tvalidation_1-gini:0.718751\n",
      "[342]\tvalidation_0-error:0.036197\tvalidation_1-error:0.037449\tvalidation_0-gini:0.70104\tvalidation_1-gini:0.718797\n",
      "[343]\tvalidation_0-error:0.036197\tvalidation_1-error:0.037449\tvalidation_0-gini:0.70104\tvalidation_1-gini:0.718797\n",
      "[344]\tvalidation_0-error:0.036197\tvalidation_1-error:0.037449\tvalidation_0-gini:0.70104\tvalidation_1-gini:0.718797\n",
      "[345]\tvalidation_0-error:0.036197\tvalidation_1-error:0.037449\tvalidation_0-gini:0.70104\tvalidation_1-gini:0.718797\n",
      "[346]\tvalidation_0-error:0.036197\tvalidation_1-error:0.037449\tvalidation_0-gini:0.70104\tvalidation_1-gini:0.718797\n",
      "[347]\tvalidation_0-error:0.036197\tvalidation_1-error:0.037449\tvalidation_0-gini:0.70104\tvalidation_1-gini:0.718797\n",
      "[348]\tvalidation_0-error:0.036197\tvalidation_1-error:0.037449\tvalidation_0-gini:0.70104\tvalidation_1-gini:0.718797\n",
      "[349]\tvalidation_0-error:0.036197\tvalidation_1-error:0.037449\tvalidation_0-gini:0.70104\tvalidation_1-gini:0.718797\n",
      "[350]\tvalidation_0-error:0.036197\tvalidation_1-error:0.037449\tvalidation_0-gini:0.70104\tvalidation_1-gini:0.718797\n",
      "[351]\tvalidation_0-error:0.036197\tvalidation_1-error:0.037449\tvalidation_0-gini:0.700964\tvalidation_1-gini:0.718782\n",
      "[352]\tvalidation_0-error:0.036197\tvalidation_1-error:0.037449\tvalidation_0-gini:0.7009\tvalidation_1-gini:0.718837\n",
      "[353]\tvalidation_0-error:0.036197\tvalidation_1-error:0.037449\tvalidation_0-gini:0.70083\tvalidation_1-gini:0.718704\n",
      "[354]\tvalidation_0-error:0.036197\tvalidation_1-error:0.037449\tvalidation_0-gini:0.70083\tvalidation_1-gini:0.718704\n",
      "[355]\tvalidation_0-error:0.036197\tvalidation_1-error:0.037449\tvalidation_0-gini:0.70083\tvalidation_1-gini:0.718704\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[356]\tvalidation_0-error:0.036197\tvalidation_1-error:0.037449\tvalidation_0-gini:0.70083\tvalidation_1-gini:0.718704\n",
      "[357]\tvalidation_0-error:0.036197\tvalidation_1-error:0.037449\tvalidation_0-gini:0.70083\tvalidation_1-gini:0.718704\n",
      "[358]\tvalidation_0-error:0.036197\tvalidation_1-error:0.037449\tvalidation_0-gini:0.70083\tvalidation_1-gini:0.718704\n",
      "[359]\tvalidation_0-error:0.036197\tvalidation_1-error:0.037449\tvalidation_0-gini:0.70083\tvalidation_1-gini:0.718704\n",
      "[360]\tvalidation_0-error:0.036197\tvalidation_1-error:0.037449\tvalidation_0-gini:0.700755\tvalidation_1-gini:0.718711\n",
      "[361]\tvalidation_0-error:0.036197\tvalidation_1-error:0.037449\tvalidation_0-gini:0.700755\tvalidation_1-gini:0.718711\n",
      "[362]\tvalidation_0-error:0.036197\tvalidation_1-error:0.037449\tvalidation_0-gini:0.700755\tvalidation_1-gini:0.718711\n",
      "[363]\tvalidation_0-error:0.036197\tvalidation_1-error:0.037449\tvalidation_0-gini:0.700755\tvalidation_1-gini:0.718711\n",
      "[364]\tvalidation_0-error:0.036197\tvalidation_1-error:0.037449\tvalidation_0-gini:0.700755\tvalidation_1-gini:0.718711\n",
      "[365]\tvalidation_0-error:0.036197\tvalidation_1-error:0.037449\tvalidation_0-gini:0.700755\tvalidation_1-gini:0.718711\n",
      "[366]\tvalidation_0-error:0.036197\tvalidation_1-error:0.037449\tvalidation_0-gini:0.700755\tvalidation_1-gini:0.718711\n",
      "[367]\tvalidation_0-error:0.036197\tvalidation_1-error:0.037449\tvalidation_0-gini:0.700755\tvalidation_1-gini:0.718711\n",
      "[368]\tvalidation_0-error:0.036197\tvalidation_1-error:0.037449\tvalidation_0-gini:0.700755\tvalidation_1-gini:0.718711\n",
      "[369]\tvalidation_0-error:0.036197\tvalidation_1-error:0.037449\tvalidation_0-gini:0.700755\tvalidation_1-gini:0.718711\n",
      "[370]\tvalidation_0-error:0.036197\tvalidation_1-error:0.037449\tvalidation_0-gini:0.700755\tvalidation_1-gini:0.718711\n",
      "[371]\tvalidation_0-error:0.036197\tvalidation_1-error:0.037449\tvalidation_0-gini:0.700755\tvalidation_1-gini:0.718711\n",
      "[372]\tvalidation_0-error:0.036197\tvalidation_1-error:0.037449\tvalidation_0-gini:0.700655\tvalidation_1-gini:0.718634\n",
      "[373]\tvalidation_0-error:0.036197\tvalidation_1-error:0.037449\tvalidation_0-gini:0.700655\tvalidation_1-gini:0.718634\n",
      "[374]\tvalidation_0-error:0.036197\tvalidation_1-error:0.037449\tvalidation_0-gini:0.700655\tvalidation_1-gini:0.718634\n",
      "[375]\tvalidation_0-error:0.036197\tvalidation_1-error:0.037449\tvalidation_0-gini:0.700655\tvalidation_1-gini:0.718634\n",
      "[376]\tvalidation_0-error:0.036197\tvalidation_1-error:0.037449\tvalidation_0-gini:0.700655\tvalidation_1-gini:0.718634\n",
      "[377]\tvalidation_0-error:0.036197\tvalidation_1-error:0.037449\tvalidation_0-gini:0.700655\tvalidation_1-gini:0.718634\n",
      "[378]\tvalidation_0-error:0.036197\tvalidation_1-error:0.037449\tvalidation_0-gini:0.700655\tvalidation_1-gini:0.718634\n",
      "[379]\tvalidation_0-error:0.036197\tvalidation_1-error:0.037449\tvalidation_0-gini:0.700507\tvalidation_1-gini:0.718633\n",
      "[380]\tvalidation_0-error:0.036197\tvalidation_1-error:0.037449\tvalidation_0-gini:0.700507\tvalidation_1-gini:0.718633\n",
      "[381]\tvalidation_0-error:0.036197\tvalidation_1-error:0.037449\tvalidation_0-gini:0.700507\tvalidation_1-gini:0.718633\n",
      "[382]\tvalidation_0-error:0.036197\tvalidation_1-error:0.037449\tvalidation_0-gini:0.700507\tvalidation_1-gini:0.718633\n",
      "[383]\tvalidation_0-error:0.036197\tvalidation_1-error:0.037449\tvalidation_0-gini:0.700507\tvalidation_1-gini:0.718633\n",
      "[384]\tvalidation_0-error:0.036197\tvalidation_1-error:0.037449\tvalidation_0-gini:0.700507\tvalidation_1-gini:0.718633\n",
      "[385]\tvalidation_0-error:0.036197\tvalidation_1-error:0.037449\tvalidation_0-gini:0.700507\tvalidation_1-gini:0.718633\n",
      "[386]\tvalidation_0-error:0.036197\tvalidation_1-error:0.037449\tvalidation_0-gini:0.700395\tvalidation_1-gini:0.718576\n",
      "[387]\tvalidation_0-error:0.036197\tvalidation_1-error:0.037449\tvalidation_0-gini:0.700318\tvalidation_1-gini:0.718492\n",
      "[388]\tvalidation_0-error:0.036197\tvalidation_1-error:0.037449\tvalidation_0-gini:0.700318\tvalidation_1-gini:0.718492\n",
      "[389]\tvalidation_0-error:0.036197\tvalidation_1-error:0.037449\tvalidation_0-gini:0.700318\tvalidation_1-gini:0.718492\n",
      "[390]\tvalidation_0-error:0.036197\tvalidation_1-error:0.037449\tvalidation_0-gini:0.700318\tvalidation_1-gini:0.718492\n",
      "[391]\tvalidation_0-error:0.036197\tvalidation_1-error:0.037449\tvalidation_0-gini:0.700318\tvalidation_1-gini:0.718492\n",
      "[392]\tvalidation_0-error:0.036197\tvalidation_1-error:0.037449\tvalidation_0-gini:0.700348\tvalidation_1-gini:0.718569\n",
      "[393]\tvalidation_0-error:0.036197\tvalidation_1-error:0.037449\tvalidation_0-gini:0.700348\tvalidation_1-gini:0.718569\n",
      "[394]\tvalidation_0-error:0.036197\tvalidation_1-error:0.037449\tvalidation_0-gini:0.700348\tvalidation_1-gini:0.718569\n",
      "[395]\tvalidation_0-error:0.036197\tvalidation_1-error:0.037449\tvalidation_0-gini:0.700348\tvalidation_1-gini:0.718569\n",
      "[396]\tvalidation_0-error:0.036197\tvalidation_1-error:0.037449\tvalidation_0-gini:0.700348\tvalidation_1-gini:0.718569\n",
      "[397]\tvalidation_0-error:0.036197\tvalidation_1-error:0.037449\tvalidation_0-gini:0.700348\tvalidation_1-gini:0.718569\n",
      "[398]\tvalidation_0-error:0.036197\tvalidation_1-error:0.037449\tvalidation_0-gini:0.700275\tvalidation_1-gini:0.718449\n",
      "[399]\tvalidation_0-error:0.036197\tvalidation_1-error:0.037449\tvalidation_0-gini:0.700129\tvalidation_1-gini:0.718472\n",
      "[400]\tvalidation_0-error:0.036197\tvalidation_1-error:0.037449\tvalidation_0-gini:0.700129\tvalidation_1-gini:0.718472\n",
      "[401]\tvalidation_0-error:0.036197\tvalidation_1-error:0.037449\tvalidation_0-gini:0.700129\tvalidation_1-gini:0.718472\n",
      "[402]\tvalidation_0-error:0.036197\tvalidation_1-error:0.037449\tvalidation_0-gini:0.700129\tvalidation_1-gini:0.718472\n",
      "[403]\tvalidation_0-error:0.036197\tvalidation_1-error:0.037449\tvalidation_0-gini:0.700129\tvalidation_1-gini:0.718472\n",
      "[404]\tvalidation_0-error:0.036197\tvalidation_1-error:0.037449\tvalidation_0-gini:0.700129\tvalidation_1-gini:0.718472\n",
      "[405]\tvalidation_0-error:0.036197\tvalidation_1-error:0.037449\tvalidation_0-gini:0.700129\tvalidation_1-gini:0.718472\n",
      "[406]\tvalidation_0-error:0.036197\tvalidation_1-error:0.037449\tvalidation_0-gini:0.700053\tvalidation_1-gini:0.71839\n",
      "[407]\tvalidation_0-error:0.036197\tvalidation_1-error:0.037449\tvalidation_0-gini:0.700053\tvalidation_1-gini:0.71839\n",
      "[408]\tvalidation_0-error:0.036197\tvalidation_1-error:0.037449\tvalidation_0-gini:0.700053\tvalidation_1-gini:0.71839\n",
      "[409]\tvalidation_0-error:0.036197\tvalidation_1-error:0.037449\tvalidation_0-gini:0.700053\tvalidation_1-gini:0.71839\n",
      "[410]\tvalidation_0-error:0.036197\tvalidation_1-error:0.037449\tvalidation_0-gini:0.700053\tvalidation_1-gini:0.71839\n",
      "[411]\tvalidation_0-error:0.036197\tvalidation_1-error:0.037449\tvalidation_0-gini:0.700053\tvalidation_1-gini:0.71839\n",
      "[412]\tvalidation_0-error:0.036197\tvalidation_1-error:0.037449\tvalidation_0-gini:0.700053\tvalidation_1-gini:0.71839\n",
      "[413]\tvalidation_0-error:0.036197\tvalidation_1-error:0.037449\tvalidation_0-gini:0.700053\tvalidation_1-gini:0.71839\n",
      "[414]\tvalidation_0-error:0.036197\tvalidation_1-error:0.037449\tvalidation_0-gini:0.700053\tvalidation_1-gini:0.71839\n",
      "[415]\tvalidation_0-error:0.036197\tvalidation_1-error:0.037449\tvalidation_0-gini:0.700053\tvalidation_1-gini:0.71839\n",
      "[416]\tvalidation_0-error:0.036197\tvalidation_1-error:0.037449\tvalidation_0-gini:0.699961\tvalidation_1-gini:0.718418\n",
      "[417]\tvalidation_0-error:0.036197\tvalidation_1-error:0.037449\tvalidation_0-gini:0.699915\tvalidation_1-gini:0.718359\n",
      "[418]\tvalidation_0-error:0.036197\tvalidation_1-error:0.037449\tvalidation_0-gini:0.699915\tvalidation_1-gini:0.718359\n",
      "[419]\tvalidation_0-error:0.036197\tvalidation_1-error:0.037449\tvalidation_0-gini:0.699915\tvalidation_1-gini:0.718359\n",
      "[420]\tvalidation_0-error:0.036197\tvalidation_1-error:0.037449\tvalidation_0-gini:0.699915\tvalidation_1-gini:0.718359\n",
      "[421]\tvalidation_0-error:0.036197\tvalidation_1-error:0.037449\tvalidation_0-gini:0.699915\tvalidation_1-gini:0.718359\n",
      "[422]\tvalidation_0-error:0.036197\tvalidation_1-error:0.037449\tvalidation_0-gini:0.699915\tvalidation_1-gini:0.718359\n",
      "[423]\tvalidation_0-error:0.036197\tvalidation_1-error:0.037449\tvalidation_0-gini:0.699915\tvalidation_1-gini:0.718359\n",
      "[424]\tvalidation_0-error:0.036197\tvalidation_1-error:0.037449\tvalidation_0-gini:0.699915\tvalidation_1-gini:0.718359\n",
      "[425]\tvalidation_0-error:0.036197\tvalidation_1-error:0.037449\tvalidation_0-gini:0.699915\tvalidation_1-gini:0.718359\n",
      "[426]\tvalidation_0-error:0.036197\tvalidation_1-error:0.037449\tvalidation_0-gini:0.699915\tvalidation_1-gini:0.718359\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[427]\tvalidation_0-error:0.036197\tvalidation_1-error:0.037449\tvalidation_0-gini:0.699915\tvalidation_1-gini:0.718359\n",
      "[428]\tvalidation_0-error:0.036197\tvalidation_1-error:0.037449\tvalidation_0-gini:0.699915\tvalidation_1-gini:0.718359\n",
      "[429]\tvalidation_0-error:0.036197\tvalidation_1-error:0.037449\tvalidation_0-gini:0.699915\tvalidation_1-gini:0.718359\n",
      "[430]\tvalidation_0-error:0.036197\tvalidation_1-error:0.037449\tvalidation_0-gini:0.699817\tvalidation_1-gini:0.718285\n",
      "[431]\tvalidation_0-error:0.036197\tvalidation_1-error:0.037449\tvalidation_0-gini:0.699683\tvalidation_1-gini:0.718233\n",
      "[432]\tvalidation_0-error:0.036197\tvalidation_1-error:0.037449\tvalidation_0-gini:0.699683\tvalidation_1-gini:0.718233\n",
      "[433]\tvalidation_0-error:0.036197\tvalidation_1-error:0.037449\tvalidation_0-gini:0.699683\tvalidation_1-gini:0.718233\n",
      "[434]\tvalidation_0-error:0.036197\tvalidation_1-error:0.037449\tvalidation_0-gini:0.699652\tvalidation_1-gini:0.718234\n",
      "[435]\tvalidation_0-error:0.036197\tvalidation_1-error:0.037449\tvalidation_0-gini:0.699652\tvalidation_1-gini:0.718234\n",
      "[436]\tvalidation_0-error:0.036197\tvalidation_1-error:0.037449\tvalidation_0-gini:0.699578\tvalidation_1-gini:0.718243\n",
      "[437]\tvalidation_0-error:0.036197\tvalidation_1-error:0.037449\tvalidation_0-gini:0.699551\tvalidation_1-gini:0.718236\n",
      "[438]\tvalidation_0-error:0.036197\tvalidation_1-error:0.037449\tvalidation_0-gini:0.699551\tvalidation_1-gini:0.718236\n",
      "[439]\tvalidation_0-error:0.036197\tvalidation_1-error:0.037449\tvalidation_0-gini:0.699551\tvalidation_1-gini:0.718236\n",
      "[440]\tvalidation_0-error:0.036197\tvalidation_1-error:0.037449\tvalidation_0-gini:0.699551\tvalidation_1-gini:0.718236\n",
      "[441]\tvalidation_0-error:0.036197\tvalidation_1-error:0.037449\tvalidation_0-gini:0.699551\tvalidation_1-gini:0.718236\n",
      "[442]\tvalidation_0-error:0.036197\tvalidation_1-error:0.037449\tvalidation_0-gini:0.699551\tvalidation_1-gini:0.718236\n",
      "[443]\tvalidation_0-error:0.036197\tvalidation_1-error:0.037449\tvalidation_0-gini:0.699551\tvalidation_1-gini:0.718236\n",
      "[444]\tvalidation_0-error:0.036197\tvalidation_1-error:0.037449\tvalidation_0-gini:0.699551\tvalidation_1-gini:0.718236\n",
      "[445]\tvalidation_0-error:0.036197\tvalidation_1-error:0.037449\tvalidation_0-gini:0.699551\tvalidation_1-gini:0.718236\n",
      "[446]\tvalidation_0-error:0.036197\tvalidation_1-error:0.037449\tvalidation_0-gini:0.699551\tvalidation_1-gini:0.718236\n",
      "[447]\tvalidation_0-error:0.036197\tvalidation_1-error:0.037449\tvalidation_0-gini:0.699551\tvalidation_1-gini:0.718236\n",
      "[448]\tvalidation_0-error:0.036197\tvalidation_1-error:0.037449\tvalidation_0-gini:0.699551\tvalidation_1-gini:0.718236\n",
      "[449]\tvalidation_0-error:0.036197\tvalidation_1-error:0.037449\tvalidation_0-gini:0.699551\tvalidation_1-gini:0.718236\n",
      "[450]\tvalidation_0-error:0.036197\tvalidation_1-error:0.037449\tvalidation_0-gini:0.699551\tvalidation_1-gini:0.718236\n",
      "[451]\tvalidation_0-error:0.036197\tvalidation_1-error:0.037449\tvalidation_0-gini:0.699551\tvalidation_1-gini:0.718236\n",
      "[452]\tvalidation_0-error:0.036197\tvalidation_1-error:0.037449\tvalidation_0-gini:0.699551\tvalidation_1-gini:0.718236\n",
      "[453]\tvalidation_0-error:0.036197\tvalidation_1-error:0.037449\tvalidation_0-gini:0.699433\tvalidation_1-gini:0.718063\n",
      "[454]\tvalidation_0-error:0.036197\tvalidation_1-error:0.037449\tvalidation_0-gini:0.699433\tvalidation_1-gini:0.718063\n",
      "[455]\tvalidation_0-error:0.036197\tvalidation_1-error:0.037449\tvalidation_0-gini:0.699433\tvalidation_1-gini:0.718063\n",
      "[456]\tvalidation_0-error:0.036197\tvalidation_1-error:0.037449\tvalidation_0-gini:0.699433\tvalidation_1-gini:0.718063\n",
      "[457]\tvalidation_0-error:0.036197\tvalidation_1-error:0.037449\tvalidation_0-gini:0.699433\tvalidation_1-gini:0.718063\n",
      "[458]\tvalidation_0-error:0.036197\tvalidation_1-error:0.037449\tvalidation_0-gini:0.699433\tvalidation_1-gini:0.718063\n",
      "[459]\tvalidation_0-error:0.036197\tvalidation_1-error:0.037449\tvalidation_0-gini:0.699433\tvalidation_1-gini:0.718063\n",
      "[460]\tvalidation_0-error:0.036197\tvalidation_1-error:0.037449\tvalidation_0-gini:0.699433\tvalidation_1-gini:0.718063\n",
      "[461]\tvalidation_0-error:0.036197\tvalidation_1-error:0.037449\tvalidation_0-gini:0.699433\tvalidation_1-gini:0.718063\n",
      "[462]\tvalidation_0-error:0.036197\tvalidation_1-error:0.037449\tvalidation_0-gini:0.699433\tvalidation_1-gini:0.718063\n",
      "[463]\tvalidation_0-error:0.036197\tvalidation_1-error:0.037449\tvalidation_0-gini:0.699433\tvalidation_1-gini:0.718063\n",
      "[464]\tvalidation_0-error:0.036197\tvalidation_1-error:0.037449\tvalidation_0-gini:0.699433\tvalidation_1-gini:0.718063\n",
      "[465]\tvalidation_0-error:0.036197\tvalidation_1-error:0.037449\tvalidation_0-gini:0.699433\tvalidation_1-gini:0.718063\n",
      "[466]\tvalidation_0-error:0.036197\tvalidation_1-error:0.037449\tvalidation_0-gini:0.699433\tvalidation_1-gini:0.718063\n",
      "[467]\tvalidation_0-error:0.036197\tvalidation_1-error:0.037449\tvalidation_0-gini:0.699433\tvalidation_1-gini:0.718063\n",
      "[468]\tvalidation_0-error:0.036197\tvalidation_1-error:0.037449\tvalidation_0-gini:0.699433\tvalidation_1-gini:0.718063\n",
      "[469]\tvalidation_0-error:0.036197\tvalidation_1-error:0.037449\tvalidation_0-gini:0.699433\tvalidation_1-gini:0.718063\n",
      "[470]\tvalidation_0-error:0.036197\tvalidation_1-error:0.037449\tvalidation_0-gini:0.699433\tvalidation_1-gini:0.718063\n",
      "[471]\tvalidation_0-error:0.036197\tvalidation_1-error:0.037449\tvalidation_0-gini:0.699433\tvalidation_1-gini:0.718063\n",
      "[472]\tvalidation_0-error:0.036197\tvalidation_1-error:0.037449\tvalidation_0-gini:0.699433\tvalidation_1-gini:0.718063\n",
      "[473]\tvalidation_0-error:0.036197\tvalidation_1-error:0.037449\tvalidation_0-gini:0.699433\tvalidation_1-gini:0.718063\n",
      "[474]\tvalidation_0-error:0.036197\tvalidation_1-error:0.037449\tvalidation_0-gini:0.699433\tvalidation_1-gini:0.718063\n",
      "[475]\tvalidation_0-error:0.036197\tvalidation_1-error:0.037449\tvalidation_0-gini:0.699433\tvalidation_1-gini:0.718063\n",
      "[476]\tvalidation_0-error:0.036197\tvalidation_1-error:0.037449\tvalidation_0-gini:0.699433\tvalidation_1-gini:0.718063\n",
      "[477]\tvalidation_0-error:0.036197\tvalidation_1-error:0.037449\tvalidation_0-gini:0.699433\tvalidation_1-gini:0.718063\n",
      "[478]\tvalidation_0-error:0.036197\tvalidation_1-error:0.037449\tvalidation_0-gini:0.699433\tvalidation_1-gini:0.718063\n",
      "[479]\tvalidation_0-error:0.036197\tvalidation_1-error:0.037449\tvalidation_0-gini:0.699433\tvalidation_1-gini:0.718063\n",
      "[480]\tvalidation_0-error:0.036197\tvalidation_1-error:0.037449\tvalidation_0-gini:0.699433\tvalidation_1-gini:0.718063\n",
      "[481]\tvalidation_0-error:0.036197\tvalidation_1-error:0.037449\tvalidation_0-gini:0.699433\tvalidation_1-gini:0.718063\n",
      "[482]\tvalidation_0-error:0.036197\tvalidation_1-error:0.037449\tvalidation_0-gini:0.699433\tvalidation_1-gini:0.718063\n",
      "[483]\tvalidation_0-error:0.036197\tvalidation_1-error:0.037449\tvalidation_0-gini:0.699433\tvalidation_1-gini:0.718063\n",
      "[484]\tvalidation_0-error:0.036197\tvalidation_1-error:0.037449\tvalidation_0-gini:0.699433\tvalidation_1-gini:0.718063\n",
      "[485]\tvalidation_0-error:0.036197\tvalidation_1-error:0.037449\tvalidation_0-gini:0.699433\tvalidation_1-gini:0.718063\n",
      "[486]\tvalidation_0-error:0.036197\tvalidation_1-error:0.037449\tvalidation_0-gini:0.699433\tvalidation_1-gini:0.718063\n",
      "[487]\tvalidation_0-error:0.036197\tvalidation_1-error:0.037449\tvalidation_0-gini:0.699433\tvalidation_1-gini:0.718063\n",
      "[488]\tvalidation_0-error:0.036197\tvalidation_1-error:0.037449\tvalidation_0-gini:0.699433\tvalidation_1-gini:0.718063\n",
      "[489]\tvalidation_0-error:0.036197\tvalidation_1-error:0.037449\tvalidation_0-gini:0.699433\tvalidation_1-gini:0.718063\n",
      "[490]\tvalidation_0-error:0.036197\tvalidation_1-error:0.037449\tvalidation_0-gini:0.699356\tvalidation_1-gini:0.718078\n",
      "[491]\tvalidation_0-error:0.036197\tvalidation_1-error:0.037449\tvalidation_0-gini:0.699356\tvalidation_1-gini:0.718078\n",
      "[492]\tvalidation_0-error:0.036197\tvalidation_1-error:0.037449\tvalidation_0-gini:0.699356\tvalidation_1-gini:0.718078\n",
      "[493]\tvalidation_0-error:0.036197\tvalidation_1-error:0.037449\tvalidation_0-gini:0.69927\tvalidation_1-gini:0.717851\n",
      "[494]\tvalidation_0-error:0.036197\tvalidation_1-error:0.037449\tvalidation_0-gini:0.69927\tvalidation_1-gini:0.717851\n",
      "[495]\tvalidation_0-error:0.036197\tvalidation_1-error:0.037449\tvalidation_0-gini:0.69927\tvalidation_1-gini:0.717851\n",
      "[496]\tvalidation_0-error:0.036197\tvalidation_1-error:0.037449\tvalidation_0-gini:0.69927\tvalidation_1-gini:0.717851\n",
      "[497]\tvalidation_0-error:0.036197\tvalidation_1-error:0.037449\tvalidation_0-gini:0.69927\tvalidation_1-gini:0.717851\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[498]\tvalidation_0-error:0.036197\tvalidation_1-error:0.037449\tvalidation_0-gini:0.699119\tvalidation_1-gini:0.717831\n",
      "[499]\tvalidation_0-error:0.036197\tvalidation_1-error:0.037449\tvalidation_0-gini:0.699119\tvalidation_1-gini:0.717831\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "       colsample_bynode=1, colsample_bytree=0.8, gamma=10,\n",
       "       learning_rate=0.07, max_delta_step=0, max_depth=4,\n",
       "       min_child_weight=6, missing=None, n_estimators=500, n_jobs=1,\n",
       "       nthread=None, objective='binary:logistic', random_state=123,\n",
       "       reg_alpha=8, reg_lambda=1.3, scale_pos_weight=1, seed=None,\n",
       "       silent=None, subsample=0.8, verbosity=1)"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eval_set = [(X_train_orig, y_train_orig), (X_test_orig, y_test_orig)]\n",
    "xg_cl.fit(X_train_orig, y_train_orig, early_stopping_rounds=50, eval_metric=gini_xgb, eval_set=eval_set, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\tvalidation_0-error:0.44068\tvalidation_1-error:0.445033\tvalidation_0-gini:0.814985\tvalidation_1-gini:0.820908\n",
      "Multiple eval metrics have been passed: 'validation_1-gini' will be used for early stopping.\n",
      "\n",
      "Will train until validation_1-gini hasn't improved in 50 rounds.\n",
      "[1]\tvalidation_0-error:0.423596\tvalidation_1-error:0.427287\tvalidation_0-gini:0.77465\tvalidation_1-gini:0.779562\n",
      "[2]\tvalidation_0-error:0.41501\tvalidation_1-error:0.414957\tvalidation_0-gini:0.757424\tvalidation_1-gini:0.761591\n",
      "[3]\tvalidation_0-error:0.414549\tvalidation_1-error:0.415764\tvalidation_0-gini:0.757062\tvalidation_1-gini:0.759868\n",
      "[4]\tvalidation_0-error:0.414866\tvalidation_1-error:0.41392\tvalidation_0-gini:0.752634\tvalidation_1-gini:0.75714\n",
      "[5]\tvalidation_0-error:0.413858\tvalidation_1-error:0.413575\tvalidation_0-gini:0.751532\tvalidation_1-gini:0.758018\n",
      "[6]\tvalidation_0-error:0.414751\tvalidation_1-error:0.41392\tvalidation_0-gini:0.753839\tvalidation_1-gini:0.760337\n",
      "[7]\tvalidation_0-error:0.413598\tvalidation_1-error:0.412192\tvalidation_0-gini:0.74939\tvalidation_1-gini:0.758815\n",
      "[8]\tvalidation_0-error:0.412993\tvalidation_1-error:0.410233\tvalidation_0-gini:0.749371\tvalidation_1-gini:0.757825\n",
      "[9]\tvalidation_0-error:0.413166\tvalidation_1-error:0.410002\tvalidation_0-gini:0.748626\tvalidation_1-gini:0.756125\n",
      "[10]\tvalidation_0-error:0.413685\tvalidation_1-error:0.408274\tvalidation_0-gini:0.745963\tvalidation_1-gini:0.754031\n",
      "[11]\tvalidation_0-error:0.411524\tvalidation_1-error:0.408965\tvalidation_0-gini:0.742401\tvalidation_1-gini:0.750207\n",
      "[12]\tvalidation_0-error:0.411063\tvalidation_1-error:0.407006\tvalidation_0-gini:0.740989\tvalidation_1-gini:0.749063\n",
      "[13]\tvalidation_0-error:0.409334\tvalidation_1-error:0.406545\tvalidation_0-gini:0.738597\tvalidation_1-gini:0.747\n",
      "[14]\tvalidation_0-error:0.408845\tvalidation_1-error:0.404932\tvalidation_0-gini:0.737143\tvalidation_1-gini:0.745306\n",
      "[15]\tvalidation_0-error:0.408326\tvalidation_1-error:0.405969\tvalidation_0-gini:0.736355\tvalidation_1-gini:0.745249\n",
      "[16]\tvalidation_0-error:0.40919\tvalidation_1-error:0.405393\tvalidation_0-gini:0.735439\tvalidation_1-gini:0.744071\n",
      "[17]\tvalidation_0-error:0.408557\tvalidation_1-error:0.403319\tvalidation_0-gini:0.734027\tvalidation_1-gini:0.741844\n",
      "[18]\tvalidation_0-error:0.408614\tvalidation_1-error:0.401821\tvalidation_0-gini:0.732834\tvalidation_1-gini:0.740531\n",
      "[19]\tvalidation_0-error:0.407836\tvalidation_1-error:0.401705\tvalidation_0-gini:0.731255\tvalidation_1-gini:0.739715\n",
      "[20]\tvalidation_0-error:0.406799\tvalidation_1-error:0.402627\tvalidation_0-gini:0.730033\tvalidation_1-gini:0.737602\n",
      "[21]\tvalidation_0-error:0.406742\tvalidation_1-error:0.40378\tvalidation_0-gini:0.728889\tvalidation_1-gini:0.736894\n",
      "[22]\tvalidation_0-error:0.406079\tvalidation_1-error:0.402397\tvalidation_0-gini:0.728595\tvalidation_1-gini:0.736928\n",
      "[23]\tvalidation_0-error:0.407001\tvalidation_1-error:0.404586\tvalidation_0-gini:0.727607\tvalidation_1-gini:0.73535\n",
      "[24]\tvalidation_0-error:0.405503\tvalidation_1-error:0.404932\tvalidation_0-gini:0.726353\tvalidation_1-gini:0.733104\n",
      "[25]\tvalidation_0-error:0.405647\tvalidation_1-error:0.403088\tvalidation_0-gini:0.725869\tvalidation_1-gini:0.732933\n",
      "[26]\tvalidation_0-error:0.404466\tvalidation_1-error:0.403895\tvalidation_0-gini:0.724177\tvalidation_1-gini:0.731005\n",
      "[27]\tvalidation_0-error:0.403947\tvalidation_1-error:0.402743\tvalidation_0-gini:0.723066\tvalidation_1-gini:0.730469\n",
      "[28]\tvalidation_0-error:0.403918\tvalidation_1-error:0.403088\tvalidation_0-gini:0.722031\tvalidation_1-gini:0.730348\n",
      "[29]\tvalidation_0-error:0.402535\tvalidation_1-error:0.404356\tvalidation_0-gini:0.720954\tvalidation_1-gini:0.728939\n",
      "[30]\tvalidation_0-error:0.401325\tvalidation_1-error:0.404125\tvalidation_0-gini:0.720286\tvalidation_1-gini:0.728154\n",
      "[31]\tvalidation_0-error:0.401786\tvalidation_1-error:0.403204\tvalidation_0-gini:0.719929\tvalidation_1-gini:0.727696\n",
      "[32]\tvalidation_0-error:0.40193\tvalidation_1-error:0.402973\tvalidation_0-gini:0.719677\tvalidation_1-gini:0.727026\n",
      "[33]\tvalidation_0-error:0.401152\tvalidation_1-error:0.40159\tvalidation_0-gini:0.719101\tvalidation_1-gini:0.72596\n",
      "[34]\tvalidation_0-error:0.401613\tvalidation_1-error:0.400899\tvalidation_0-gini:0.718761\tvalidation_1-gini:0.725327\n",
      "[35]\tvalidation_0-error:0.400519\tvalidation_1-error:0.402051\tvalidation_0-gini:0.717951\tvalidation_1-gini:0.725421\n",
      "[36]\tvalidation_0-error:0.40049\tvalidation_1-error:0.40159\tvalidation_0-gini:0.71702\tvalidation_1-gini:0.724134\n",
      "[37]\tvalidation_0-error:0.400547\tvalidation_1-error:0.401245\tvalidation_0-gini:0.717133\tvalidation_1-gini:0.724426\n",
      "[38]\tvalidation_0-error:0.400259\tvalidation_1-error:0.399631\tvalidation_0-gini:0.715924\tvalidation_1-gini:0.724372\n",
      "[39]\tvalidation_0-error:0.400058\tvalidation_1-error:0.40136\tvalidation_0-gini:0.715286\tvalidation_1-gini:0.724046\n",
      "[40]\tvalidation_0-error:0.399395\tvalidation_1-error:0.40136\tvalidation_0-gini:0.714835\tvalidation_1-gini:0.72354\n",
      "[41]\tvalidation_0-error:0.399049\tvalidation_1-error:0.401245\tvalidation_0-gini:0.713712\tvalidation_1-gini:0.722797\n",
      "[42]\tvalidation_0-error:0.399251\tvalidation_1-error:0.400668\tvalidation_0-gini:0.71337\tvalidation_1-gini:0.722271\n",
      "[43]\tvalidation_0-error:0.399136\tvalidation_1-error:0.401705\tvalidation_0-gini:0.71293\tvalidation_1-gini:0.721655\n",
      "[44]\tvalidation_0-error:0.398992\tvalidation_1-error:0.400899\tvalidation_0-gini:0.712832\tvalidation_1-gini:0.720962\n",
      "[45]\tvalidation_0-error:0.398271\tvalidation_1-error:0.402512\tvalidation_0-gini:0.712241\tvalidation_1-gini:0.721068\n",
      "[46]\tvalidation_0-error:0.397436\tvalidation_1-error:0.40159\tvalidation_0-gini:0.711484\tvalidation_1-gini:0.721096\n",
      "[47]\tvalidation_0-error:0.397926\tvalidation_1-error:0.40136\tvalidation_0-gini:0.710919\tvalidation_1-gini:0.72087\n",
      "[48]\tvalidation_0-error:0.398185\tvalidation_1-error:0.400899\tvalidation_0-gini:0.71046\tvalidation_1-gini:0.720519\n",
      "[49]\tvalidation_0-error:0.397551\tvalidation_1-error:0.401475\tvalidation_0-gini:0.710086\tvalidation_1-gini:0.720372\n",
      "[50]\tvalidation_0-error:0.397205\tvalidation_1-error:0.401245\tvalidation_0-gini:0.710036\tvalidation_1-gini:0.720621\n",
      "[51]\tvalidation_0-error:0.397839\tvalidation_1-error:0.401014\tvalidation_0-gini:0.709842\tvalidation_1-gini:0.719937\n",
      "[52]\tvalidation_0-error:0.397465\tvalidation_1-error:0.401245\tvalidation_0-gini:0.708797\tvalidation_1-gini:0.71907\n",
      "[53]\tvalidation_0-error:0.397551\tvalidation_1-error:0.401245\tvalidation_0-gini:0.708398\tvalidation_1-gini:0.718628\n",
      "[54]\tvalidation_0-error:0.397177\tvalidation_1-error:0.402282\tvalidation_0-gini:0.708083\tvalidation_1-gini:0.718313\n",
      "[55]\tvalidation_0-error:0.397666\tvalidation_1-error:0.403088\tvalidation_0-gini:0.707569\tvalidation_1-gini:0.71795\n",
      "[56]\tvalidation_0-error:0.397638\tvalidation_1-error:0.401245\tvalidation_0-gini:0.707069\tvalidation_1-gini:0.717643\n",
      "[57]\tvalidation_0-error:0.397321\tvalidation_1-error:0.401705\tvalidation_0-gini:0.706598\tvalidation_1-gini:0.717531\n",
      "[58]\tvalidation_0-error:0.397292\tvalidation_1-error:0.400668\tvalidation_0-gini:0.706153\tvalidation_1-gini:0.717819\n",
      "[59]\tvalidation_0-error:0.396975\tvalidation_1-error:0.400438\tvalidation_0-gini:0.706038\tvalidation_1-gini:0.717642\n",
      "[60]\tvalidation_0-error:0.396514\tvalidation_1-error:0.400092\tvalidation_0-gini:0.70576\tvalidation_1-gini:0.717397\n",
      "[61]\tvalidation_0-error:0.396658\tvalidation_1-error:0.400668\tvalidation_0-gini:0.70565\tvalidation_1-gini:0.717171\n",
      "[62]\tvalidation_0-error:0.396456\tvalidation_1-error:0.400092\tvalidation_0-gini:0.705255\tvalidation_1-gini:0.717017\n",
      "[63]\tvalidation_0-error:0.395851\tvalidation_1-error:0.399516\tvalidation_0-gini:0.705036\tvalidation_1-gini:0.71705\n",
      "[64]\tvalidation_0-error:0.396111\tvalidation_1-error:0.40136\tvalidation_0-gini:0.704569\tvalidation_1-gini:0.717123\n",
      "[65]\tvalidation_0-error:0.396283\tvalidation_1-error:0.401129\tvalidation_0-gini:0.704615\tvalidation_1-gini:0.717159\n",
      "[66]\tvalidation_0-error:0.396082\tvalidation_1-error:0.400668\tvalidation_0-gini:0.704101\tvalidation_1-gini:0.717219\n",
      "[67]\tvalidation_0-error:0.396283\tvalidation_1-error:0.400553\tvalidation_0-gini:0.704079\tvalidation_1-gini:0.717149\n",
      "[68]\tvalidation_0-error:0.395995\tvalidation_1-error:0.400668\tvalidation_0-gini:0.703798\tvalidation_1-gini:0.716777\n",
      "[69]\tvalidation_0-error:0.395794\tvalidation_1-error:0.400438\tvalidation_0-gini:0.7037\tvalidation_1-gini:0.716831\n",
      "[70]\tvalidation_0-error:0.395592\tvalidation_1-error:0.400207\tvalidation_0-gini:0.703628\tvalidation_1-gini:0.716372\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[71]\tvalidation_0-error:0.395621\tvalidation_1-error:0.399401\tvalidation_0-gini:0.70334\tvalidation_1-gini:0.716037\n",
      "[72]\tvalidation_0-error:0.395765\tvalidation_1-error:0.399401\tvalidation_0-gini:0.703065\tvalidation_1-gini:0.716008\n",
      "[73]\tvalidation_0-error:0.395477\tvalidation_1-error:0.399286\tvalidation_0-gini:0.7029\tvalidation_1-gini:0.715944\n",
      "[74]\tvalidation_0-error:0.395448\tvalidation_1-error:0.399286\tvalidation_0-gini:0.7029\tvalidation_1-gini:0.715944\n",
      "[75]\tvalidation_0-error:0.395736\tvalidation_1-error:0.399516\tvalidation_0-gini:0.702791\tvalidation_1-gini:0.715969\n",
      "[76]\tvalidation_0-error:0.395707\tvalidation_1-error:0.400323\tvalidation_0-gini:0.702703\tvalidation_1-gini:0.71575\n",
      "[77]\tvalidation_0-error:0.395678\tvalidation_1-error:0.399977\tvalidation_0-gini:0.702577\tvalidation_1-gini:0.715176\n",
      "[78]\tvalidation_0-error:0.395851\tvalidation_1-error:0.400207\tvalidation_0-gini:0.702577\tvalidation_1-gini:0.715176\n",
      "[79]\tvalidation_0-error:0.395707\tvalidation_1-error:0.399977\tvalidation_0-gini:0.702577\tvalidation_1-gini:0.715176\n",
      "[80]\tvalidation_0-error:0.395707\tvalidation_1-error:0.399977\tvalidation_0-gini:0.702577\tvalidation_1-gini:0.715176\n",
      "[81]\tvalidation_0-error:0.396168\tvalidation_1-error:0.399516\tvalidation_0-gini:0.702304\tvalidation_1-gini:0.714953\n",
      "[82]\tvalidation_0-error:0.396111\tvalidation_1-error:0.399401\tvalidation_0-gini:0.702253\tvalidation_1-gini:0.71487\n",
      "[83]\tvalidation_0-error:0.396082\tvalidation_1-error:0.399401\tvalidation_0-gini:0.702253\tvalidation_1-gini:0.71487\n",
      "[84]\tvalidation_0-error:0.396197\tvalidation_1-error:0.398709\tvalidation_0-gini:0.702107\tvalidation_1-gini:0.714389\n",
      "[85]\tvalidation_0-error:0.395851\tvalidation_1-error:0.398248\tvalidation_0-gini:0.701759\tvalidation_1-gini:0.714627\n",
      "[86]\tvalidation_0-error:0.395794\tvalidation_1-error:0.398364\tvalidation_0-gini:0.701475\tvalidation_1-gini:0.71471\n",
      "[87]\tvalidation_0-error:0.395304\tvalidation_1-error:0.398248\tvalidation_0-gini:0.701339\tvalidation_1-gini:0.714496\n",
      "[88]\tvalidation_0-error:0.395362\tvalidation_1-error:0.398364\tvalidation_0-gini:0.701339\tvalidation_1-gini:0.714496\n",
      "[89]\tvalidation_0-error:0.395621\tvalidation_1-error:0.398248\tvalidation_0-gini:0.701339\tvalidation_1-gini:0.714496\n",
      "[90]\tvalidation_0-error:0.395707\tvalidation_1-error:0.398364\tvalidation_0-gini:0.701326\tvalidation_1-gini:0.714316\n",
      "[91]\tvalidation_0-error:0.395707\tvalidation_1-error:0.398364\tvalidation_0-gini:0.701326\tvalidation_1-gini:0.714316\n",
      "[92]\tvalidation_0-error:0.39565\tvalidation_1-error:0.397557\tvalidation_0-gini:0.701033\tvalidation_1-gini:0.714108\n",
      "[93]\tvalidation_0-error:0.395333\tvalidation_1-error:0.397788\tvalidation_0-gini:0.701033\tvalidation_1-gini:0.714108\n",
      "[94]\tvalidation_0-error:0.395419\tvalidation_1-error:0.397672\tvalidation_0-gini:0.701033\tvalidation_1-gini:0.714108\n",
      "[95]\tvalidation_0-error:0.39565\tvalidation_1-error:0.397557\tvalidation_0-gini:0.700781\tvalidation_1-gini:0.71423\n",
      "[96]\tvalidation_0-error:0.39565\tvalidation_1-error:0.397672\tvalidation_0-gini:0.700781\tvalidation_1-gini:0.714231\n",
      "[97]\tvalidation_0-error:0.39565\tvalidation_1-error:0.397672\tvalidation_0-gini:0.700781\tvalidation_1-gini:0.714231\n",
      "[98]\tvalidation_0-error:0.395678\tvalidation_1-error:0.397788\tvalidation_0-gini:0.700781\tvalidation_1-gini:0.71423\n",
      "[99]\tvalidation_0-error:0.395506\tvalidation_1-error:0.397672\tvalidation_0-gini:0.700781\tvalidation_1-gini:0.71423\n",
      "[100]\tvalidation_0-error:0.395419\tvalidation_1-error:0.398364\tvalidation_0-gini:0.700628\tvalidation_1-gini:0.71426\n",
      "[101]\tvalidation_0-error:0.395506\tvalidation_1-error:0.398594\tvalidation_0-gini:0.700628\tvalidation_1-gini:0.71426\n",
      "[102]\tvalidation_0-error:0.395448\tvalidation_1-error:0.398594\tvalidation_0-gini:0.700628\tvalidation_1-gini:0.71426\n",
      "[103]\tvalidation_0-error:0.395448\tvalidation_1-error:0.398594\tvalidation_0-gini:0.700628\tvalidation_1-gini:0.71426\n",
      "[104]\tvalidation_0-error:0.395448\tvalidation_1-error:0.398364\tvalidation_0-gini:0.700628\tvalidation_1-gini:0.71426\n",
      "[105]\tvalidation_0-error:0.395678\tvalidation_1-error:0.397672\tvalidation_0-gini:0.700612\tvalidation_1-gini:0.714255\n",
      "[106]\tvalidation_0-error:0.395678\tvalidation_1-error:0.397672\tvalidation_0-gini:0.700612\tvalidation_1-gini:0.714255\n",
      "[107]\tvalidation_0-error:0.39565\tvalidation_1-error:0.398018\tvalidation_0-gini:0.700612\tvalidation_1-gini:0.714255\n",
      "[108]\tvalidation_0-error:0.395333\tvalidation_1-error:0.398248\tvalidation_0-gini:0.700401\tvalidation_1-gini:0.714217\n",
      "[109]\tvalidation_0-error:0.395218\tvalidation_1-error:0.398709\tvalidation_0-gini:0.700333\tvalidation_1-gini:0.713972\n",
      "[110]\tvalidation_0-error:0.395362\tvalidation_1-error:0.398825\tvalidation_0-gini:0.700333\tvalidation_1-gini:0.713972\n",
      "[111]\tvalidation_0-error:0.39516\tvalidation_1-error:0.398825\tvalidation_0-gini:0.700333\tvalidation_1-gini:0.713972\n",
      "[112]\tvalidation_0-error:0.394555\tvalidation_1-error:0.397788\tvalidation_0-gini:0.700018\tvalidation_1-gini:0.713571\n",
      "[113]\tvalidation_0-error:0.394958\tvalidation_1-error:0.397903\tvalidation_0-gini:0.69999\tvalidation_1-gini:0.713644\n",
      "[114]\tvalidation_0-error:0.395016\tvalidation_1-error:0.397903\tvalidation_0-gini:0.69999\tvalidation_1-gini:0.713644\n",
      "[115]\tvalidation_0-error:0.395218\tvalidation_1-error:0.397903\tvalidation_0-gini:0.69999\tvalidation_1-gini:0.713644\n",
      "[116]\tvalidation_0-error:0.395073\tvalidation_1-error:0.397903\tvalidation_0-gini:0.69999\tvalidation_1-gini:0.713644\n",
      "[117]\tvalidation_0-error:0.395073\tvalidation_1-error:0.397903\tvalidation_0-gini:0.69999\tvalidation_1-gini:0.713644\n",
      "[118]\tvalidation_0-error:0.394843\tvalidation_1-error:0.397903\tvalidation_0-gini:0.69999\tvalidation_1-gini:0.713644\n",
      "[119]\tvalidation_0-error:0.394699\tvalidation_1-error:0.397442\tvalidation_0-gini:0.699862\tvalidation_1-gini:0.713532\n",
      "[120]\tvalidation_0-error:0.394584\tvalidation_1-error:0.396981\tvalidation_0-gini:0.699671\tvalidation_1-gini:0.713446\n",
      "[121]\tvalidation_0-error:0.394612\tvalidation_1-error:0.396866\tvalidation_0-gini:0.699671\tvalidation_1-gini:0.713445\n",
      "[122]\tvalidation_0-error:0.394612\tvalidation_1-error:0.39675\tvalidation_0-gini:0.699671\tvalidation_1-gini:0.713445\n",
      "[123]\tvalidation_0-error:0.394612\tvalidation_1-error:0.396866\tvalidation_0-gini:0.699671\tvalidation_1-gini:0.713446\n",
      "[124]\tvalidation_0-error:0.394555\tvalidation_1-error:0.39675\tvalidation_0-gini:0.699671\tvalidation_1-gini:0.713446\n",
      "[125]\tvalidation_0-error:0.39467\tvalidation_1-error:0.396866\tvalidation_0-gini:0.699671\tvalidation_1-gini:0.713446\n",
      "[126]\tvalidation_0-error:0.394612\tvalidation_1-error:0.397211\tvalidation_0-gini:0.699537\tvalidation_1-gini:0.713566\n",
      "[127]\tvalidation_0-error:0.394699\tvalidation_1-error:0.397096\tvalidation_0-gini:0.699537\tvalidation_1-gini:0.713566\n",
      "[128]\tvalidation_0-error:0.39467\tvalidation_1-error:0.396981\tvalidation_0-gini:0.699537\tvalidation_1-gini:0.713566\n",
      "[129]\tvalidation_0-error:0.39467\tvalidation_1-error:0.396981\tvalidation_0-gini:0.699537\tvalidation_1-gini:0.713566\n",
      "[130]\tvalidation_0-error:0.394353\tvalidation_1-error:0.397327\tvalidation_0-gini:0.699114\tvalidation_1-gini:0.713572\n",
      "[131]\tvalidation_0-error:0.394324\tvalidation_1-error:0.397211\tvalidation_0-gini:0.699114\tvalidation_1-gini:0.713572\n",
      "[132]\tvalidation_0-error:0.394411\tvalidation_1-error:0.397327\tvalidation_0-gini:0.699114\tvalidation_1-gini:0.713572\n",
      "[133]\tvalidation_0-error:0.393777\tvalidation_1-error:0.397903\tvalidation_0-gini:0.698668\tvalidation_1-gini:0.713375\n",
      "[134]\tvalidation_0-error:0.39395\tvalidation_1-error:0.397903\tvalidation_0-gini:0.698668\tvalidation_1-gini:0.713374\n",
      "[135]\tvalidation_0-error:0.39395\tvalidation_1-error:0.397903\tvalidation_0-gini:0.698668\tvalidation_1-gini:0.713374\n",
      "[136]\tvalidation_0-error:0.393777\tvalidation_1-error:0.397903\tvalidation_0-gini:0.698668\tvalidation_1-gini:0.713374\n",
      "[137]\tvalidation_0-error:0.393748\tvalidation_1-error:0.397903\tvalidation_0-gini:0.698668\tvalidation_1-gini:0.713374\n",
      "[138]\tvalidation_0-error:0.394065\tvalidation_1-error:0.397788\tvalidation_0-gini:0.698606\tvalidation_1-gini:0.713279\n",
      "[139]\tvalidation_0-error:0.394036\tvalidation_1-error:0.398018\tvalidation_0-gini:0.698606\tvalidation_1-gini:0.713279\n",
      "[140]\tvalidation_0-error:0.394123\tvalidation_1-error:0.397672\tvalidation_0-gini:0.698606\tvalidation_1-gini:0.713279\n",
      "[141]\tvalidation_0-error:0.394123\tvalidation_1-error:0.397672\tvalidation_0-gini:0.698606\tvalidation_1-gini:0.713279\n",
      "[142]\tvalidation_0-error:0.394065\tvalidation_1-error:0.397557\tvalidation_0-gini:0.698606\tvalidation_1-gini:0.713279\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[143]\tvalidation_0-error:0.394008\tvalidation_1-error:0.397788\tvalidation_0-gini:0.698606\tvalidation_1-gini:0.713279\n",
      "[144]\tvalidation_0-error:0.394036\tvalidation_1-error:0.397672\tvalidation_0-gini:0.698606\tvalidation_1-gini:0.713279\n",
      "[145]\tvalidation_0-error:0.394008\tvalidation_1-error:0.398018\tvalidation_0-gini:0.698449\tvalidation_1-gini:0.713019\n",
      "[146]\tvalidation_0-error:0.394008\tvalidation_1-error:0.398018\tvalidation_0-gini:0.698449\tvalidation_1-gini:0.713019\n",
      "[147]\tvalidation_0-error:0.394008\tvalidation_1-error:0.398018\tvalidation_0-gini:0.698448\tvalidation_1-gini:0.713019\n",
      "[148]\tvalidation_0-error:0.393921\tvalidation_1-error:0.397788\tvalidation_0-gini:0.698459\tvalidation_1-gini:0.713183\n",
      "[149]\tvalidation_0-error:0.393748\tvalidation_1-error:0.397903\tvalidation_0-gini:0.698352\tvalidation_1-gini:0.713064\n",
      "[150]\tvalidation_0-error:0.393863\tvalidation_1-error:0.398248\tvalidation_0-gini:0.698352\tvalidation_1-gini:0.713064\n",
      "[151]\tvalidation_0-error:0.394036\tvalidation_1-error:0.397788\tvalidation_0-gini:0.698047\tvalidation_1-gini:0.71277\n",
      "[152]\tvalidation_0-error:0.394036\tvalidation_1-error:0.397788\tvalidation_0-gini:0.698047\tvalidation_1-gini:0.71277\n",
      "[153]\tvalidation_0-error:0.393172\tvalidation_1-error:0.398133\tvalidation_0-gini:0.697906\tvalidation_1-gini:0.71255\n",
      "[154]\tvalidation_0-error:0.393086\tvalidation_1-error:0.398133\tvalidation_0-gini:0.697906\tvalidation_1-gini:0.712551\n",
      "[155]\tvalidation_0-error:0.393258\tvalidation_1-error:0.398018\tvalidation_0-gini:0.697906\tvalidation_1-gini:0.712551\n",
      "[156]\tvalidation_0-error:0.393201\tvalidation_1-error:0.398133\tvalidation_0-gini:0.697906\tvalidation_1-gini:0.712551\n",
      "[157]\tvalidation_0-error:0.393258\tvalidation_1-error:0.398018\tvalidation_0-gini:0.697906\tvalidation_1-gini:0.71255\n",
      "[158]\tvalidation_0-error:0.393114\tvalidation_1-error:0.398133\tvalidation_0-gini:0.697906\tvalidation_1-gini:0.712551\n",
      "[159]\tvalidation_0-error:0.393201\tvalidation_1-error:0.398133\tvalidation_0-gini:0.697906\tvalidation_1-gini:0.712551\n",
      "[160]\tvalidation_0-error:0.393316\tvalidation_1-error:0.397903\tvalidation_0-gini:0.697906\tvalidation_1-gini:0.712551\n",
      "[161]\tvalidation_0-error:0.393287\tvalidation_1-error:0.398133\tvalidation_0-gini:0.697906\tvalidation_1-gini:0.71255\n",
      "[162]\tvalidation_0-error:0.393172\tvalidation_1-error:0.398018\tvalidation_0-gini:0.697906\tvalidation_1-gini:0.712551\n",
      "[163]\tvalidation_0-error:0.393172\tvalidation_1-error:0.398018\tvalidation_0-gini:0.697906\tvalidation_1-gini:0.712551\n",
      "[164]\tvalidation_0-error:0.393201\tvalidation_1-error:0.398018\tvalidation_0-gini:0.697906\tvalidation_1-gini:0.712551\n",
      "[165]\tvalidation_0-error:0.39323\tvalidation_1-error:0.397903\tvalidation_0-gini:0.697838\tvalidation_1-gini:0.712541\n",
      "[166]\tvalidation_0-error:0.393143\tvalidation_1-error:0.398018\tvalidation_0-gini:0.697838\tvalidation_1-gini:0.712542\n",
      "[167]\tvalidation_0-error:0.393114\tvalidation_1-error:0.398018\tvalidation_0-gini:0.697838\tvalidation_1-gini:0.712542\n",
      "[168]\tvalidation_0-error:0.393201\tvalidation_1-error:0.397903\tvalidation_0-gini:0.697838\tvalidation_1-gini:0.712542\n",
      "[169]\tvalidation_0-error:0.393258\tvalidation_1-error:0.398133\tvalidation_0-gini:0.697695\tvalidation_1-gini:0.712295\n",
      "[170]\tvalidation_0-error:0.393143\tvalidation_1-error:0.397557\tvalidation_0-gini:0.697568\tvalidation_1-gini:0.712198\n",
      "[171]\tvalidation_0-error:0.392884\tvalidation_1-error:0.396635\tvalidation_0-gini:0.697341\tvalidation_1-gini:0.711913\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "       colsample_bynode=1, colsample_bytree=0.8, gamma=10,\n",
       "       learning_rate=0.07, max_delta_step=0, max_depth=4,\n",
       "       min_child_weight=6, missing=None, n_estimators=172, n_jobs=1,\n",
       "       nthread=None, objective='binary:logistic', random_state=123,\n",
       "       reg_alpha=8, reg_lambda=1.3, scale_pos_weight=1, seed=None,\n",
       "       silent=None, subsample=0.8, verbosity=1)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eval_set = [(X_train, y_train), (X_test, y_test)]\n",
    "xg_cl.fit(X_train, y_train, early_stopping_rounds=50, eval_metric=gini_xgb, eval_set=eval_set, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = xg_cl.evals_result()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_xg = xg_cl.predict(X_test_orig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_xg = xg_cl.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy_score:  0.9625513469922633\n",
      "confusion_matrix: \n",
      " [[114585      0]\n",
      " [  4458      0]]\n",
      "classification_report: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      1.00      0.98    114585\n",
      "           1       0.00      0.00      0.00      4458\n",
      "\n",
      "   micro avg       0.96      0.96      0.96    119043\n",
      "   macro avg       0.48      0.50      0.49    119043\n",
      "weighted avg       0.93      0.96      0.94    119043\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Supratik\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Supratik\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Supratik\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "print(\"accuracy_score: \", accuracy_score(y_test_orig, pred_xg))\n",
    "print(\"confusion_matrix: \\n\", confusion_matrix(y_test_orig, pred_xg))\n",
    "print(\"classification_report: \\n\", classification_report(y_test_orig, pred_xg))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy_score:  0.6033648306061304\n",
      "confusion_matrix: \n",
      " [[2671 1570]\n",
      " [1872 2565]]\n",
      "classification_report: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.59      0.63      0.61      4241\n",
      "           1       0.62      0.58      0.60      4437\n",
      "\n",
      "   micro avg       0.60      0.60      0.60      8678\n",
      "   macro avg       0.60      0.60      0.60      8678\n",
      "weighted avg       0.60      0.60      0.60      8678\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"accuracy_score: \", accuracy_score(y_test, pred_xg))\n",
    "print(\"confusion_matrix: \\n\", confusion_matrix(y_test, pred_xg))\n",
    "print(\"classification_report: \\n\", classification_report(y_test, pred_xg))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gini: 0.050, Max. Gini: 0.244, Normalized Gini: 0.203\n"
     ]
    }
   ],
   "source": [
    "gini_predictions = gini(y_test_orig, pred_xg)\n",
    "gini_max = gini(y_test_orig, y_test_orig)\n",
    "ngini= gini_normalized(y_test_orig, pred_xg)\n",
    "print('Gini: %.3f, Max. Gini: %.3f, Normalized Gini: %.3f' % (gini_predictions, gini_max, ngini))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gini: 0.052, Max. Gini: 0.244, Normalized Gini: 0.212\n"
     ]
    }
   ],
   "source": [
    "gini_predictions = gini(y_test, pred_xg)\n",
    "gini_max = gini(y_test, y_test)\n",
    "ngini= gini_normalized(y_test, pred_xg)\n",
    "print('Gini: %.3f, Max. Gini: %.3f, Normalized Gini: %.3f' % (gini_predictions, gini_max, ngini))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "XGB_pred_prob = list(map(lambda x: x[1],xg_cl.predict_proba(X_test_orig)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "XGB_pred_prob = list(map(lambda x: x[1],xg_cl.predict_proba(X_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gini: 0.069, Max. Gini: 0.244, Normalized Gini: 0.281\n"
     ]
    }
   ],
   "source": [
    "gini_predictions = gini(y_test_orig, XGB_pred_prob)\n",
    "gini_max = gini(y_test_orig, y_test_orig)\n",
    "ngini= gini_normalized(y_test_orig, XGB_pred_prob)\n",
    "print('Gini: %.3f, Max. Gini: %.3f, Normalized Gini: %.3f' % (gini_predictions, gini_max, ngini))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gini: 0.070, Max. Gini: 0.244, Normalized Gini: 0.288\n"
     ]
    }
   ],
   "source": [
    "gini_predictions = gini(y_test, XGB_pred_prob)\n",
    "gini_max = gini(y_test, y_test)\n",
    "ngini= gini_normalized(y_test, XGB_pred_prob)\n",
    "print('Gini: %.3f, Max. Gini: %.3f, Normalized Gini: %.3f' % (gini_predictions, gini_max, ngini))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(34710, 34)"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_orig.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_unscaled = test.drop(['id','ps_car_01_cat','ps_car_02_cat','ps_car_03_cat','ps_car_05_cat',\n",
    "                          'ps_car_07_cat','ps_car_09_cat','ps_car_11','ps_car_12','ps_car_14','ps_ind_02_cat',\n",
    "                          'ps_ind_04_cat','ps_ind_05_cat','ps_reg_03','ps_car_04_cat_enc', 'ps_car_06_cat_enc', 'ps_car_08_cat_enc',\n",
    "       'ps_car_10_cat_enc', 'ps_car_11_cat_enc', 'ps_car_01_cat_mod_enc',\n",
    "       'ps_car_02_cat_mod_enc', 'ps_car_07_cat_mod_enc',\n",
    "       'ps_car_09_cat_mod_enc', 'ps_ind_02_cat_mod_enc',\n",
    "       'ps_ind_04_cat_mod_enc', 'ps_ind_05_cat_mod_enc'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_unscaled = test_unscaled.drop(col_to_drop, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_pred = list(map(lambda x: x[1],xg_cl.predict_proba(test_unscaled)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_pred = list(map(lambda x: x[1],xg_cl.predict_proba(test_unscaled)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission = pd.concat([test['id'], pd.DataFrame({'target':test_pred})], axis=1)\n",
    "submission.to_csv('submission.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Light GBM Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install lightgbm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "import lightgbm as lgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Supratik\\Anaconda3\\lib\\site-packages\\lightgbm\\engine.py:118: UserWarning: Found `num_iterations` in params. Will use it instead of argument\n",
      "  warnings.warn(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n"
     ]
    }
   ],
   "source": [
    "lgb_params = {\n",
    "                'learning_rate': 0.02,\n",
    "                'num_iterations': 700,\n",
    "                'max_bin': 15,\n",
    "                'subsample': 0.8,\n",
    "                'subsample_freq': 10,\n",
    "                'colsample_bytree': 0.8,\n",
    "                'min_child_samples': 800,\n",
    "                'random_state': 123,\n",
    "                'scale_pos_weight':3\n",
    "             }\n",
    "\n",
    "model_lgb = lgb.train(lgb_params, lgb.Dataset(X_train_orig, label=y_train_orig), 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [],
   "source": [
    "lgb_params = {\n",
    "               'feature_fraction': 0.70, #0.50\n",
    "               'feature_fraction_seed':1000,\n",
    "               'metric': 'binary_logloss',\n",
    "               'nthread':-1, \n",
    "               'min_data_in_leaf': 2**4, \n",
    "               'bagging_fraction': 0.50, #0.50\n",
    "               'bagging_freq':1,\n",
    "               'learning_rate': 0.03, #0.03\n",
    "               'objective': 'binary', \n",
    "               'bagging_seed': 1000, \n",
    "               'num_leaves': 2**17,#2**15\n",
    "               'max_depth':2**10,\n",
    "               'verbose':1,\n",
    "               'random_state':123,\n",
    "               #'categorical_feature': '''name:ps_calc_15_bin,ps_calc_16_bin,ps_calc_17_bin,ps_calc_18_bin,\n",
    "                #                         ps_calc_19_bin,ps_calc_20_bin,ps_ind_02_cat_mod,ps_ind_04_cat_mod,\n",
    "                 #                        ps_ind_05_cat_mod,ps_ind_06_bin,ps_ind_07_bin,ps_ind_08_bin,ps_ind_09_bin,\n",
    "                 #                        ps_ind_10_bin,ps_ind_11_bin,ps_ind_12_bin,ps_ind_13_bin,ps_ind_16_bin,\n",
    "                  #                       ps_ind_17_bin,ps_ind_18_bin,ps_car_01_cat_mod,ps_car_02_cat_mod,\n",
    "                  #                       ps_car_04_cat,ps_car_06_cat,ps_car_07_cat_mod,ps_car_08_cat,\n",
    "                   #                      ps_car_09_cat_mod,ps_car_10_cat,ps_car_11_cat'''\n",
    "              }\n",
    "\n",
    "model_lgb = lgb.train(lgb_params, lgb.Dataset(X_train, label=y_train), 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test R-squared for LightGBM is 0.011037\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import r2_score\n",
    "pred_lgb = model_lgb.predict(X_test_orig)\n",
    "print('Test R-squared for LightGBM is %f' % r2_score(y_test_orig, pred_lgb))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test R-squared for LightGBM is 0.032001\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import r2_score\n",
    "pred_lgb = model_lgb.predict(X_test)\n",
    "print('Test R-squared for LightGBM is %f' % r2_score(y_test, pred_lgb))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.038880264928686174\n"
     ]
    }
   ],
   "source": [
    "fpr, tpr, thresholds =roc_curve(y_test_orig, pred_lgb)\n",
    "\n",
    "threshold=cutoff_youdens_j(fpr,tpr,thresholds)\n",
    "\n",
    "print(threshold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.47667327541317334\n"
     ]
    }
   ],
   "source": [
    "fpr, tpr, thresholds =roc_curve(y_test, pred_lgb)\n",
    "\n",
    "threshold=cutoff_youdens_j(fpr,tpr,thresholds)\n",
    "\n",
    "print(threshold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions_lgb = list(map(lambda x: 1 if x > threshold else 0,pred_lgb))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions_lgb = list(map(lambda x: 1 if x > threshold else 0,pred_lgb))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy_score:  0.6075132519013597\n",
      "confusion_matrix: \n",
      " [[2639 1602]\n",
      " [1804 2633]]\n",
      "classification_report: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.59      0.62      0.61      4241\n",
      "           1       0.62      0.59      0.61      4437\n",
      "\n",
      "   micro avg       0.61      0.61      0.61      8678\n",
      "   macro avg       0.61      0.61      0.61      8678\n",
      "weighted avg       0.61      0.61      0.61      8678\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"accuracy_score: \", accuracy_score(y_test_orig, predictions_lgb))\n",
    "print(\"confusion_matrix: \\n\", confusion_matrix(y_test_orig, predictions_lgb))\n",
    "print(\"classification_report: \\n\", classification_report(y_test_orig, predictions_lgb))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy_score:  0.5826227241299838\n",
      "confusion_matrix: \n",
      " [[2239 2002]\n",
      " [1620 2817]]\n",
      "classification_report: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.58      0.53      0.55      4241\n",
      "           1       0.58      0.63      0.61      4437\n",
      "\n",
      "   micro avg       0.58      0.58      0.58      8678\n",
      "   macro avg       0.58      0.58      0.58      8678\n",
      "weighted avg       0.58      0.58      0.58      8678\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"accuracy_score: \", accuracy_score(y_test, predictions_lgb))\n",
    "print(\"confusion_matrix: \\n\", confusion_matrix(y_test, predictions_lgb))\n",
    "print(\"classification_report: \\n\", classification_report(y_test, predictions_lgb))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gini: 0.054, Max. Gini: 0.244, Normalized Gini: 0.222\n"
     ]
    }
   ],
   "source": [
    "gini_predictions = gini(y_test_orig, predictions_lgb)\n",
    "gini_max = gini(y_test_orig, y_test_orig)\n",
    "ngini= gini_normalized(y_test_orig, predictions_lgb)\n",
    "print('Gini: %.3f, Max. Gini: %.3f, Normalized Gini: %.3f' % (gini_predictions, gini_max, ngini))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gini: 0.041, Max. Gini: 0.244, Normalized Gini: 0.169\n"
     ]
    }
   ],
   "source": [
    "gini_predictions = gini(y_test, predictions_lgb)\n",
    "gini_max = gini(y_test, y_test)\n",
    "ngini= gini_normalized(y_test, predictions_lgb)\n",
    "print('Gini: %.3f, Max. Gini: %.3f, Normalized Gini: %.3f' % (gini_predictions, gini_max, ngini))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gini: 0.136, Max. Gini: 0.481, Normalized Gini: 0.282\n"
     ]
    }
   ],
   "source": [
    "gini_predictions = gini(y_test_orig, pred_lgb)\n",
    "gini_max = gini(y_test_orig, y_test_orig)\n",
    "ngini= gini_normalized(y_test_orig, pred_lgb)\n",
    "print('Gini: %.3f, Max. Gini: %.3f, Normalized Gini: %.3f' % (gini_predictions, gini_max, ngini))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gini: 0.054, Max. Gini: 0.244, Normalized Gini: 0.222\n"
     ]
    }
   ],
   "source": [
    "gini_predictions = gini(y_test, pred_lgb)\n",
    "gini_max = gini(y_test, y_test)\n",
    "ngini= gini_normalized(y_test, pred_lgb)\n",
    "print('Gini: %.3f, Max. Gini: %.3f, Normalized Gini: %.3f' % (gini_predictions, gini_max, ngini))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_pred = model_lgb.predict(test_unscaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission = pd.concat([test['id'], pd.DataFrame({'target':test_pred})], axis=1)\n",
    "submission.to_csv('submission.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# K Nearest Neighbors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 301,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Supratik\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\data.py:645: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by StandardScaler.\n",
      "  return self.partial_fit(X, y)\n",
      "C:\\Users\\Supratik\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:3: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by StandardScaler.\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n",
      "C:\\Users\\Supratik\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:4: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by StandardScaler.\n",
      "  after removing the cwd from sys.path.\n"
     ]
    }
   ],
   "source": [
    "'''scaler = StandardScaler()\n",
    "scaler.fit(X_train)\n",
    "scaled_X_train = scaler.transform(X_train)\n",
    "scaled_X_test = scaler.transform(X_test)'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''df_scaled_X_train = pd.DataFrame(scaled_X_train,columns=X_train.columns)\n",
    "df_scaled_X_test = pd.DataFrame(scaled_X_test,columns=X_test.columns)'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "errors = []\n",
    "for i in range(1,40):\n",
    "    KNN = KNeighborsClassifier(n_neighbors=i)\n",
    "    KNN.fit(X_train, y_train)\n",
    "    pred_i = KNN.predict(X_test)\n",
    "    errors.append(np.mean(np.abs(y_test - pred_i)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 302,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn = KNeighborsClassifier(n_neighbors=37) # NOW WITH K=30\n",
    "\n",
    "knn.fit(X_train,y_train)\n",
    "pred_KNN = knn.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 303,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WITH K=37\n",
      "\n",
      "\n",
      "0.5472459091956672\n",
      "\n",
      "\n",
      "[[2550 1691]\n",
      " [2238 2199]]\n",
      "\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.53      0.60      0.56      4241\n",
      "           1       0.57      0.50      0.53      4437\n",
      "\n",
      "   micro avg       0.55      0.55      0.55      8678\n",
      "   macro avg       0.55      0.55      0.55      8678\n",
      "weighted avg       0.55      0.55      0.55      8678\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "\n",
    "print('WITH K=37')\n",
    "print('\\n')\n",
    "print(accuracy_score(y_test,pred_KNN))\n",
    "print('\\n')\n",
    "print(confusion_matrix(y_test,pred_KNN))\n",
    "print('\\n')\n",
    "print(classification_report(y_test,pred_KNN))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 304,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gini: 0.026, Max. Gini: 0.244, Normalized Gini: 0.105\n"
     ]
    }
   ],
   "source": [
    "gini_predictions = gini(y_test, pred_KNN)\n",
    "gini_max = gini(y_test, y_test)\n",
    "ngini= gini_normalized(y_test, pred_KNN)\n",
    "print('Gini: %.3f, Max. Gini: %.3f, Normalized Gini: %.3f' % (gini_predictions, gini_max, ngini))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 305,
   "metadata": {},
   "outputs": [],
   "source": [
    "KNN_pred_prob = list(map(lambda x: x[1],knn.predict_proba(X_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 306,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gini: 0.033, Max. Gini: 0.244, Normalized Gini: 0.136\n"
     ]
    }
   ],
   "source": [
    "gini_predictions = gini(y_test, KNN_pred_prob)\n",
    "gini_max = gini(y_test, y_test)\n",
    "ngini= gini_normalized(y_test, KNN_pred_prob)\n",
    "print('Gini: %.3f, Max. Gini: %.3f, Normalized Gini: %.3f' % (gini_predictions, gini_max, ngini))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_pred = knn.predict_proba(test.drop(['id','ps_car_01_cat','ps_car_02_cat','ps_car_03_cat','ps_car_05_cat',\n",
    "                          'ps_car_07_cat','ps_car_09_cat','ps_car_11','ps_car_12','ps_car_14','ps_ind_02_cat',\n",
    "                          'ps_ind_04_cat','ps_ind_05_cat','ps_reg_03'], axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "KNN_pred_prob = list(map(lambda x: x[1],test_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission = pd.concat([test['id'], pd.DataFrame({'target':KNN_pred_prob})], axis=1)\n",
    "submission.to_csv('submission.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SVM Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 307,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 308,
   "metadata": {},
   "outputs": [],
   "source": [
    "SVC_Mod = SVC(C=2, gamma = 0.1, kernel='rbf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 309,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(C=2, cache_size=200, class_weight=None, coef0=0.0,\n",
       "  decision_function_shape='ovr', degree=3, gamma=0.1, kernel='rbf',\n",
       "  max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
       "  tol=0.001, verbose=False)"
      ]
     },
     "execution_count": 309,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "SVC_Mod.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 310,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_SVM = SVC_Mod.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 311,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5419451486517631\n",
      "\n",
      "\n",
      "[[2266 1975]\n",
      " [2000 2437]]\n",
      "\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.53      0.53      0.53      4241\n",
      "           1       0.55      0.55      0.55      4437\n",
      "\n",
      "   micro avg       0.54      0.54      0.54      8678\n",
      "   macro avg       0.54      0.54      0.54      8678\n",
      "weighted avg       0.54      0.54      0.54      8678\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(accuracy_score(y_test,pred_SVM))\n",
    "print('\\n')\n",
    "print(confusion_matrix(y_test,pred_SVM))\n",
    "print('\\n')\n",
    "print(classification_report(y_test,pred_SVM))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 312,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gini: 0.022, Max. Gini: 0.244, Normalized Gini: 0.091\n"
     ]
    }
   ],
   "source": [
    "gini_predictions = gini(y_test, pred_SVM)\n",
    "gini_max = gini(y_test, y_test)\n",
    "ngini= gini_normalized(y_test, pred_SVM)\n",
    "print('Gini: %.3f, Max. Gini: %.3f, Normalized Gini: %.3f' % (gini_predictions, gini_max, ngini))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''SVC_pred_prob = list(map(lambda x: x[1],SVC_Mod.predict_proba(X_test)))'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''gini_predictions = gini(y_test, SVC_pred_prob)\n",
    "gini_max = gini(y_test, y_test)\n",
    "ngini= gini_normalized(y_test, SVC_pred_prob)\n",
    "print('Gini: %.3f, Max. Gini: %.3f, Normalized Gini: %.3f' % (gini_predictions, gini_max, ngini))'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SVM using Grid Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = {'C' : [0.1,0.5,1,2,5], 'gamma' : [0.1, 0.01, 0.001, 1], 'kernel' : ['rbf','poly']}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "Grid = GridSearchCV(SVC(),param_grid, cv=5, refit=True, verbose=3, n_jobs=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 40 candidates, totalling 200 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n"
     ]
    }
   ],
   "source": [
    "Grid.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(Grid.best_params_)\n",
    "print(Grid.best_estimator_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_grid = Grid.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(accuracy_score(y_test,pred_grid))\n",
    "print('\\n')\n",
    "print(confusion_matrix(y_test,pred_grid))\n",
    "print('\\n')\n",
    "print(classification_report(y_test,pred_grid))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using tensorflow estimator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [],
   "source": [
    "feat_cols = []\n",
    "for col in X_train_orig.columns:\n",
    "    feat_cols.append(tf.feature_column.numeric_column(col))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_func = tf.estimator.inputs.pandas_input_fn(x=X_train_orig,y=y_train_orig,\n",
    "                                                 batch_size=1000,num_epochs=5, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using default config.\n",
      "WARNING:tensorflow:Using temporary folder as model directory: C:\\Users\\Supratik\\AppData\\Local\\Temp\\tmp1kwqos24\n",
      "INFO:tensorflow:Using config: {'_model_dir': 'C:\\\\Users\\\\Supratik\\\\AppData\\\\Local\\\\Temp\\\\tmp1kwqos24', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': allow_soft_placement: true\n",
      "graph_options {\n",
      "  rewrite_options {\n",
      "    meta_optimizer_iterations: ONE\n",
      "  }\n",
      "}\n",
      ", '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x000002A41B42C9E8>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}\n"
     ]
    }
   ],
   "source": [
    "classifier = tf.estimator.DNNClassifier(hidden_units=[54, 27, 10, 1], n_classes=2,feature_columns=feat_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Saving checkpoints for 0 into C:\\Users\\Supratik\\AppData\\Local\\Temp\\tmp1kwqos24\\model.ckpt.\n",
      "INFO:tensorflow:loss = 695.0956, step = 1\n",
      "INFO:tensorflow:Saving checkpoints for 50 into C:\\Users\\Supratik\\AppData\\Local\\Temp\\tmp1kwqos24\\model.ckpt.\n",
      "INFO:tensorflow:Loss for final step: 693.6463.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow_estimator.python.estimator.canned.dnn.DNNClassifier at 0x2a41b42c438>"
      ]
     },
     "execution_count": 261,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier.train(input_fn=input_func,steps=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from C:\\Users\\Supratik\\AppData\\Local\\Temp\\tmp1kwqos24\\model.ckpt-50\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n"
     ]
    }
   ],
   "source": [
    "pred_fn = tf.estimator.inputs.pandas_input_fn(x=X_test_orig,batch_size=len(X_test_orig),shuffle=False)\n",
    "note_predictions = list(classifier.predict(input_fn=pred_fn))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_preds  = []\n",
    "for pred in note_predictions:\n",
    "    final_preds.append(pred['class_ids'][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, classification_report,confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.48870707536298685\n",
      "\n",
      "\n",
      "[[4241    0]\n",
      " [4437    0]]\n",
      "\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.49      1.00      0.66      4241\n",
      "           1       0.00      0.00      0.00      4437\n",
      "\n",
      "   micro avg       0.49      0.49      0.49      8678\n",
      "   macro avg       0.24      0.50      0.33      8678\n",
      "weighted avg       0.24      0.49      0.32      8678\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Supratik\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Supratik\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Supratik\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "print(accuracy_score(y_test_orig,final_preds))\n",
    "print('\\n')\n",
    "print(confusion_matrix(y_test_orig,final_preds))\n",
    "print('\\n')\n",
    "print(classification_report(y_test_orig,final_preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gini: 0.003, Max. Gini: 0.244, Normalized Gini: 0.014\n"
     ]
    }
   ],
   "source": [
    "# Gini with predicted probabilities\n",
    "gini_predictions = gini(y_test_orig, final_preds)\n",
    "gini_max = gini(y_test_orig, y_test_orig)\n",
    "ngini= gini_normalized(y_test_orig, final_preds)\n",
    "print('Gini: %.3f, Max. Gini: %.3f, Normalized Gini: %.3f' % (gini_predictions, gini_max, ngini))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Keras Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: keras in c:\\users\\supratik\\anaconda3\\lib\\site-packages (2.2.4)\n",
      "Requirement already satisfied: pyyaml in c:\\users\\supratik\\anaconda3\\lib\\site-packages (from keras) (5.1)\n",
      "Requirement already satisfied: keras-preprocessing>=1.0.5 in c:\\users\\supratik\\anaconda3\\lib\\site-packages (from keras) (1.1.0)\n",
      "Requirement already satisfied: keras-applications>=1.0.6 in c:\\users\\supratik\\anaconda3\\lib\\site-packages (from keras) (1.0.8)\n",
      "Requirement already satisfied: six>=1.9.0 in c:\\users\\supratik\\anaconda3\\lib\\site-packages (from keras) (1.12.0)\n",
      "Requirement already satisfied: scipy>=0.14 in c:\\users\\supratik\\anaconda3\\lib\\site-packages (from keras) (1.2.1)\n",
      "Requirement already satisfied: numpy>=1.9.1 in c:\\users\\supratik\\anaconda3\\lib\\site-packages (from keras) (1.16.2)\n",
      "Requirement already satisfied: h5py in c:\\users\\supratik\\anaconda3\\lib\\site-packages (from keras) (2.9.0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "!pip install keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers.core import Dense\n",
    "from keras.wrappers.scikit_learn import KerasClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create model\n",
    "from keras.optimizers import Adam\n",
    "model = Sequential()\n",
    "model.add(Dense(71, input_dim=X_train.shape[1], kernel_initializer='normal', activation='relu'))\n",
    "model.add(Dense(10, kernel_initializer='normal', activation='relu'))\n",
    "model.add(Dense(1, kernel_initializer='normal'))\n",
    "# Compile model\n",
    "model.compile(loss='mean_squared_error', optimizer='adam')\n",
    "seed = 7\n",
    "np.random.seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\Supratik\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "Epoch 1/100\n",
      "34710/34710 [==============================] - 1s 17us/step - loss: 0.2797\n",
      "Epoch 2/100\n",
      "34710/34710 [==============================] - 0s 11us/step - loss: 0.2407\n",
      "Epoch 3/100\n",
      "34710/34710 [==============================] - 0s 10us/step - loss: 0.2405\n",
      "Epoch 4/100\n",
      "34710/34710 [==============================] - 0s 9us/step - loss: 0.2402\n",
      "Epoch 5/100\n",
      "34710/34710 [==============================] - 0s 9us/step - loss: 0.2397\n",
      "Epoch 6/100\n",
      "34710/34710 [==============================] - 0s 9us/step - loss: 0.2392\n",
      "Epoch 7/100\n",
      "34710/34710 [==============================] - ETA: 0s - loss: 0.238 - 0s 9us/step - loss: 0.2386\n",
      "Epoch 8/100\n",
      "34710/34710 [==============================] - 0s 12us/step - loss: 0.2380\n",
      "Epoch 9/100\n",
      "34710/34710 [==============================] - 0s 14us/step - loss: 0.2373\n",
      "Epoch 10/100\n",
      "34710/34710 [==============================] - 0s 10us/step - loss: 0.2367\n",
      "Epoch 11/100\n",
      "34710/34710 [==============================] - 0s 11us/step - loss: 0.2362\n",
      "Epoch 12/100\n",
      "34710/34710 [==============================] - 0s 12us/step - loss: 0.2355\n",
      "Epoch 13/100\n",
      "34710/34710 [==============================] - 0s 13us/step - loss: 0.2351\n",
      "Epoch 14/100\n",
      "34710/34710 [==============================] - 0s 11us/step - loss: 0.2345\n",
      "Epoch 15/100\n",
      "34710/34710 [==============================] - 0s 11us/step - loss: 0.2339\n",
      "Epoch 16/100\n",
      "34710/34710 [==============================] - 0s 10us/step - loss: 0.2335\n",
      "Epoch 17/100\n",
      "34710/34710 [==============================] - 0s 10us/step - loss: 0.2332\n",
      "Epoch 18/100\n",
      "34710/34710 [==============================] - 0s 9us/step - loss: 0.2327\n",
      "Epoch 19/100\n",
      "34710/34710 [==============================] - 0s 9us/step - loss: 0.2324\n",
      "Epoch 20/100\n",
      "34710/34710 [==============================] - 0s 9us/step - loss: 0.2318\n",
      "Epoch 21/100\n",
      "34710/34710 [==============================] - 0s 9us/step - loss: 0.2318\n",
      "Epoch 22/100\n",
      "34710/34710 [==============================] - 0s 9us/step - loss: 0.2310\n",
      "Epoch 23/100\n",
      "34710/34710 [==============================] - 0s 9us/step - loss: 0.2306\n",
      "Epoch 24/100\n",
      "34710/34710 [==============================] - 0s 9us/step - loss: 0.2304\n",
      "Epoch 25/100\n",
      "34710/34710 [==============================] - 0s 9us/step - loss: 0.2300\n",
      "Epoch 26/100\n",
      "34710/34710 [==============================] - 1s 25us/step - loss: 0.2294\n",
      "Epoch 27/100\n",
      "34710/34710 [==============================] - 0s 9us/step - loss: 0.2290\n",
      "Epoch 28/100\n",
      "34710/34710 [==============================] - 1s 16us/step - loss: 0.2290\n",
      "Epoch 29/100\n",
      "34710/34710 [==============================] - 0s 11us/step - loss: 0.2287\n",
      "Epoch 30/100\n",
      "34710/34710 [==============================] - 0s 10us/step - loss: 0.2283\n",
      "Epoch 31/100\n",
      "34710/34710 [==============================] - 0s 12us/step - loss: 0.2278\n",
      "Epoch 32/100\n",
      "34710/34710 [==============================] - 0s 12us/step - loss: 0.2281\n",
      "Epoch 33/100\n",
      "34710/34710 [==============================] - 0s 10us/step - loss: 0.2273\n",
      "Epoch 34/100\n",
      "34710/34710 [==============================] - 0s 10us/step - loss: 0.2274\n",
      "Epoch 35/100\n",
      "34710/34710 [==============================] - 0s 9us/step - loss: 0.2267\n",
      "Epoch 36/100\n",
      "34710/34710 [==============================] - 0s 9us/step - loss: 0.2263\n",
      "Epoch 37/100\n",
      "34710/34710 [==============================] - 0s 10us/step - loss: 0.2262\n",
      "Epoch 38/100\n",
      "34710/34710 [==============================] - 0s 9us/step - loss: 0.2254\n",
      "Epoch 39/100\n",
      "34710/34710 [==============================] - 0s 9us/step - loss: 0.2253\n",
      "Epoch 40/100\n",
      "34710/34710 [==============================] - 0s 9us/step - loss: 0.2251\n",
      "Epoch 41/100\n",
      "34710/34710 [==============================] - 0s 9us/step - loss: 0.2245\n",
      "Epoch 42/100\n",
      "34710/34710 [==============================] - 0s 9us/step - loss: 0.2239\n",
      "Epoch 43/100\n",
      "34710/34710 [==============================] - 0s 9us/step - loss: 0.2239\n",
      "Epoch 44/100\n",
      "34710/34710 [==============================] - 0s 9us/step - loss: 0.2235\n",
      "Epoch 45/100\n",
      "34710/34710 [==============================] - 0s 11us/step - loss: 0.2228\n",
      "Epoch 46/100\n",
      "34710/34710 [==============================] - 0s 9us/step - loss: 0.2223\n",
      "Epoch 47/100\n",
      "34710/34710 [==============================] - 0s 9us/step - loss: 0.2218\n",
      "Epoch 48/100\n",
      "34710/34710 [==============================] - 0s 10us/step - loss: 0.2214\n",
      "Epoch 49/100\n",
      "34710/34710 [==============================] - 0s 9us/step - loss: 0.2211\n",
      "Epoch 50/100\n",
      "34710/34710 [==============================] - 0s 9us/step - loss: 0.2211\n",
      "Epoch 51/100\n",
      "34710/34710 [==============================] - 0s 9us/step - loss: 0.2206\n",
      "Epoch 52/100\n",
      "34710/34710 [==============================] - 0s 9us/step - loss: 0.2202\n",
      "Epoch 53/100\n",
      "34710/34710 [==============================] - 0s 9us/step - loss: 0.2193\n",
      "Epoch 54/100\n",
      "34710/34710 [==============================] - 0s 9us/step - loss: 0.2188\n",
      "Epoch 55/100\n",
      "34710/34710 [==============================] - 0s 10us/step - loss: 0.2184\n",
      "Epoch 56/100\n",
      "34710/34710 [==============================] - 0s 8us/step - loss: 0.2180\n",
      "Epoch 57/100\n",
      "34710/34710 [==============================] - 0s 11us/step - loss: 0.2179\n",
      "Epoch 58/100\n",
      "34710/34710 [==============================] - 0s 12us/step - loss: 0.2171\n",
      "Epoch 59/100\n",
      "34710/34710 [==============================] - 0s 13us/step - loss: 0.2166\n",
      "Epoch 60/100\n",
      "34710/34710 [==============================] - 0s 11us/step - loss: 0.2164\n",
      "Epoch 61/100\n",
      "34710/34710 [==============================] - 0s 10us/step - loss: 0.2159\n",
      "Epoch 62/100\n",
      "34710/34710 [==============================] - 0s 9us/step - loss: 0.2161\n",
      "Epoch 63/100\n",
      "34710/34710 [==============================] - 0s 8us/step - loss: 0.2158\n",
      "Epoch 64/100\n",
      "34710/34710 [==============================] - 0s 9us/step - loss: 0.2151\n",
      "Epoch 65/100\n",
      "34710/34710 [==============================] - 0s 9us/step - loss: 0.2148\n",
      "Epoch 66/100\n",
      "34710/34710 [==============================] - 0s 9us/step - loss: 0.2148\n",
      "Epoch 67/100\n",
      "34710/34710 [==============================] - 0s 9us/step - loss: 0.2142\n",
      "Epoch 68/100\n",
      "34710/34710 [==============================] - 0s 9us/step - loss: 0.2134\n",
      "Epoch 69/100\n",
      "34710/34710 [==============================] - 0s 9us/step - loss: 0.2134\n",
      "Epoch 70/100\n",
      "34710/34710 [==============================] - 0s 9us/step - loss: 0.2134\n",
      "Epoch 71/100\n",
      "34710/34710 [==============================] - 0s 9us/step - loss: 0.2124\n",
      "Epoch 72/100\n",
      "34710/34710 [==============================] - 0s 9us/step - loss: 0.2126\n",
      "Epoch 73/100\n",
      "34710/34710 [==============================] - 0s 9us/step - loss: 0.2125\n",
      "Epoch 74/100\n",
      "34710/34710 [==============================] - 0s 9us/step - loss: 0.2119\n",
      "Epoch 75/100\n",
      "34710/34710 [==============================] - 0s 9us/step - loss: 0.2119\n",
      "Epoch 76/100\n",
      "34710/34710 [==============================] - 0s 9us/step - loss: 0.2113\n",
      "Epoch 77/100\n",
      "34710/34710 [==============================] - 0s 9us/step - loss: 0.2111\n",
      "Epoch 78/100\n",
      "34710/34710 [==============================] - 0s 9us/step - loss: 0.2109\n",
      "Epoch 79/100\n",
      "34710/34710 [==============================] - 0s 9us/step - loss: 0.2108\n",
      "Epoch 80/100\n",
      "34710/34710 [==============================] - 0s 9us/step - loss: 0.2104\n",
      "Epoch 81/100\n",
      "34710/34710 [==============================] - 0s 9us/step - loss: 0.2108\n",
      "Epoch 82/100\n",
      "34710/34710 [==============================] - 0s 9us/step - loss: 0.2102\n",
      "Epoch 83/100\n",
      "34710/34710 [==============================] - 0s 8us/step - loss: 0.2102\n",
      "Epoch 84/100\n",
      "34710/34710 [==============================] - 0s 9us/step - loss: 0.2099\n",
      "Epoch 85/100\n",
      "34710/34710 [==============================] - ETA: 0s - loss: 0.209 - 0s 9us/step - loss: 0.2097\n",
      "Epoch 86/100\n",
      "34710/34710 [==============================] - 0s 8us/step - loss: 0.2094\n",
      "Epoch 87/100\n",
      "34710/34710 [==============================] - 0s 9us/step - loss: 0.2090\n",
      "Epoch 88/100\n",
      "34710/34710 [==============================] - 0s 9us/step - loss: 0.2090\n",
      "Epoch 89/100\n",
      "34710/34710 [==============================] - 0s 9us/step - loss: 0.2087\n",
      "Epoch 90/100\n",
      "34710/34710 [==============================] - 0s 10us/step - loss: 0.2085\n",
      "Epoch 91/100\n",
      "34710/34710 [==============================] - 0s 10us/step - loss: 0.2084\n",
      "Epoch 92/100\n",
      "34710/34710 [==============================] - 0s 9us/step - loss: 0.2081\n",
      "Epoch 93/100\n",
      "34710/34710 [==============================] - 0s 9us/step - loss: 0.2081\n",
      "Epoch 94/100\n",
      "34710/34710 [==============================] - 0s 9us/step - loss: 0.2085\n",
      "Epoch 95/100\n",
      "34710/34710 [==============================] - 0s 9us/step - loss: 0.2074\n",
      "Epoch 96/100\n",
      "34710/34710 [==============================] - 0s 9us/step - loss: 0.2072\n",
      "Epoch 97/100\n",
      "34710/34710 [==============================] - 0s 9us/step - loss: 0.2071\n",
      "Epoch 98/100\n",
      "34710/34710 [==============================] - 0s 8us/step - loss: 0.2075\n",
      "Epoch 99/100\n",
      "34710/34710 [==============================] - 0s 8us/step - loss: 0.2068\n",
      "Epoch 100/100\n",
      "34710/34710 [==============================] - 0s 9us/step - loss: 0.2071\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x2a41b1b21d0>"
      ]
     },
     "execution_count": 244,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train, y_train, epochs=100, batch_size=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds_keras = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds_keras=preds_keras.flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gini: 0.035, Max. Gini: 0.244, Normalized Gini: 0.145\n"
     ]
    }
   ],
   "source": [
    "gini_predictions = gini(y_test, preds_keras)\n",
    "gini_max = gini(y_test, y_test)\n",
    "ngini= gini_normalized(y_test, preds_keras)\n",
    "print('Gini: %.3f, Max. Gini: %.3f, Normalized Gini: %.3f' % (gini_predictions, gini_max, ngini))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Naive Bayes Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {},
   "outputs": [],
   "source": [
    "nbayes_model = MultinomialNB().fit(X_train_orig, y_train_orig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = nbayes_model.predict(X_test_orig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 0, ..., 0, 0, 1], dtype=int64)"
      ]
     },
     "execution_count": 240,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gini: 0.029, Max. Gini: 0.244, Normalized Gini: 0.119\n"
     ]
    }
   ],
   "source": [
    "gini_predictions = gini(y_test, y_pred)\n",
    "gini_max = gini(y_test, y_test)\n",
    "ngini= gini_normalized(y_test, y_pred)\n",
    "print('Gini: %.3f, Max. Gini: %.3f, Normalized Gini: %.3f' % (gini_predictions, gini_max, ngini))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
