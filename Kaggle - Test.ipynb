{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('train.csv', na_values=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>target</th>\n",
       "      <th>ps_ind_01</th>\n",
       "      <th>ps_ind_02_cat</th>\n",
       "      <th>ps_ind_03</th>\n",
       "      <th>ps_ind_04_cat</th>\n",
       "      <th>ps_ind_05_cat</th>\n",
       "      <th>ps_ind_06_bin</th>\n",
       "      <th>ps_ind_07_bin</th>\n",
       "      <th>ps_ind_08_bin</th>\n",
       "      <th>...</th>\n",
       "      <th>ps_calc_11</th>\n",
       "      <th>ps_calc_12</th>\n",
       "      <th>ps_calc_13</th>\n",
       "      <th>ps_calc_14</th>\n",
       "      <th>ps_calc_15_bin</th>\n",
       "      <th>ps_calc_16_bin</th>\n",
       "      <th>ps_calc_17_bin</th>\n",
       "      <th>ps_calc_18_bin</th>\n",
       "      <th>ps_calc_19_bin</th>\n",
       "      <th>ps_calc_20_bin</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>16</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>17</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 59 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   id  target  ps_ind_01  ps_ind_02_cat  ps_ind_03  ps_ind_04_cat  \\\n",
       "0   7       0          2              2          5              1   \n",
       "1   9       0          1              1          7              0   \n",
       "2  13       0          5              4          9              1   \n",
       "3  16       0          0              1          2              0   \n",
       "4  17       0          0              2          0              1   \n",
       "\n",
       "   ps_ind_05_cat  ps_ind_06_bin  ps_ind_07_bin  ps_ind_08_bin  ...  \\\n",
       "0              0              0              1              0  ...   \n",
       "1              0              0              0              1  ...   \n",
       "2              0              0              0              1  ...   \n",
       "3              0              1              0              0  ...   \n",
       "4              0              1              0              0  ...   \n",
       "\n",
       "   ps_calc_11  ps_calc_12  ps_calc_13  ps_calc_14  ps_calc_15_bin  \\\n",
       "0           9           1           5           8               0   \n",
       "1           3           1           1           9               0   \n",
       "2           4           2           7           7               0   \n",
       "3           2           2           4           9               0   \n",
       "4           3           1           1           3               0   \n",
       "\n",
       "   ps_calc_16_bin  ps_calc_17_bin  ps_calc_18_bin  ps_calc_19_bin  \\\n",
       "0               1               1               0               0   \n",
       "1               1               1               0               1   \n",
       "2               1               1               0               1   \n",
       "3               0               0               0               0   \n",
       "4               0               0               1               1   \n",
       "\n",
       "   ps_calc_20_bin  \n",
       "0               1  \n",
       "1               0  \n",
       "2               0  \n",
       "3               0  \n",
       "4               0  \n",
       "\n",
       "[5 rows x 59 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(595212, 59)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 595212 entries, 0 to 595211\n",
      "Data columns (total 59 columns):\n",
      "id                595212 non-null int64\n",
      "target            595212 non-null int64\n",
      "ps_ind_01         595212 non-null int64\n",
      "ps_ind_02_cat     595212 non-null int64\n",
      "ps_ind_03         595212 non-null int64\n",
      "ps_ind_04_cat     595212 non-null int64\n",
      "ps_ind_05_cat     595212 non-null int64\n",
      "ps_ind_06_bin     595212 non-null int64\n",
      "ps_ind_07_bin     595212 non-null int64\n",
      "ps_ind_08_bin     595212 non-null int64\n",
      "ps_ind_09_bin     595212 non-null int64\n",
      "ps_ind_10_bin     595212 non-null int64\n",
      "ps_ind_11_bin     595212 non-null int64\n",
      "ps_ind_12_bin     595212 non-null int64\n",
      "ps_ind_13_bin     595212 non-null int64\n",
      "ps_ind_14         595212 non-null int64\n",
      "ps_ind_15         595212 non-null int64\n",
      "ps_ind_16_bin     595212 non-null int64\n",
      "ps_ind_17_bin     595212 non-null int64\n",
      "ps_ind_18_bin     595212 non-null int64\n",
      "ps_reg_01         595212 non-null float64\n",
      "ps_reg_02         595212 non-null float64\n",
      "ps_reg_03         595212 non-null float64\n",
      "ps_car_01_cat     595212 non-null int64\n",
      "ps_car_02_cat     595212 non-null int64\n",
      "ps_car_03_cat     595212 non-null int64\n",
      "ps_car_04_cat     595212 non-null int64\n",
      "ps_car_05_cat     595212 non-null int64\n",
      "ps_car_06_cat     595212 non-null int64\n",
      "ps_car_07_cat     595212 non-null int64\n",
      "ps_car_08_cat     595212 non-null int64\n",
      "ps_car_09_cat     595212 non-null int64\n",
      "ps_car_10_cat     595212 non-null int64\n",
      "ps_car_11_cat     595212 non-null int64\n",
      "ps_car_11         595212 non-null int64\n",
      "ps_car_12         595212 non-null float64\n",
      "ps_car_13         595212 non-null float64\n",
      "ps_car_14         595212 non-null float64\n",
      "ps_car_15         595212 non-null float64\n",
      "ps_calc_01        595212 non-null float64\n",
      "ps_calc_02        595212 non-null float64\n",
      "ps_calc_03        595212 non-null float64\n",
      "ps_calc_04        595212 non-null int64\n",
      "ps_calc_05        595212 non-null int64\n",
      "ps_calc_06        595212 non-null int64\n",
      "ps_calc_07        595212 non-null int64\n",
      "ps_calc_08        595212 non-null int64\n",
      "ps_calc_09        595212 non-null int64\n",
      "ps_calc_10        595212 non-null int64\n",
      "ps_calc_11        595212 non-null int64\n",
      "ps_calc_12        595212 non-null int64\n",
      "ps_calc_13        595212 non-null int64\n",
      "ps_calc_14        595212 non-null int64\n",
      "ps_calc_15_bin    595212 non-null int64\n",
      "ps_calc_16_bin    595212 non-null int64\n",
      "ps_calc_17_bin    595212 non-null int64\n",
      "ps_calc_18_bin    595212 non-null int64\n",
      "ps_calc_19_bin    595212 non-null int64\n",
      "ps_calc_20_bin    595212 non-null int64\n",
      "dtypes: float64(10), int64(49)\n",
      "memory usage: 267.9 MB\n"
     ]
    }
   ],
   "source": [
    "train.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = pd.read_csv('test.csv', na_values=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>ps_ind_01</th>\n",
       "      <th>ps_ind_02_cat</th>\n",
       "      <th>ps_ind_03</th>\n",
       "      <th>ps_ind_04_cat</th>\n",
       "      <th>ps_ind_05_cat</th>\n",
       "      <th>ps_ind_06_bin</th>\n",
       "      <th>ps_ind_07_bin</th>\n",
       "      <th>ps_ind_08_bin</th>\n",
       "      <th>ps_ind_09_bin</th>\n",
       "      <th>...</th>\n",
       "      <th>ps_calc_11</th>\n",
       "      <th>ps_calc_12</th>\n",
       "      <th>ps_calc_13</th>\n",
       "      <th>ps_calc_14</th>\n",
       "      <th>ps_calc_15_bin</th>\n",
       "      <th>ps_calc_16_bin</th>\n",
       "      <th>ps_calc_17_bin</th>\n",
       "      <th>ps_calc_18_bin</th>\n",
       "      <th>ps_calc_19_bin</th>\n",
       "      <th>ps_calc_20_bin</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 58 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   id  ps_ind_01  ps_ind_02_cat  ps_ind_03  ps_ind_04_cat  ps_ind_05_cat  \\\n",
       "0   0          0              1          8              1              0   \n",
       "1   1          4              2          5              1              0   \n",
       "2   2          5              1          3              0              0   \n",
       "3   3          0              1          6              0              0   \n",
       "4   4          5              1          7              0              0   \n",
       "\n",
       "   ps_ind_06_bin  ps_ind_07_bin  ps_ind_08_bin  ps_ind_09_bin  ...  \\\n",
       "0              0              1              0              0  ...   \n",
       "1              0              0              0              1  ...   \n",
       "2              0              0              0              1  ...   \n",
       "3              1              0              0              0  ...   \n",
       "4              0              0              0              1  ...   \n",
       "\n",
       "   ps_calc_11  ps_calc_12  ps_calc_13  ps_calc_14  ps_calc_15_bin  \\\n",
       "0           1           1           1          12               0   \n",
       "1           2           0           3          10               0   \n",
       "2           4           0           2           4               0   \n",
       "3           5           1           0           5               1   \n",
       "4           4           0           0           4               0   \n",
       "\n",
       "   ps_calc_16_bin  ps_calc_17_bin  ps_calc_18_bin  ps_calc_19_bin  \\\n",
       "0               1               1               0               0   \n",
       "1               0               1               1               0   \n",
       "2               0               0               0               0   \n",
       "3               0               1               0               0   \n",
       "4               1               1               0               0   \n",
       "\n",
       "   ps_calc_20_bin  \n",
       "0               1  \n",
       "1               1  \n",
       "2               0  \n",
       "3               0  \n",
       "4               1  \n",
       "\n",
       "[5 rows x 58 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(892816, 58)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 892816 entries, 0 to 892815\n",
      "Data columns (total 58 columns):\n",
      "id                892816 non-null int64\n",
      "ps_ind_01         892816 non-null int64\n",
      "ps_ind_02_cat     892816 non-null int64\n",
      "ps_ind_03         892816 non-null int64\n",
      "ps_ind_04_cat     892816 non-null int64\n",
      "ps_ind_05_cat     892816 non-null int64\n",
      "ps_ind_06_bin     892816 non-null int64\n",
      "ps_ind_07_bin     892816 non-null int64\n",
      "ps_ind_08_bin     892816 non-null int64\n",
      "ps_ind_09_bin     892816 non-null int64\n",
      "ps_ind_10_bin     892816 non-null int64\n",
      "ps_ind_11_bin     892816 non-null int64\n",
      "ps_ind_12_bin     892816 non-null int64\n",
      "ps_ind_13_bin     892816 non-null int64\n",
      "ps_ind_14         892816 non-null int64\n",
      "ps_ind_15         892816 non-null int64\n",
      "ps_ind_16_bin     892816 non-null int64\n",
      "ps_ind_17_bin     892816 non-null int64\n",
      "ps_ind_18_bin     892816 non-null int64\n",
      "ps_reg_01         892816 non-null float64\n",
      "ps_reg_02         892816 non-null float64\n",
      "ps_reg_03         892816 non-null float64\n",
      "ps_car_01_cat     892816 non-null int64\n",
      "ps_car_02_cat     892816 non-null int64\n",
      "ps_car_03_cat     892816 non-null int64\n",
      "ps_car_04_cat     892816 non-null int64\n",
      "ps_car_05_cat     892816 non-null int64\n",
      "ps_car_06_cat     892816 non-null int64\n",
      "ps_car_07_cat     892816 non-null int64\n",
      "ps_car_08_cat     892816 non-null int64\n",
      "ps_car_09_cat     892816 non-null int64\n",
      "ps_car_10_cat     892816 non-null int64\n",
      "ps_car_11_cat     892816 non-null int64\n",
      "ps_car_11         892816 non-null int64\n",
      "ps_car_12         892816 non-null float64\n",
      "ps_car_13         892816 non-null float64\n",
      "ps_car_14         892816 non-null float64\n",
      "ps_car_15         892816 non-null float64\n",
      "ps_calc_01        892816 non-null float64\n",
      "ps_calc_02        892816 non-null float64\n",
      "ps_calc_03        892816 non-null float64\n",
      "ps_calc_04        892816 non-null int64\n",
      "ps_calc_05        892816 non-null int64\n",
      "ps_calc_06        892816 non-null int64\n",
      "ps_calc_07        892816 non-null int64\n",
      "ps_calc_08        892816 non-null int64\n",
      "ps_calc_09        892816 non-null int64\n",
      "ps_calc_10        892816 non-null int64\n",
      "ps_calc_11        892816 non-null int64\n",
      "ps_calc_12        892816 non-null int64\n",
      "ps_calc_13        892816 non-null int64\n",
      "ps_calc_14        892816 non-null int64\n",
      "ps_calc_15_bin    892816 non-null int64\n",
      "ps_calc_16_bin    892816 non-null int64\n",
      "ps_calc_17_bin    892816 non-null int64\n",
      "ps_calc_18_bin    892816 non-null int64\n",
      "ps_calc_19_bin    892816 non-null int64\n",
      "ps_calc_20_bin    892816 non-null int64\n",
      "dtypes: float64(10), int64(48)\n",
      "memory usage: 395.1 MB\n"
     ]
    }
   ],
   "source": [
    "test.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Supratik\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:1: FutureWarning: Sorting because non-concatenation axis is not aligned. A future version\n",
      "of pandas will change to not sort by default.\n",
      "\n",
      "To accept the future behavior, pass 'sort=False'.\n",
      "\n",
      "To retain the current behavior and silence the warning, pass 'sort=True'.\n",
      "\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    }
   ],
   "source": [
    "traintest = pd.concat([train,test])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>ps_calc_01</th>\n",
       "      <th>ps_calc_02</th>\n",
       "      <th>ps_calc_03</th>\n",
       "      <th>ps_calc_04</th>\n",
       "      <th>ps_calc_05</th>\n",
       "      <th>ps_calc_06</th>\n",
       "      <th>ps_calc_07</th>\n",
       "      <th>ps_calc_08</th>\n",
       "      <th>ps_calc_09</th>\n",
       "      <th>...</th>\n",
       "      <th>ps_ind_13_bin</th>\n",
       "      <th>ps_ind_14</th>\n",
       "      <th>ps_ind_15</th>\n",
       "      <th>ps_ind_16_bin</th>\n",
       "      <th>ps_ind_17_bin</th>\n",
       "      <th>ps_ind_18_bin</th>\n",
       "      <th>ps_reg_01</th>\n",
       "      <th>ps_reg_02</th>\n",
       "      <th>ps_reg_03</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.2</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.718070</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>9</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.3</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>5</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.766078</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>13</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>16</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.1</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>4</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.580948</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>17</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.840759</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>19</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.4</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>2</td>\n",
       "      <td>11</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.9</td>\n",
       "      <td>1.8</td>\n",
       "      <td>2.332649</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>20</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.5</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.617454</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>22</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>13</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.607248</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>26</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.6</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>9</td>\n",
       "      <td>4</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.901388</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>28</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.8</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "      <td>2</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.9</td>\n",
       "      <td>1.4</td>\n",
       "      <td>2.316652</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>34</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>8</td>\n",
       "      <td>2</td>\n",
       "      <td>9</td>\n",
       "      <td>4</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.795692</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>35</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.5</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.378319</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>36</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.9</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>4</td>\n",
       "      <td>11</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.548293</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>43</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.6</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.684197</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>46</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.6</td>\n",
       "      <td>1.052972</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>48</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>5</td>\n",
       "      <td>10</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.3</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>50</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.3</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>6</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.699553</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>58</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>8</td>\n",
       "      <td>2</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.810864</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>61</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.3</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>3</td>\n",
       "      <td>11</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.3</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>64</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.402337</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>65</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.8</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>8</td>\n",
       "      <td>3</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.7</td>\n",
       "      <td>1.372725</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>66</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.1</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>9</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.955903</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>72</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.6</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>11</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.742041</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>74</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.6</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.2</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>77</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.3</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>4</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.587367</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>78</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.6</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>9</td>\n",
       "      <td>4</td>\n",
       "      <td>10</td>\n",
       "      <td>4</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>13</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.2</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>79</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.2</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.666146</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>80</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.5</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>4</td>\n",
       "      <td>10</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.8</td>\n",
       "      <td>1.034408</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>84</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>3</td>\n",
       "      <td>9</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.3</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>85</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.6</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>12</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.9</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.155692</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>892786</th>\n",
       "      <td>1487982</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.2</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.649519</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>892787</th>\n",
       "      <td>1487984</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.490535</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>892788</th>\n",
       "      <td>1487985</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>5</td>\n",
       "      <td>10</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.9</td>\n",
       "      <td>1.2</td>\n",
       "      <td>1.022252</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>892789</th>\n",
       "      <td>1487986</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.6</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>9</td>\n",
       "      <td>3</td>\n",
       "      <td>9</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.609816</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>892790</th>\n",
       "      <td>1487987</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.2</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>4</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.9</td>\n",
       "      <td>1.027436</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>892791</th>\n",
       "      <td>1487989</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.8</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>8</td>\n",
       "      <td>3</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.752080</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>892792</th>\n",
       "      <td>1487991</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>9</td>\n",
       "      <td>3</td>\n",
       "      <td>9</td>\n",
       "      <td>4</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.637868</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>892793</th>\n",
       "      <td>1487993</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.8</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>9</td>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.791360</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>892794</th>\n",
       "      <td>1487995</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>4</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.9</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.108772</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>892795</th>\n",
       "      <td>1487997</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.6</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.942404</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>892796</th>\n",
       "      <td>1487998</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.6</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.456207</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>892797</th>\n",
       "      <td>1487999</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>4</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.3</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>892798</th>\n",
       "      <td>1488000</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.8</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>11</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.9</td>\n",
       "      <td>1.2</td>\n",
       "      <td>2.077709</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>892799</th>\n",
       "      <td>1488002</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.7</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>4</td>\n",
       "      <td>11</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>11</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.748331</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>892800</th>\n",
       "      <td>1488003</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.4</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>9</td>\n",
       "      <td>2</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>11</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.2</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>892801</th>\n",
       "      <td>1488004</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.6</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "      <td>4</td>\n",
       "      <td>8</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.856227</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>892802</th>\n",
       "      <td>1488006</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.1</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>9</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.707107</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>892803</th>\n",
       "      <td>1488007</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>9</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.656696</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>892804</th>\n",
       "      <td>1488010</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>13</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.4</td>\n",
       "      <td>1.022558</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>892805</th>\n",
       "      <td>1488012</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.6</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>9</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.754155</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>892806</th>\n",
       "      <td>1488014</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.4</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>11</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.1</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>892807</th>\n",
       "      <td>1488015</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>9</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.1</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>892808</th>\n",
       "      <td>1488018</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.1</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.603635</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>892809</th>\n",
       "      <td>1488019</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>9</td>\n",
       "      <td>4</td>\n",
       "      <td>8</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.606218</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>892810</th>\n",
       "      <td>1488020</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.9</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>4</td>\n",
       "      <td>8</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.862772</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>892811</th>\n",
       "      <td>1488022</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.9</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.3</td>\n",
       "      <td>1.048809</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>892812</th>\n",
       "      <td>1488023</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.6</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>4</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>11</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.7</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.246495</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>892813</th>\n",
       "      <td>1488024</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.9</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>4</td>\n",
       "      <td>8</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.609303</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>892814</th>\n",
       "      <td>1488025</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>13</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.920937</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>892815</th>\n",
       "      <td>1488026</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "      <td>4</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.992157</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1488028 rows Ã— 59 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             id  ps_calc_01  ps_calc_02  ps_calc_03  ps_calc_04  ps_calc_05  \\\n",
       "0             7         0.6         0.5         0.2           3           1   \n",
       "1             9         0.3         0.1         0.3           2           1   \n",
       "2            13         0.5         0.7         0.1           2           2   \n",
       "3            16         0.6         0.9         0.1           2           4   \n",
       "4            17         0.4         0.6         0.0           2           2   \n",
       "5            19         0.7         0.8         0.4           3           1   \n",
       "6            20         0.2         0.6         0.5           2           2   \n",
       "7            22         0.1         0.5         0.1           1           2   \n",
       "8            26         0.9         0.8         0.6           3           1   \n",
       "9            28         0.7         0.8         0.8           2           2   \n",
       "10           34         0.8         0.1         0.0           2           3   \n",
       "11           35         0.3         0.7         0.5           2           2   \n",
       "12           36         0.7         0.8         0.9           4           1   \n",
       "13           43         0.8         0.7         0.6           2           1   \n",
       "14           46         0.4         0.4         0.1           3           1   \n",
       "15           48         0.5         0.4         0.2           2           1   \n",
       "16           50         0.3         0.0         0.3           2           1   \n",
       "17           58         0.2         0.6         0.1           1           3   \n",
       "18           61         0.4         0.3         0.3           3           1   \n",
       "19           64         0.7         0.3         0.2           2           2   \n",
       "20           65         0.8         0.6         0.8           1           4   \n",
       "21           66         0.3         0.7         0.1           3           2   \n",
       "22           72         0.0         0.6         0.6           3           2   \n",
       "23           74         0.3         0.7         0.6           2           1   \n",
       "24           77         0.2         0.2         0.3           2           1   \n",
       "25           78         0.5         0.7         0.6           2           2   \n",
       "26           79         0.9         0.5         0.2           4           2   \n",
       "27           80         0.7         0.1         0.5           2           1   \n",
       "28           84         0.8         0.4         0.1           2           2   \n",
       "29           85         0.9         0.3         0.6           2           3   \n",
       "...         ...         ...         ...         ...         ...         ...   \n",
       "892786  1487982         0.8         0.5         0.2           3           3   \n",
       "892787  1487984         0.9         0.1         0.1           3           1   \n",
       "892788  1487985         0.5         0.4         0.0           4           1   \n",
       "892789  1487986         0.9         0.9         0.6           2           3   \n",
       "892790  1487987         0.0         0.5         0.2           3           1   \n",
       "892791  1487989         0.3         0.8         0.8           4           3   \n",
       "892792  1487991         0.5         0.5         0.5           2           4   \n",
       "892793  1487993         0.5         0.0         0.8           4           2   \n",
       "892794  1487995         0.2         0.5         0.5           2           2   \n",
       "892795  1487997         0.8         0.2         0.6           2           3   \n",
       "892796  1487998         0.6         0.8         0.6           2           1   \n",
       "892797  1487999         0.2         0.8         0.0           2           2   \n",
       "892798  1488000         0.9         0.2         0.8           1           2   \n",
       "892799  1488002         0.8         0.4         0.7           3           1   \n",
       "892800  1488003         0.2         0.6         0.4           2           3   \n",
       "892801  1488004         0.0         0.2         0.6           2           2   \n",
       "892802  1488006         0.8         0.3         0.1           3           3   \n",
       "892803  1488007         0.9         0.0         0.1           1           2   \n",
       "892804  1488010         0.2         0.4         0.2           3           1   \n",
       "892805  1488012         0.4         0.7         0.6           1           1   \n",
       "892806  1488014         0.0         0.4         0.4           3           3   \n",
       "892807  1488015         0.8         0.8         0.1           1           3   \n",
       "892808  1488018         0.9         0.8         0.1           5           3   \n",
       "892809  1488019         0.5         0.8         0.1           2           2   \n",
       "892810  1488020         0.4         0.5         0.9           1           1   \n",
       "892811  1488022         0.3         0.4         0.9           1           1   \n",
       "892812  1488023         0.3         0.2         0.6           1           3   \n",
       "892813  1488024         0.3         0.3         0.9           2           1   \n",
       "892814  1488025         0.1         0.1         0.3           1           1   \n",
       "892815  1488026         0.4         0.4         0.2           3           4   \n",
       "\n",
       "        ps_calc_06  ps_calc_07  ps_calc_08  ps_calc_09  ...  ps_ind_13_bin  \\\n",
       "0               10           1          10           1  ...              0   \n",
       "1                9           5           8           1  ...              0   \n",
       "2                9           1           8           2  ...              0   \n",
       "3                7           1           8           4  ...              0   \n",
       "4                6           3          10           2  ...              0   \n",
       "5                8           2          11           3  ...              0   \n",
       "6                8           1           8           3  ...              0   \n",
       "7                7           1           6           1  ...              0   \n",
       "8                7           3           9           4  ...              0   \n",
       "9                8           2           9           1  ...              0   \n",
       "10               8           2           9           4  ...              0   \n",
       "11               8           2          10           1  ...              0   \n",
       "12               8           4          11           1  ...              0   \n",
       "13              10           1           8           3  ...              0   \n",
       "14               8           2           6           3  ...              0   \n",
       "15               9           5          10           2  ...              0   \n",
       "16              10           6           7           3  ...              0   \n",
       "17               8           2           9           1  ...              0   \n",
       "18               8           3          11           2  ...              0   \n",
       "19               8           2           5           2  ...              0   \n",
       "20               8           3           8           1  ...              0   \n",
       "21               9           3           7           3  ...              0   \n",
       "22               8           0           9           0  ...              0   \n",
       "23               8           3          10           2  ...              0   \n",
       "24               7           4           7           2  ...              0   \n",
       "25               9           4          10           4  ...              0   \n",
       "26               7           2          10           0  ...              0   \n",
       "27               7           4          10           2  ...              0   \n",
       "28              10           3           9           2  ...              0   \n",
       "29               7           3          12           2  ...              0   \n",
       "...            ...         ...         ...         ...  ...            ...   \n",
       "892786           8           1           8           0  ...              0   \n",
       "892787           6           2          10           2  ...              0   \n",
       "892788           8           5          10           3  ...              0   \n",
       "892789           9           3           9           2  ...              0   \n",
       "892790           7           2          10           4  ...              0   \n",
       "892791           8           3           8           0  ...              0   \n",
       "892792           9           3           9           4  ...              0   \n",
       "892793           9           2           8           3  ...              0   \n",
       "892794           8           1          10           4  ...              0   \n",
       "892795           6           2           9           0  ...              0   \n",
       "892796           9           2           7           1  ...              0   \n",
       "892797          10           4           8           1  ...              0   \n",
       "892798           8           2          10           1  ...              0   \n",
       "892799           8           4          11           2  ...              0   \n",
       "892800           9           2           9           0  ...              0   \n",
       "892801           8           4           8           3  ...              0   \n",
       "892802           5           2           9           2  ...              0   \n",
       "892803           7           2           9           3  ...              0   \n",
       "892804           9           1           9           0  ...              0   \n",
       "892805           6           3           9           2  ...              0   \n",
       "892806           7           1          11           2  ...              0   \n",
       "892807           6           2           9           3  ...              0   \n",
       "892808           5           1          10           2  ...              0   \n",
       "892809           9           4           8           2  ...              0   \n",
       "892810           7           4           8           2  ...              0   \n",
       "892811           7           3          10           3  ...              0   \n",
       "892812           7           3          10           4  ...              0   \n",
       "892813          10           4           8           2  ...              0   \n",
       "892814           9           2          10           1  ...              0   \n",
       "892815           7           2           8           4  ...              0   \n",
       "\n",
       "        ps_ind_14  ps_ind_15  ps_ind_16_bin  ps_ind_17_bin  ps_ind_18_bin  \\\n",
       "0               0         11              0              1              0   \n",
       "1               0          3              0              0              1   \n",
       "2               0         12              1              0              0   \n",
       "3               0          8              1              0              0   \n",
       "4               0          9              1              0              0   \n",
       "5               0          6              1              0              0   \n",
       "6               0          8              1              0              0   \n",
       "7               0         13              1              0              0   \n",
       "8               0          6              1              0              0   \n",
       "9               0          4              0              0              1   \n",
       "10              0          3              1              0              0   \n",
       "11              0          9              1              0              0   \n",
       "12              0         10              1              0              0   \n",
       "13              0         12              1              0              0   \n",
       "14              0         10              0              0              1   \n",
       "15              0          5              0              0              1   \n",
       "16              0          9              1              0              0   \n",
       "17              0          4              1              0              0   \n",
       "18              0         12              1              0              0   \n",
       "19              0          8              1              0              0   \n",
       "20              0          3              0              0              1   \n",
       "21              0          8              1              0              0   \n",
       "22              0         11              1              0              0   \n",
       "23              0          3              1              0              0   \n",
       "24              0          9              0              0              1   \n",
       "25              0         13              1              0              0   \n",
       "26              0          8              1              0              0   \n",
       "27              0         12              1              0              0   \n",
       "28              0          8              1              0              0   \n",
       "29              0          8              1              0              0   \n",
       "...           ...        ...            ...            ...            ...   \n",
       "892786          0          2              1              0              0   \n",
       "892787          0         10              0              1              0   \n",
       "892788          0          8              1              0              0   \n",
       "892789          0          7              1              0              0   \n",
       "892790          0          9              0              1              0   \n",
       "892791          0         10              0              0              0   \n",
       "892792          0          3              0              0              1   \n",
       "892793          0          8              1              0              0   \n",
       "892794          0         12              1              0              0   \n",
       "892795          0          7              0              0              1   \n",
       "892796          0          2              0              0              1   \n",
       "892797          0          3              0              0              1   \n",
       "892798          0         11              1              0              0   \n",
       "892799          0         11              1              0              0   \n",
       "892800          0         11              1              0              0   \n",
       "892801          0          4              0              0              1   \n",
       "892802          0          4              0              0              1   \n",
       "892803          0          4              1              0              0   \n",
       "892804          0         13              1              0              0   \n",
       "892805          0         11              0              1              0   \n",
       "892806          0          2              0              0              0   \n",
       "892807          0          2              0              0              1   \n",
       "892808          0          9              1              0              0   \n",
       "892809          0          8              1              0              0   \n",
       "892810          0          9              0              0              0   \n",
       "892811          0          2              0              0              1   \n",
       "892812          0         11              1              0              0   \n",
       "892813          0          5              0              0              1   \n",
       "892814          0         13              1              0              0   \n",
       "892815          0         12              1              0              0   \n",
       "\n",
       "        ps_reg_01  ps_reg_02  ps_reg_03  target  \n",
       "0             0.7        0.2   0.718070     0.0  \n",
       "1             0.8        0.4   0.766078     0.0  \n",
       "2             0.0        0.0  -1.000000     0.0  \n",
       "3             0.9        0.2   0.580948     0.0  \n",
       "4             0.7        0.6   0.840759     0.0  \n",
       "5             0.9        1.8   2.332649     0.0  \n",
       "6             0.6        0.1   0.617454     0.0  \n",
       "7             0.7        0.4   0.607248     0.0  \n",
       "8             0.9        0.7   0.901388     0.0  \n",
       "9             0.9        1.4   2.316652     1.0  \n",
       "10            0.5        0.4   0.795692     0.0  \n",
       "11            0.9        0.1   0.378319     0.0  \n",
       "12            0.5        0.2   0.548293     0.0  \n",
       "13            0.7        0.9   0.684197     0.0  \n",
       "14            0.8        0.6   1.052972     0.0  \n",
       "15            0.4        0.3  -1.000000     0.0  \n",
       "16            0.6        0.3   0.699553     0.0  \n",
       "17            0.9        0.5   0.810864     0.0  \n",
       "18            0.3        0.3  -1.000000     0.0  \n",
       "19            0.9        0.3   0.402337     1.0  \n",
       "20            0.4        0.7   1.372725     0.0  \n",
       "21            0.7        0.4   0.955903     0.0  \n",
       "22            0.6        0.4   0.742041     0.0  \n",
       "23            0.2        0.2  -1.000000     0.0  \n",
       "24            0.4        0.2   0.587367     0.0  \n",
       "25            0.1        0.2  -1.000000     0.0  \n",
       "26            0.6        0.2   0.666146     0.0  \n",
       "27            0.9        0.8   1.034408     0.0  \n",
       "28            0.2        0.3  -1.000000     1.0  \n",
       "29            0.9        1.0   1.155692     0.0  \n",
       "...           ...        ...        ...     ...  \n",
       "892786        0.8        0.3   0.649519     NaN  \n",
       "892787        0.9        0.2   0.490535     NaN  \n",
       "892788        0.9        1.2   1.022252     NaN  \n",
       "892789        0.8        0.2   0.609816     NaN  \n",
       "892790        0.6        0.9   1.027436     NaN  \n",
       "892791        0.0        0.0   0.752080     NaN  \n",
       "892792        0.0        0.0   0.637868     NaN  \n",
       "892793        0.8        0.4   0.791360     NaN  \n",
       "892794        0.9        1.0   1.108772     NaN  \n",
       "892795        0.9        0.2   0.942404     NaN  \n",
       "892796        0.7        0.0   0.456207     NaN  \n",
       "892797        0.1        0.3  -1.000000     NaN  \n",
       "892798        0.9        1.2   2.077709     NaN  \n",
       "892799        0.4        0.4   0.748331     NaN  \n",
       "892800        0.1        0.2  -1.000000     NaN  \n",
       "892801        0.4        0.7   0.856227     NaN  \n",
       "892802        0.6        0.1   0.707107     NaN  \n",
       "892803        0.9        0.2   0.656696     NaN  \n",
       "892804        0.7        0.4   1.022558     NaN  \n",
       "892805        0.4        0.0   0.754155     NaN  \n",
       "892806        0.1        0.1  -1.000000     NaN  \n",
       "892807        0.2        0.1  -1.000000     NaN  \n",
       "892808        0.9        0.4   0.603635     NaN  \n",
       "892809        0.8        0.2   0.606218     NaN  \n",
       "892810        0.8        0.4   0.862772     NaN  \n",
       "892811        0.5        0.3   1.048809     NaN  \n",
       "892812        0.7        1.0   1.246495     NaN  \n",
       "892813        0.4        0.0   0.609303     NaN  \n",
       "892814        0.6        0.6   0.920937     NaN  \n",
       "892815        0.9        0.8   0.992157     NaN  \n",
       "\n",
       "[1488028 rows x 59 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "traintest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1488028, 59)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "traintest.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 1488028 entries, 0 to 892815\n",
      "Data columns (total 59 columns):\n",
      "id                1488028 non-null int64\n",
      "ps_calc_01        1488028 non-null float64\n",
      "ps_calc_02        1488028 non-null float64\n",
      "ps_calc_03        1488028 non-null float64\n",
      "ps_calc_04        1488028 non-null int64\n",
      "ps_calc_05        1488028 non-null int64\n",
      "ps_calc_06        1488028 non-null int64\n",
      "ps_calc_07        1488028 non-null int64\n",
      "ps_calc_08        1488028 non-null int64\n",
      "ps_calc_09        1488028 non-null int64\n",
      "ps_calc_10        1488028 non-null int64\n",
      "ps_calc_11        1488028 non-null int64\n",
      "ps_calc_12        1488028 non-null int64\n",
      "ps_calc_13        1488028 non-null int64\n",
      "ps_calc_14        1488028 non-null int64\n",
      "ps_calc_15_bin    1488028 non-null int64\n",
      "ps_calc_16_bin    1488028 non-null int64\n",
      "ps_calc_17_bin    1488028 non-null int64\n",
      "ps_calc_18_bin    1488028 non-null int64\n",
      "ps_calc_19_bin    1488028 non-null int64\n",
      "ps_calc_20_bin    1488028 non-null int64\n",
      "ps_car_01_cat     1488028 non-null int64\n",
      "ps_car_02_cat     1488028 non-null int64\n",
      "ps_car_03_cat     1488028 non-null int64\n",
      "ps_car_04_cat     1488028 non-null int64\n",
      "ps_car_05_cat     1488028 non-null int64\n",
      "ps_car_06_cat     1488028 non-null int64\n",
      "ps_car_07_cat     1488028 non-null int64\n",
      "ps_car_08_cat     1488028 non-null int64\n",
      "ps_car_09_cat     1488028 non-null int64\n",
      "ps_car_10_cat     1488028 non-null int64\n",
      "ps_car_11         1488028 non-null int64\n",
      "ps_car_11_cat     1488028 non-null int64\n",
      "ps_car_12         1488028 non-null float64\n",
      "ps_car_13         1488028 non-null float64\n",
      "ps_car_14         1488028 non-null float64\n",
      "ps_car_15         1488028 non-null float64\n",
      "ps_ind_01         1488028 non-null int64\n",
      "ps_ind_02_cat     1488028 non-null int64\n",
      "ps_ind_03         1488028 non-null int64\n",
      "ps_ind_04_cat     1488028 non-null int64\n",
      "ps_ind_05_cat     1488028 non-null int64\n",
      "ps_ind_06_bin     1488028 non-null int64\n",
      "ps_ind_07_bin     1488028 non-null int64\n",
      "ps_ind_08_bin     1488028 non-null int64\n",
      "ps_ind_09_bin     1488028 non-null int64\n",
      "ps_ind_10_bin     1488028 non-null int64\n",
      "ps_ind_11_bin     1488028 non-null int64\n",
      "ps_ind_12_bin     1488028 non-null int64\n",
      "ps_ind_13_bin     1488028 non-null int64\n",
      "ps_ind_14         1488028 non-null int64\n",
      "ps_ind_15         1488028 non-null int64\n",
      "ps_ind_16_bin     1488028 non-null int64\n",
      "ps_ind_17_bin     1488028 non-null int64\n",
      "ps_ind_18_bin     1488028 non-null int64\n",
      "ps_reg_01         1488028 non-null float64\n",
      "ps_reg_02         1488028 non-null float64\n",
      "ps_reg_03         1488028 non-null float64\n",
      "target            595212 non-null float64\n",
      "dtypes: float64(11), int64(48)\n",
      "memory usage: 681.2 MB\n"
     ]
    }
   ],
   "source": [
    "traintest.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>ps_calc_01</th>\n",
       "      <th>ps_calc_02</th>\n",
       "      <th>ps_calc_03</th>\n",
       "      <th>ps_calc_04</th>\n",
       "      <th>ps_calc_05</th>\n",
       "      <th>ps_calc_06</th>\n",
       "      <th>ps_calc_07</th>\n",
       "      <th>ps_calc_08</th>\n",
       "      <th>ps_calc_09</th>\n",
       "      <th>...</th>\n",
       "      <th>ps_ind_13_bin</th>\n",
       "      <th>ps_ind_14</th>\n",
       "      <th>ps_ind_15</th>\n",
       "      <th>ps_ind_16_bin</th>\n",
       "      <th>ps_ind_17_bin</th>\n",
       "      <th>ps_ind_18_bin</th>\n",
       "      <th>ps_reg_01</th>\n",
       "      <th>ps_reg_02</th>\n",
       "      <th>ps_reg_03</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>1.488028e+06</td>\n",
       "      <td>1.488028e+06</td>\n",
       "      <td>1.488028e+06</td>\n",
       "      <td>1.488028e+06</td>\n",
       "      <td>1.488028e+06</td>\n",
       "      <td>1.488028e+06</td>\n",
       "      <td>1.488028e+06</td>\n",
       "      <td>1.488028e+06</td>\n",
       "      <td>1.488028e+06</td>\n",
       "      <td>1.488028e+06</td>\n",
       "      <td>...</td>\n",
       "      <td>1.488028e+06</td>\n",
       "      <td>1.488028e+06</td>\n",
       "      <td>1.488028e+06</td>\n",
       "      <td>1.488028e+06</td>\n",
       "      <td>1.488028e+06</td>\n",
       "      <td>1.488028e+06</td>\n",
       "      <td>1.488028e+06</td>\n",
       "      <td>1.488028e+06</td>\n",
       "      <td>1.488028e+06</td>\n",
       "      <td>595212.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>7.440135e+05</td>\n",
       "      <td>4.496817e-01</td>\n",
       "      <td>4.501073e-01</td>\n",
       "      <td>4.499718e-01</td>\n",
       "      <td>2.371666e+00</td>\n",
       "      <td>1.885551e+00</td>\n",
       "      <td>7.688461e+00</td>\n",
       "      <td>3.008052e+00</td>\n",
       "      <td>9.225874e+00</td>\n",
       "      <td>2.338736e+00</td>\n",
       "      <td>...</td>\n",
       "      <td>1.002669e-03</td>\n",
       "      <td>1.241038e-02</td>\n",
       "      <td>7.298086e+00</td>\n",
       "      <td>6.606838e-01</td>\n",
       "      <td>1.206718e-01</td>\n",
       "      <td>1.543620e-01</td>\n",
       "      <td>6.110305e-01</td>\n",
       "      <td>4.395943e-01</td>\n",
       "      <td>5.514848e-01</td>\n",
       "      <td>0.036448</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>4.295568e+05</td>\n",
       "      <td>2.872071e-01</td>\n",
       "      <td>2.871817e-01</td>\n",
       "      <td>2.872136e-01</td>\n",
       "      <td>1.117059e+00</td>\n",
       "      <td>1.136029e+00</td>\n",
       "      <td>1.333837e+00</td>\n",
       "      <td>1.414919e+00</td>\n",
       "      <td>1.460205e+00</td>\n",
       "      <td>1.247940e+00</td>\n",
       "      <td>...</td>\n",
       "      <td>3.164909e-02</td>\n",
       "      <td>1.273684e-01</td>\n",
       "      <td>3.543585e+00</td>\n",
       "      <td>4.734774e-01</td>\n",
       "      <td>3.257456e-01</td>\n",
       "      <td>3.612955e-01</td>\n",
       "      <td>2.876763e-01</td>\n",
       "      <td>4.045123e-01</td>\n",
       "      <td>7.938159e-01</td>\n",
       "      <td>0.187401</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>-1.000000e+00</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>3.720068e+05</td>\n",
       "      <td>2.000000e-01</td>\n",
       "      <td>2.000000e-01</td>\n",
       "      <td>2.000000e-01</td>\n",
       "      <td>2.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>7.000000e+00</td>\n",
       "      <td>2.000000e+00</td>\n",
       "      <td>8.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>5.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>4.000000e-01</td>\n",
       "      <td>2.000000e-01</td>\n",
       "      <td>5.250000e-01</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>7.440135e+05</td>\n",
       "      <td>4.000000e-01</td>\n",
       "      <td>5.000000e-01</td>\n",
       "      <td>5.000000e-01</td>\n",
       "      <td>2.000000e+00</td>\n",
       "      <td>2.000000e+00</td>\n",
       "      <td>8.000000e+00</td>\n",
       "      <td>3.000000e+00</td>\n",
       "      <td>9.000000e+00</td>\n",
       "      <td>2.000000e+00</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>7.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>7.000000e-01</td>\n",
       "      <td>3.000000e-01</td>\n",
       "      <td>7.211103e-01</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>1.116020e+06</td>\n",
       "      <td>7.000000e-01</td>\n",
       "      <td>7.000000e-01</td>\n",
       "      <td>7.000000e-01</td>\n",
       "      <td>3.000000e+00</td>\n",
       "      <td>3.000000e+00</td>\n",
       "      <td>9.000000e+00</td>\n",
       "      <td>4.000000e+00</td>\n",
       "      <td>1.000000e+01</td>\n",
       "      <td>3.000000e+00</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>1.000000e+01</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>9.000000e-01</td>\n",
       "      <td>6.000000e-01</td>\n",
       "      <td>1.001561e+00</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.488027e+06</td>\n",
       "      <td>9.000000e-01</td>\n",
       "      <td>9.000000e-01</td>\n",
       "      <td>9.000000e-01</td>\n",
       "      <td>5.000000e+00</td>\n",
       "      <td>6.000000e+00</td>\n",
       "      <td>1.000000e+01</td>\n",
       "      <td>9.000000e+00</td>\n",
       "      <td>1.200000e+01</td>\n",
       "      <td>7.000000e+00</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>4.000000e+00</td>\n",
       "      <td>1.300000e+01</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>9.000000e-01</td>\n",
       "      <td>1.800000e+00</td>\n",
       "      <td>4.423517e+00</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows Ã— 59 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                 id    ps_calc_01    ps_calc_02    ps_calc_03    ps_calc_04  \\\n",
       "count  1.488028e+06  1.488028e+06  1.488028e+06  1.488028e+06  1.488028e+06   \n",
       "mean   7.440135e+05  4.496817e-01  4.501073e-01  4.499718e-01  2.371666e+00   \n",
       "std    4.295568e+05  2.872071e-01  2.871817e-01  2.872136e-01  1.117059e+00   \n",
       "min    0.000000e+00  0.000000e+00  0.000000e+00  0.000000e+00  0.000000e+00   \n",
       "25%    3.720068e+05  2.000000e-01  2.000000e-01  2.000000e-01  2.000000e+00   \n",
       "50%    7.440135e+05  4.000000e-01  5.000000e-01  5.000000e-01  2.000000e+00   \n",
       "75%    1.116020e+06  7.000000e-01  7.000000e-01  7.000000e-01  3.000000e+00   \n",
       "max    1.488027e+06  9.000000e-01  9.000000e-01  9.000000e-01  5.000000e+00   \n",
       "\n",
       "         ps_calc_05    ps_calc_06    ps_calc_07    ps_calc_08    ps_calc_09  \\\n",
       "count  1.488028e+06  1.488028e+06  1.488028e+06  1.488028e+06  1.488028e+06   \n",
       "mean   1.885551e+00  7.688461e+00  3.008052e+00  9.225874e+00  2.338736e+00   \n",
       "std    1.136029e+00  1.333837e+00  1.414919e+00  1.460205e+00  1.247940e+00   \n",
       "min    0.000000e+00  0.000000e+00  0.000000e+00  1.000000e+00  0.000000e+00   \n",
       "25%    1.000000e+00  7.000000e+00  2.000000e+00  8.000000e+00  1.000000e+00   \n",
       "50%    2.000000e+00  8.000000e+00  3.000000e+00  9.000000e+00  2.000000e+00   \n",
       "75%    3.000000e+00  9.000000e+00  4.000000e+00  1.000000e+01  3.000000e+00   \n",
       "max    6.000000e+00  1.000000e+01  9.000000e+00  1.200000e+01  7.000000e+00   \n",
       "\n",
       "       ...  ps_ind_13_bin     ps_ind_14     ps_ind_15  ps_ind_16_bin  \\\n",
       "count  ...   1.488028e+06  1.488028e+06  1.488028e+06   1.488028e+06   \n",
       "mean   ...   1.002669e-03  1.241038e-02  7.298086e+00   6.606838e-01   \n",
       "std    ...   3.164909e-02  1.273684e-01  3.543585e+00   4.734774e-01   \n",
       "min    ...   0.000000e+00  0.000000e+00  0.000000e+00   0.000000e+00   \n",
       "25%    ...   0.000000e+00  0.000000e+00  5.000000e+00   0.000000e+00   \n",
       "50%    ...   0.000000e+00  0.000000e+00  7.000000e+00   1.000000e+00   \n",
       "75%    ...   0.000000e+00  0.000000e+00  1.000000e+01   1.000000e+00   \n",
       "max    ...   1.000000e+00  4.000000e+00  1.300000e+01   1.000000e+00   \n",
       "\n",
       "       ps_ind_17_bin  ps_ind_18_bin     ps_reg_01     ps_reg_02     ps_reg_03  \\\n",
       "count   1.488028e+06   1.488028e+06  1.488028e+06  1.488028e+06  1.488028e+06   \n",
       "mean    1.206718e-01   1.543620e-01  6.110305e-01  4.395943e-01  5.514848e-01   \n",
       "std     3.257456e-01   3.612955e-01  2.876763e-01  4.045123e-01  7.938159e-01   \n",
       "min     0.000000e+00   0.000000e+00  0.000000e+00  0.000000e+00 -1.000000e+00   \n",
       "25%     0.000000e+00   0.000000e+00  4.000000e-01  2.000000e-01  5.250000e-01   \n",
       "50%     0.000000e+00   0.000000e+00  7.000000e-01  3.000000e-01  7.211103e-01   \n",
       "75%     0.000000e+00   0.000000e+00  9.000000e-01  6.000000e-01  1.001561e+00   \n",
       "max     1.000000e+00   1.000000e+00  9.000000e-01  1.800000e+00  4.423517e+00   \n",
       "\n",
       "              target  \n",
       "count  595212.000000  \n",
       "mean        0.036448  \n",
       "std         0.187401  \n",
       "min         0.000000  \n",
       "25%         0.000000  \n",
       "50%         0.000000  \n",
       "75%         0.000000  \n",
       "max         1.000000  \n",
       "\n",
       "[8 rows x 59 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "traintest.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    573518\n",
       "1     21694\n",
       "Name: target, dtype: int64"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train['target'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ps_car_03_cat, ps_car_05_cat & ps_reg_03 have too many missing values (-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6    149327\n",
       "0.0    149227\n",
       "0.2    149157\n",
       "0.5    149148\n",
       "0.1    148797\n",
       "0.8    148635\n",
       "0.4    148527\n",
       "0.3    148476\n",
       "0.9    148411\n",
       "0.7    148323\n",
       "Name: ps_calc_01, dtype: int64"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "traintest['ps_calc_01'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "target           1.000000\n",
       "ps_ind_06_bin   -0.034017\n",
       "ps_ind_07_bin    0.034218\n",
       "ps_ind_17_bin    0.037053\n",
       "ps_reg_02        0.034800\n",
       "ps_reg_03        0.030888\n",
       "ps_car_02_cat   -0.031534\n",
       "ps_car_03_cat    0.032401\n",
       "ps_car_04_cat    0.032900\n",
       "ps_car_07_cat   -0.036395\n",
       "ps_car_12        0.038790\n",
       "ps_car_13        0.053899\n",
       "Name: target, dtype: float64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.corr().loc['target',] [abs(train.corr().loc['target',]) > 0.03]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['target', 'ps_ind_06_bin', 'ps_ind_07_bin', 'ps_ind_17_bin',\n",
       "       'ps_reg_02', 'ps_reg_03', 'ps_car_02_cat', 'ps_car_03_cat',\n",
       "       'ps_car_04_cat', 'ps_car_07_cat', 'ps_car_12', 'ps_car_13'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.corr().loc['target',] [abs(train.corr().loc['target',]) > 0.03].index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imputing median in variables with missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, feature in enumerate(list(train)):\n",
    "    if train[feature].isnull().sum() > 0:\n",
    "         train[feature+\"_mod\"] = train[feature].fillna(traintest[feature].median())\n",
    " \n",
    "for i, feature in enumerate(list(test)):\n",
    "    if test[feature].isnull().sum() > 0:\n",
    "        test[feature+\"_mod\"]= test[feature].fillna(traintest[feature].median())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing variables for significant chi-squared"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['ps_ind_05_cat_mod', 'ps_car_04_cat', 'ps_car_06_cat', 'ps_car_11_cat']\n"
     ]
    }
   ],
   "source": [
    "train['target_mod'] = train['target'].map(lambda x: 2 if x==0 else x)\n",
    "prob = 0.95\n",
    "list_imp_features = []\n",
    "for feature in cat_and_bin_features:\n",
    "    f_obs = np.array([train[feature].values,train['target_mod'].values])\n",
    "    stat, p, dof = stats.chi2_contingency(f_obs)[0:3]\n",
    "    critical = stats.chi2.ppf(prob, dof)\n",
    "    if abs(stat) >= critical:\n",
    "        list_imp_features.append(feature)\n",
    "print(list_imp_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Upsampling positive Tragets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(43388, 69)\n",
      "1    21694\n",
      "0    21694\n",
      "Name: target, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "train_pos = train[train['target'] == 1]\n",
    "train_neg = train[train['target'] == 0]\n",
    "train_neg_sampled = train_neg.sample(n=21694)\n",
    "train_upsampled = pd.concat([train_neg_sampled,train_pos])\n",
    "print(train_upsampled.shape)\n",
    "print(train_upsampled['target'].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using all variables except ones with too many missing values and the original unimputed variables with missings in them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Variables ps_reg_03, ps_car_03_cat and ps_car_05_cat are being dropped as they have too many missing values\n",
    "#Other variables are being replced with the same variables augmented by imputing values for missings\n",
    "X = train_upsampled.drop(['id','ps_car_01_cat','ps_car_02_cat','ps_car_03_cat','ps_car_05_cat',\n",
    "                          'ps_car_07_cat','ps_car_09_cat','ps_car_11','ps_car_12','ps_car_14','ps_ind_02_cat',\n",
    "                          'ps_ind_04_cat','ps_ind_05_cat','ps_reg_03'], axis=1)\n",
    "y = train_upsampled['target']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(43388, 55)\n",
      "(43388,)\n"
     ]
    }
   ],
   "source": [
    "print(X.shape)\n",
    "print(y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Standard Scaling Continous Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['target', 'ps_ind_01', 'ps_ind_03', 'ps_ind_06_bin', 'ps_ind_07_bin',\n",
       "       'ps_ind_08_bin', 'ps_ind_09_bin', 'ps_ind_10_bin', 'ps_ind_11_bin',\n",
       "       'ps_ind_12_bin', 'ps_ind_13_bin', 'ps_ind_14', 'ps_ind_15',\n",
       "       'ps_ind_16_bin', 'ps_ind_17_bin', 'ps_ind_18_bin', 'ps_reg_01',\n",
       "       'ps_reg_02', 'ps_car_04_cat', 'ps_car_06_cat', 'ps_car_08_cat',\n",
       "       'ps_car_10_cat', 'ps_car_11_cat', 'ps_car_13', 'ps_car_15',\n",
       "       'ps_calc_01', 'ps_calc_02', 'ps_calc_03', 'ps_calc_04', 'ps_calc_05',\n",
       "       'ps_calc_06', 'ps_calc_07', 'ps_calc_08', 'ps_calc_09', 'ps_calc_10',\n",
       "       'ps_calc_11', 'ps_calc_12', 'ps_calc_13', 'ps_calc_14',\n",
       "       'ps_calc_15_bin', 'ps_calc_16_bin', 'ps_calc_17_bin', 'ps_calc_18_bin',\n",
       "       'ps_calc_19_bin', 'ps_calc_20_bin', 'ps_car_01_cat_mod',\n",
       "       'ps_car_02_cat_mod', 'ps_car_07_cat_mod', 'ps_car_09_cat_mod',\n",
       "       'ps_car_11_mod', 'ps_car_12_mod', 'ps_car_14_mod', 'ps_ind_02_cat_mod',\n",
       "       'ps_ind_04_cat_mod', 'ps_ind_05_cat_mod'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(43388, 25)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Supratik\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\data.py:645: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by StandardScaler.\n",
      "  return self.partial_fit(X, y)\n",
      "C:\\Users\\Supratik\\Anaconda3\\lib\\site-packages\\sklearn\\base.py:464: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by StandardScaler.\n",
      "  return self.fit(X, **fit_params).transform(X)\n"
     ]
    }
   ],
   "source": [
    "sc = StandardScaler()\n",
    "\n",
    "scaled_X = pd.DataFrame(sc.fit_transform(X[['ps_ind_01', 'ps_ind_03', \n",
    "       'ps_ind_14', 'ps_ind_15', 'ps_reg_01','ps_reg_02', 'ps_car_13', 'ps_car_15',\n",
    "       'ps_calc_01', 'ps_calc_02', 'ps_calc_03', 'ps_calc_04', 'ps_calc_05',\n",
    "       'ps_calc_06', 'ps_calc_07', 'ps_calc_08', 'ps_calc_09', 'ps_calc_10',\n",
    "       'ps_calc_11', 'ps_calc_12', 'ps_calc_13', 'ps_calc_14',\n",
    "       'ps_car_11_mod', 'ps_car_12_mod', 'ps_car_14_mod']]))\n",
    "\n",
    "scaled_X.columns = ['ps_ind_01', 'ps_ind_03', \n",
    "       'ps_ind_14', 'ps_ind_15', 'ps_reg_01','ps_reg_02', 'ps_car_13', 'ps_car_15',\n",
    "       'ps_calc_01', 'ps_calc_02', 'ps_calc_03', 'ps_calc_04', 'ps_calc_05',\n",
    "       'ps_calc_06', 'ps_calc_07', 'ps_calc_08', 'ps_calc_09', 'ps_calc_10',\n",
    "       'ps_calc_11', 'ps_calc_12', 'ps_calc_13', 'ps_calc_14',\n",
    "       'ps_car_11_mod', 'ps_car_12_mod', 'ps_car_14_mod']\n",
    "\n",
    "scaled_X = scaled_X.reset_index(drop=True)\n",
    "\n",
    "print(scaled_X.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Supratik\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:6: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by StandardScaler.\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "scaled_test_X = pd.DataFrame(sc.transform(test[['ps_ind_01', 'ps_ind_03', \n",
    "       'ps_ind_14', 'ps_ind_15', 'ps_reg_01','ps_reg_02', 'ps_car_13', 'ps_car_15',\n",
    "       'ps_calc_01', 'ps_calc_02', 'ps_calc_03', 'ps_calc_04', 'ps_calc_05',\n",
    "       'ps_calc_06', 'ps_calc_07', 'ps_calc_08', 'ps_calc_09', 'ps_calc_10',\n",
    "       'ps_calc_11', 'ps_calc_12', 'ps_calc_13', 'ps_calc_14',\n",
    "       'ps_car_11_mod', 'ps_car_12_mod', 'ps_car_14_mod']]))\n",
    "\n",
    "scaled_test_X.columns = ['ps_ind_01', 'ps_ind_03', \n",
    "       'ps_ind_14', 'ps_ind_15', 'ps_reg_01','ps_reg_02', 'ps_car_13', 'ps_car_15',\n",
    "       'ps_calc_01', 'ps_calc_02', 'ps_calc_03', 'ps_calc_04', 'ps_calc_05',\n",
    "       'ps_calc_06', 'ps_calc_07', 'ps_calc_08', 'ps_calc_09', 'ps_calc_10',\n",
    "       'ps_calc_11', 'ps_calc_12', 'ps_calc_13', 'ps_calc_14',\n",
    "       'ps_car_11_mod', 'ps_car_12_mod', 'ps_car_14_mod']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(892816, 25)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scaled_test_X.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# One Hot Encoding Binary Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Supratik\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\_encoders.py:371: FutureWarning: The handling of integer data will change in version 0.22. Currently, the categories are determined based on the range [0, max(values)], while in the future they will be determined based on the unique values.\n",
      "If you want the future behaviour and silence this warning, you can specify \"categories='auto'\".\n",
      "In case you used a LabelEncoder before this OneHotEncoder to convert the categories to integers, then you can now use the OneHotEncoder directly.\n",
      "  warnings.warn(msg, FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "oh = OneHotEncoder()\n",
    "ohencoded_x = oh.fit_transform(X[['ps_ind_06_bin', 'ps_ind_07_bin',\n",
    "       'ps_ind_08_bin', 'ps_ind_09_bin', 'ps_ind_10_bin', 'ps_ind_11_bin',\n",
    "       'ps_ind_12_bin', 'ps_ind_13_bin','ps_ind_16_bin', 'ps_ind_17_bin', 'ps_ind_18_bin',\n",
    "       'ps_calc_15_bin', 'ps_calc_16_bin', 'ps_calc_17_bin', 'ps_calc_18_bin',\n",
    "       'ps_calc_19_bin', 'ps_calc_20_bin']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "ohencoded_test_x = oh.transform(test[['ps_ind_06_bin', 'ps_ind_07_bin',\n",
    "       'ps_ind_08_bin', 'ps_ind_09_bin', 'ps_ind_10_bin', 'ps_ind_11_bin',\n",
    "       'ps_ind_12_bin', 'ps_ind_13_bin','ps_ind_16_bin', 'ps_ind_17_bin', 'ps_ind_18_bin',\n",
    "       'ps_calc_15_bin', 'ps_calc_16_bin', 'ps_calc_17_bin', 'ps_calc_18_bin',\n",
    "       'ps_calc_19_bin', 'ps_calc_20_bin']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(43388, 34)\n",
      "(892816, 34)\n"
     ]
    }
   ],
   "source": [
    "oh_df = pd.DataFrame(ohencoded_x.toarray())\n",
    "oh_df_test = pd.DataFrame(ohencoded_test_x.toarray())\n",
    "print(oh_df.shape)\n",
    "print(oh_df_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Mean Encoding Categorical Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "X['ps_car_04_cat_enc'] = X['ps_car_04_cat'].map(X.groupby('ps_car_04_cat').target.mean())\n",
    "X['ps_car_06_cat_enc'] = X['ps_car_06_cat'].map(X.groupby('ps_car_06_cat').target.mean())\n",
    "X['ps_car_08_cat_enc'] = X['ps_car_08_cat'].map(X.groupby('ps_car_08_cat').target.mean())\n",
    "X['ps_car_10_cat_enc'] = X['ps_car_10_cat'].map(X.groupby('ps_car_10_cat').target.mean())\n",
    "X['ps_car_11_cat_enc'] = X['ps_car_11_cat'].map(X.groupby('ps_car_11_cat').target.mean())\n",
    "X['ps_car_01_cat_mod_enc'] = X['ps_car_01_cat_mod'].map(X.groupby('ps_car_01_cat_mod').target.mean())\n",
    "X['ps_car_02_cat_mod_enc'] = X['ps_car_02_cat_mod'].map(X.groupby('ps_car_02_cat_mod').target.mean())\n",
    "X['ps_car_07_cat_mod_enc'] = X['ps_car_07_cat_mod'].map(X.groupby('ps_car_07_cat_mod').target.mean())\n",
    "X['ps_car_09_cat_mod_enc'] = X['ps_car_09_cat_mod'].map(X.groupby('ps_car_09_cat_mod').target.mean())\n",
    "X['ps_ind_02_cat_mod_enc'] = X['ps_ind_02_cat_mod'].map(X.groupby('ps_ind_02_cat_mod').target.mean())\n",
    "X['ps_ind_04_cat_mod_enc'] = X['ps_ind_04_cat_mod'].map(X.groupby('ps_ind_04_cat_mod').target.mean())\n",
    "X['ps_ind_05_cat_mod_enc'] = X['ps_ind_05_cat_mod'].map(X.groupby('ps_ind_05_cat_mod').target.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "test['ps_car_04_cat_enc'] = test['ps_car_04_cat'].map(X.groupby('ps_car_04_cat').target.mean())\n",
    "test['ps_car_06_cat_enc'] = test['ps_car_06_cat'].map(X.groupby('ps_car_06_cat').target.mean())\n",
    "test['ps_car_08_cat_enc'] = test['ps_car_08_cat'].map(X.groupby('ps_car_08_cat').target.mean())\n",
    "test['ps_car_10_cat_enc'] = test['ps_car_10_cat'].map(X.groupby('ps_car_10_cat').target.mean())\n",
    "test['ps_car_11_cat_enc'] = test['ps_car_11_cat'].map(X.groupby('ps_car_11_cat').target.mean())\n",
    "test['ps_car_01_cat_mod_enc'] = test['ps_car_01_cat_mod'].map(X.groupby('ps_car_01_cat_mod').target.mean())\n",
    "test['ps_car_02_cat_mod_enc'] = test['ps_car_02_cat_mod'].map(X.groupby('ps_car_02_cat_mod').target.mean())\n",
    "test['ps_car_07_cat_mod_enc'] = test['ps_car_07_cat_mod'].map(X.groupby('ps_car_07_cat_mod').target.mean())\n",
    "test['ps_car_09_cat_mod_enc'] = test['ps_car_09_cat_mod'].map(X.groupby('ps_car_09_cat_mod').target.mean())\n",
    "test['ps_ind_02_cat_mod_enc'] = test['ps_ind_02_cat_mod'].map(X.groupby('ps_ind_02_cat_mod').target.mean())\n",
    "test['ps_ind_04_cat_mod_enc'] = test['ps_ind_04_cat_mod'].map(X.groupby('ps_ind_04_cat_mod').target.mean())\n",
    "test['ps_ind_05_cat_mod_enc'] = test['ps_ind_05_cat_mod'].map(X.groupby('ps_ind_05_cat_mod').target.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_encoded = X[['ps_car_04_cat_enc','ps_car_06_cat_enc',\n",
    "                                               'ps_car_08_cat_enc','ps_car_10_cat_enc','ps_car_11_cat_enc',\n",
    "                                               'ps_car_01_cat_mod_enc','ps_car_02_cat_mod_enc',\n",
    "                                              'ps_car_07_cat_mod_enc','ps_car_09_cat_mod_enc',\n",
    "                                              'ps_ind_02_cat_mod_enc','ps_ind_04_cat_mod_enc',\n",
    "                                              'ps_ind_05_cat_mod_enc']].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(43388, 12)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_encoded.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_mean_encoded = test[['ps_car_04_cat_enc','ps_car_06_cat_enc',\n",
    "                                               'ps_car_08_cat_enc','ps_car_10_cat_enc','ps_car_11_cat_enc',\n",
    "                                               'ps_car_01_cat_mod_enc','ps_car_02_cat_mod_enc',\n",
    "                                              'ps_car_07_cat_mod_enc','ps_car_09_cat_mod_enc',\n",
    "                                              'ps_ind_02_cat_mod_enc','ps_ind_04_cat_mod_enc',\n",
    "                                              'ps_ind_05_cat_mod_enc']].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(892816, 12)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_mean_encoded.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_new = pd.concat([scaled_X, oh_df, mean_encoded], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(43388, 71)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_new.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_new = pd.concat([scaled_test_X, oh_df_test, test_mean_encoded], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "y=y.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X_new, y, test_size = 0.2, random_state = 123)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Also using a set of unscaled and unencoded values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_orig =train.drop(['id','target','ps_car_01_cat','ps_car_02_cat','ps_car_03_cat','ps_car_05_cat',\n",
    "                          'ps_car_07_cat','ps_car_09_cat','ps_car_11','ps_car_12','ps_car_14','ps_ind_02_cat',\n",
    "                          'ps_ind_04_cat','ps_ind_05_cat','ps_reg_03'], axis=1)\n",
    "y_orig = train['target']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dropping 'ps_calc' features which do not show any relationship with other features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "col_to_drop = list(X_orig.columns[X_orig.columns.str.startswith('ps_calc_')])\n",
    "X_orig = X_orig.drop(col_to_drop, axis=1)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_orig, X_test_orig, y_train_orig, y_test_orig = \\\n",
    "    train_test_split(X_orig, y_orig, test_size = 0.2, random_state = 123)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define Normalized Gini Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gini(actual, pred):\n",
    "    assert (len(actual) == len(pred))\n",
    "    all = np.asarray(np.c_[actual, pred, np.arange(len(actual))], dtype=np.float)\n",
    "    all = all[np.lexsort((all[:, 2], -1 * all[:, 1]))]\n",
    "    totalLosses = all[:, 0].sum()\n",
    "    giniSum = all[:, 0].cumsum().sum() / totalLosses\n",
    "\n",
    "    giniSum -= (len(actual) + 1) / 2.\n",
    "    return giniSum / len(actual)\n",
    "\n",
    "\n",
    "def gini_normalized(actual, pred):\n",
    "    return gini(actual, pred) / gini(actual, actual)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using predict method of sklearn Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = LogisticRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Supratik\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='warn',\n",
       "          n_jobs=None, penalty='l2', random_state=None, solver='warn',\n",
       "          tol=0.0001, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = lr.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    4515\n",
       "1    4163\n",
       "dtype: int64"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.Series(predictions).value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy_score:  0.5800875777828993\n",
      "confusion_matrix: \n",
      " [[2556 1685]\n",
      " [1959 2478]]\n",
      "classification_report: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.57      0.60      0.58      4241\n",
      "           1       0.60      0.56      0.58      4437\n",
      "\n",
      "   micro avg       0.58      0.58      0.58      8678\n",
      "   macro avg       0.58      0.58      0.58      8678\n",
      "weighted avg       0.58      0.58      0.58      8678\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"accuracy_score: \", accuracy_score(y_test, predictions))\n",
    "print(\"confusion_matrix: \\n\", confusion_matrix(y_test, predictions))\n",
    "print(\"classification_report: \\n\", classification_report(y_test, predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gini: 0.041, Max. Gini: 0.244, Normalized Gini: 0.166\n"
     ]
    }
   ],
   "source": [
    "gini_predictions = gini(y_test, predictions)\n",
    "gini_max = gini(y_test, y_test)\n",
    "ngini= gini_normalized(y_test, predictions)\n",
    "print('Gini: %.3f, Max. Gini: %.3f, Normalized Gini: %.3f' % (gini_predictions, gini_max, ngini))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using predict_proba method of sklearn Logistic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_probs = list(map(lambda x: x[1],lr.predict_proba(X_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_curve\n",
    "fpr, tpr, thresholds =roc_curve(y_test, predicted_probs)\n",
    "\n",
    "def cutoff_youdens_j(fpr,tpr,thresholds):\n",
    "    j_scores = tpr-fpr\n",
    "    j_ordered = sorted(zip(j_scores,thresholds))\n",
    "    return j_ordered[-1][1]\n",
    "\n",
    "threshold=cutoff_youdens_j(fpr,tpr,thresholds)\n",
    "\n",
    "print(threshold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions_new = list(map(lambda x: 1 if x > threshold else 0,predicted_probs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy_score:  0.5873473150495506\n",
      "confusion_matrix: \n",
      " [[2405 1836]\n",
      " [1745 2692]]\n",
      "classification_report: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.58      0.57      0.57      4241\n",
      "           1       0.59      0.61      0.60      4437\n",
      "\n",
      "   micro avg       0.59      0.59      0.59      8678\n",
      "   macro avg       0.59      0.59      0.59      8678\n",
      "weighted avg       0.59      0.59      0.59      8678\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"accuracy_score: \", accuracy_score(y_test, predictions_new))\n",
    "print(\"confusion_matrix: \\n\", confusion_matrix(y_test, predictions_new))\n",
    "print(\"classification_report: \\n\", classification_report(y_test, predictions_new))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gini: 0.057, Max. Gini: 0.244, Normalized Gini: 0.233\n"
     ]
    }
   ],
   "source": [
    "gini_predictions = gini(y_test, predicted_probs)\n",
    "gini_max = gini(y_test, y_test)\n",
    "ngini= gini_normalized(y_test, predicted_probs)\n",
    "print('Gini: %.3f, Max. Gini: %.3f, Normalized Gini: %.3f' % (gini_predictions, gini_max, ngini))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using predict method of statsmodels Logistic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "import statsmodels.formula.api as smf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.columns = ['psind01','psind03','psind14','psind15','psreg01','psreg02','pscar13','pscar15',\n",
    "                   'pscalc01','pscalc02','pscalc03','pscalc04','pscalc05','pscalc06','pscalc07',\n",
    "                   'pscalc08','pscalc09','pscalc10','pscalc11','pscalc12','pscalc13','pscalc14',\n",
    "                   'pscar11mod','pscar12mod','pscar14mod','OH0','OH1','OH2','OH3','OH4','OH5','OH6','OH7','OH8',\n",
    "                   'OH9','OH10','OH11','OH12','OH13','OH14','OH15','OH16','OH17','OH18','OH19','OH20','OH21',\n",
    "                   'OH22','OH23','OH24','OH25','OH26','OH27','OH28','OH29','OH30','OH31','OH32','OH33',\n",
    "                   'pscar04catenc','pscar06catenc','pscar08catenc','pscar10catenc','pscar11catenc',\n",
    "                   'pscar01catmodenc','pscar02catmodenc','pscar07catmodenc','pscar09catmodenc','psind02catmodenc',\n",
    "                   'psind04catmodenc','psind05catmodenc']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test.columns = ['psind01','psind03','psind14','psind15','psreg01','psreg02','pscar13','pscar15',\n",
    "                   'pscalc01','pscalc02','pscalc03','pscalc04','pscalc05','pscalc06','pscalc07',\n",
    "                   'pscalc08','pscalc09','pscalc10','pscalc11','pscalc12','pscalc13','pscalc14',\n",
    "                   'pscar11mod','pscar12mod','pscar14mod','OH0','OH1','OH2','OH3','OH4','OH5','OH6','OH7','OH8',\n",
    "                   'OH9','OH10','OH11','OH12','OH13','OH14','OH15','OH16','OH17','OH18','OH19','OH20','OH21',\n",
    "                   'OH22','OH23','OH24','OH25','OH26','OH27','OH28','OH29','OH30','OH31','OH32','OH33',\n",
    "                   'pscar04catenc','pscar06catenc','pscar08catenc','pscar10catenc','pscar11catenc',\n",
    "                   'pscar01catmodenc','pscar02catmodenc','pscar07catmodenc','pscar09catmodenc','psind02catmodenc',\n",
    "                   'psind04catmodenc','psind05catmodenc']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_new.columns = ['psind01','psind03','psind14','psind15','psreg01','psreg02','pscar13','pscar15',\n",
    "                   'pscalc01','pscalc02','pscalc03','pscalc04','pscalc05','pscalc06','pscalc07',\n",
    "                   'pscalc08','pscalc09','pscalc10','pscalc11','pscalc12','pscalc13','pscalc14',\n",
    "                   'pscar11mod','pscar12mod','pscar14mod','OH0','OH1','OH2','OH3','OH4','OH5','OH6','OH7','OH8',\n",
    "                   'OH9','OH10','OH11','OH12','OH13','OH14','OH15','OH16','OH17','OH18','OH19','OH20','OH21',\n",
    "                   'OH22','OH23','OH24','OH25','OH26','OH27','OH28','OH29','OH30','OH31','OH32','OH33',\n",
    "                   'pscar04catenc','pscar06catenc','pscar08catenc','pscar10catenc','pscar11catenc',\n",
    "                   'pscar01catmodenc','pscar02catmodenc','pscar07catmodenc','pscar09catmodenc','psind02catmodenc',\n",
    "                   'psind04catmodenc','psind05catmodenc']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_logistic = X_train.copy()\n",
    "X_train_logistic['target']=y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Maximum number of iterations has been exceeded.\n",
      "         Current function value: 0.666286\n",
      "         Iterations: 35\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Supratik\\Anaconda3\\lib\\site-packages\\statsmodels\\base\\model.py:508: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
      "  \"Check mle_retvals\", ConvergenceWarning)\n"
     ]
    }
   ],
   "source": [
    "model = '''target ~ psind01+psind03+psind14+psind15+psreg01+psreg02+pscar13+pscar15+\n",
    "                   pscalc01+pscalc02+pscalc03+pscalc04+pscalc05+pscalc06+pscalc07+\n",
    "                   pscalc08+pscalc09+pscalc10+pscalc11+pscalc12+pscalc13+pscalc14+\n",
    "                   pscar11mod+pscar12mod+pscar14mod+OH0+OH1+OH2+OH3+OH4+OH5+OH6+OH7+OH8+OH9+OH10+\n",
    "                   OH11+OH12+OH13+OH14+OH15+OH16+OH17+OH18+OH19+OH20+OH21+OH22+OH23+OH24+OH25+OH26+OH27+OH28+OH29+\n",
    "                   OH30+OH31+OH32+OH33+pscar04catenc+pscar06catenc+pscar08catenc+\n",
    "                   pscar10catenc+pscar11catenc+pscar01catmodenc+pscar02catmodenc+\n",
    "                   pscar07catmodenc+pscar09catmodenc+psind02catmodenc+psind04catmodenc+\n",
    "                   psind05catmodenc'''\n",
    "results = smf.logit(formula = model, data=X_train_logistic, missing='drop').fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                           Logit Regression Results                           \n",
      "==============================================================================\n",
      "Dep. Variable:                 target   No. Observations:                34710\n",
      "Model:                          Logit   Df Residuals:                    34657\n",
      "Method:                           MLE   Df Model:                           52\n",
      "Date:                Wed, 03 Jul 2019   Pseudo R-squ.:                 0.03873\n",
      "Time:                        21:42:14   Log-Likelihood:                -23127.\n",
      "converged:                      False   LL-Null:                       -24059.\n",
      "                                        LLR p-value:                     0.000\n",
      "====================================================================================\n",
      "                       coef    std err          z      P>|z|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------------\n",
      "Intercept           -1.0287        nan        nan        nan         nan         nan\n",
      "psind01              0.0341      0.012      2.754      0.006       0.010       0.058\n",
      "psind03              0.0445      0.012      3.744      0.000       0.021       0.068\n",
      "psind14             -0.1544        nan        nan        nan         nan         nan\n",
      "psind15             -0.1026      0.013     -7.976      0.000      -0.128      -0.077\n",
      "psreg01              0.0811      0.013      6.206      0.000       0.055       0.107\n",
      "psreg02              0.0551      0.013      4.102      0.000       0.029       0.082\n",
      "pscar13              0.0927      0.026      3.515      0.000       0.041       0.144\n",
      "pscar15              0.0425      0.016      2.711      0.007       0.012       0.073\n",
      "pscalc01             0.0199      0.011      1.798      0.072      -0.002       0.042\n",
      "pscalc02             0.0096      0.011      0.872      0.383      -0.012       0.031\n",
      "pscalc03             0.0066      0.011      0.600      0.549      -0.015       0.028\n",
      "pscalc04             0.0050      0.011      0.450      0.652      -0.017       0.027\n",
      "pscalc05             0.0047      0.011      0.427      0.669      -0.017       0.026\n",
      "pscalc06            -0.0003      0.011     -0.023      0.981      -0.022       0.021\n",
      "pscalc07             0.0023      0.011      0.206      0.837      -0.019       0.024\n",
      "pscalc08            -0.0091      0.011     -0.829      0.407      -0.031       0.012\n",
      "pscalc09            -0.0046      0.011     -0.413      0.679      -0.026       0.017\n",
      "pscalc10             0.0003      0.011      0.031      0.976      -0.021       0.022\n",
      "pscalc11            -0.0006      0.011     -0.052      0.959      -0.022       0.021\n",
      "pscalc12            -0.0058      0.011     -0.525      0.599      -0.027       0.016\n",
      "pscalc13            -0.0024      0.011     -0.215      0.830      -0.024       0.019\n",
      "pscalc14             0.0172      0.011      1.560      0.119      -0.004       0.039\n",
      "pscar11mod          -0.0151      0.012     -1.242      0.214      -0.039       0.009\n",
      "pscar12mod           0.0092      0.020      0.452      0.651      -0.031       0.049\n",
      "pscar14mod          -0.0762      0.015     -5.219      0.000      -0.105      -0.048\n",
      "OH0                 -0.7158   4.57e+05  -1.57e-06      1.000   -8.96e+05    8.96e+05\n",
      "OH1                 -0.3129        nan        nan        nan         nan         nan\n",
      "OH2                 -0.8322        nan        nan        nan         nan         nan\n",
      "OH3                 -0.1965        nan        nan        nan         nan         nan\n",
      "OH4                 -0.8069   5.58e+05  -1.45e-06      1.000   -1.09e+06    1.09e+06\n",
      "OH5                 -0.2218        nan        nan        nan         nan         nan\n",
      "OH6                 -0.7312        nan        nan        nan         nan         nan\n",
      "OH7                 -0.2975        nan        nan        nan         nan         nan\n",
      "OH8                 -0.6661    5.7e+05  -1.17e-06      1.000   -1.12e+06    1.12e+06\n",
      "OH9                 -0.3626        nan        nan        nan         nan         nan\n",
      "OH10                -0.9183   2.56e+04  -3.58e-05      1.000   -5.03e+04    5.03e+04\n",
      "OH11                -0.1104        nan        nan        nan         nan         nan\n",
      "OH12                -1.0800   2.39e+05  -4.53e-06      1.000   -4.68e+05    4.68e+05\n",
      "OH13                 0.0513        nan        nan        nan         nan         nan\n",
      "OH14                -1.4133    3.2e+05  -4.41e-06      1.000   -6.28e+05    6.28e+05\n",
      "OH15                 0.3846        nan        nan        nan         nan         nan\n",
      "OH16                -0.4614        nan        nan        nan         nan         nan\n",
      "OH17                -0.5673        nan        nan        nan         nan         nan\n",
      "OH18                -0.6563   7.95e+04  -8.26e-06      1.000   -1.56e+05    1.56e+05\n",
      "OH19                -0.3724   8.97e+04  -4.15e-06      1.000   -1.76e+05    1.76e+05\n",
      "OH20                -0.4982   1.54e+05  -3.23e-06      1.000   -3.02e+05    3.02e+05\n",
      "OH21                -0.5305   1.58e+05  -3.37e-06      1.000   -3.09e+05    3.09e+05\n",
      "OH22                -0.5228        nan        nan        nan         nan         nan\n",
      "OH23                -0.5058        nan        nan        nan         nan         nan\n",
      "OH24                -0.5109   3.25e+05  -1.57e-06      1.000   -6.38e+05    6.38e+05\n",
      "OH25                -0.5177   3.24e+05   -1.6e-06      1.000   -6.35e+05    6.35e+05\n",
      "OH26                -0.5045        nan        nan        nan         nan         nan\n",
      "OH27                -0.5242        nan        nan        nan         nan         nan\n",
      "OH28                -0.5038   1.16e+06  -4.34e-07      1.000   -2.28e+06    2.28e+06\n",
      "OH29                -0.5248   1.16e+06  -4.53e-07      1.000   -2.27e+06    2.27e+06\n",
      "OH30                -0.5082   3.85e+05  -1.32e-06      1.000   -7.55e+05    7.55e+05\n",
      "OH31                -0.5205   3.85e+05  -1.35e-06      1.000   -7.55e+05    7.55e+05\n",
      "OH32                -0.4869        nan        nan        nan         nan         nan\n",
      "OH33                -0.5418        nan        nan        nan         nan         nan\n",
      "pscar04catenc        0.1135      0.380      0.299      0.765      -0.631       0.858\n",
      "pscar06catenc       -0.3063      0.346     -0.886      0.376      -0.984       0.371\n",
      "pscar08catenc        0.7245      0.462      1.568      0.117      -0.181       1.630\n",
      "pscar10catenc        3.3555      2.245      1.495      0.135      -1.044       7.755\n",
      "pscar11catenc        2.1887      0.236      9.290      0.000       1.727       2.650\n",
      "pscar01catmodenc     1.8977      0.250      7.580      0.000       1.407       2.388\n",
      "pscar02catmodenc     0.4772      0.359      1.330      0.184      -0.226       1.181\n",
      "pscar07catmodenc     2.8331      0.566      5.006      0.000       1.724       3.942\n",
      "pscar09catmodenc     2.0042      0.373      5.379      0.000       1.274       2.734\n",
      "psind02catmodenc     5.7824      1.346      4.297      0.000       3.145       8.420\n",
      "psind04catmodenc     1.5421      0.901      1.712      0.087      -0.223       3.308\n",
      "psind05catmodenc     4.1369      0.285     14.517      0.000       3.578       4.695\n",
      "====================================================================================\n"
     ]
    }
   ],
   "source": [
    "print(results.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5002111834572159\n"
     ]
    }
   ],
   "source": [
    "pred_prob_stat = results.predict(X_test)\n",
    "\n",
    "fpr, tpr, thresholds =roc_curve(y_test, pred_prob_stat)\n",
    "\n",
    "threshold=cutoff_youdens_j(fpr,tpr,thresholds)\n",
    "\n",
    "print(threshold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions_stats = list(map(lambda x: 1 if x > threshold else 0,pred_prob_stat))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy_score:  0.5858492740262733\n",
      "confusion_matrix: \n",
      " [[2596 1645]\n",
      " [1949 2488]]\n",
      "classification_report: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.57      0.61      0.59      4241\n",
      "           1       0.60      0.56      0.58      4437\n",
      "\n",
      "   micro avg       0.59      0.59      0.59      8678\n",
      "   macro avg       0.59      0.59      0.59      8678\n",
      "weighted avg       0.59      0.59      0.59      8678\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"accuracy_score: \", accuracy_score(y_test, predictions_stats))\n",
    "print(\"confusion_matrix: \\n\", confusion_matrix(y_test, predictions_stats))\n",
    "print(\"classification_report: \\n\", classification_report(y_test, predictions_stats))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gini: 0.043, Max. Gini: 0.244, Normalized Gini: 0.178\n"
     ]
    }
   ],
   "source": [
    "# Gini with target 1/0\n",
    "gini_predictions = gini(y_test, predictions_stats)\n",
    "gini_max = gini(y_test, y_test)\n",
    "ngini= gini_normalized(y_test, predictions_stats)\n",
    "print('Gini: %.3f, Max. Gini: %.3f, Normalized Gini: %.3f' % (gini_predictions, gini_max, ngini))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gini: 0.057, Max. Gini: 0.244, Normalized Gini: 0.235\n"
     ]
    }
   ],
   "source": [
    "# Gini with predicted probabilities\n",
    "gini_predictions = gini(y_test, pred_prob_stat)\n",
    "gini_max = gini(y_test, y_test)\n",
    "ngini= gini_normalized(y_test, pred_prob_stat)\n",
    "print('Gini: %.3f, Max. Gini: %.3f, Normalized Gini: %.3f' % (gini_predictions, gini_max, ngini))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_pred = results.predict(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission = pd.concat([test['id'], pd.DataFrame({'target':test_pred})], axis=1)\n",
    "submission.to_csv('submission.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using Random Forest Classifier on all variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [],
   "source": [
    "RF = RandomForestClassifier(\n",
    "    n_estimators=1000,\n",
    "    criterion='gini',\n",
    "    max_depth=2**10,\n",
    "    min_samples_split=2,\n",
    "    min_samples_leaf=0.02,\n",
    "    min_weight_fraction_leaf=0.0,\n",
    "    max_features=0.8,\n",
    "    max_leaf_nodes=None,\n",
    "    n_jobs=-1,\n",
    "    random_state=123,\n",
    "    verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  42 tasks      | elapsed:    2.6s\n",
      "[Parallel(n_jobs=-1)]: Done 192 tasks      | elapsed:   13.6s\n",
      "[Parallel(n_jobs=-1)]: Done 442 tasks      | elapsed:   34.3s\n",
      "[Parallel(n_jobs=-1)]: Done 792 tasks      | elapsed:   56.1s\n",
      "[Parallel(n_jobs=-1)]: Done 1000 out of 1000 | elapsed:  1.1min finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=1024, max_features=0.8, max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=0.02, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, n_estimators=1000, n_jobs=-1,\n",
       "            oob_score=False, random_state=123, verbose=1, warm_start=False)"
      ]
     },
     "execution_count": 197,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "RF.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=4)]: Using backend ThreadingBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=4)]: Done 442 tasks      | elapsed:    0.2s\n",
      "[Parallel(n_jobs=4)]: Done 792 tasks      | elapsed:    0.4s\n",
      "[Parallel(n_jobs=4)]: Done 1000 out of 1000 | elapsed:    0.5s finished\n"
     ]
    }
   ],
   "source": [
    "RF_preds = RF.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy_score:  0.5795114081585618\n",
      "confusion_matrix: \n",
      " [[2549 1692]\n",
      " [1957 2480]]\n",
      "classification_report: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.57      0.60      0.58      4241\n",
      "           1       0.59      0.56      0.58      4437\n",
      "\n",
      "   micro avg       0.58      0.58      0.58      8678\n",
      "   macro avg       0.58      0.58      0.58      8678\n",
      "weighted avg       0.58      0.58      0.58      8678\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"accuracy_score: \", accuracy_score(y_test, RF_preds))\n",
    "print(\"confusion_matrix: \\n\", confusion_matrix(y_test, RF_preds))\n",
    "print(\"classification_report: \\n\", classification_report(y_test, RF_preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gini: 0.040, Max. Gini: 0.244, Normalized Gini: 0.166\n"
     ]
    }
   ],
   "source": [
    "gini_predictions = gini(y_test, RF_preds)\n",
    "gini_max = gini(y_test, y_test)\n",
    "ngini= gini_normalized(y_test, RF_preds)\n",
    "print('Gini: %.3f, Max. Gini: %.3f, Normalized Gini: %.3f' % (gini_predictions, gini_max, ngini))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=4)]: Using backend ThreadingBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 442 tasks      | elapsed:    0.2s\n",
      "[Parallel(n_jobs=4)]: Done 792 tasks      | elapsed:    0.4s\n",
      "[Parallel(n_jobs=4)]: Done 1000 out of 1000 | elapsed:    0.5s finished\n"
     ]
    }
   ],
   "source": [
    "RF_pred_prob = list(map(lambda x: x[1],RF.predict_proba(X_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gini: 0.056, Max. Gini: 0.244, Normalized Gini: 0.229\n"
     ]
    }
   ],
   "source": [
    "gini_predictions = gini(y_test, RF_pred_prob)\n",
    "gini_max = gini(y_test, y_test)\n",
    "ngini= gini_normalized(y_test, RF_pred_prob)\n",
    "print('Gini: %.3f, Max. Gini: %.3f, Normalized Gini: %.3f' % (gini_predictions, gini_max, ngini))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=4)]: Using backend ThreadingBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    2.0s\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:    9.2s\n",
      "[Parallel(n_jobs=4)]: Done 442 tasks      | elapsed:   22.0s\n",
      "[Parallel(n_jobs=4)]: Done 792 tasks      | elapsed:   39.2s\n",
      "[Parallel(n_jobs=4)]: Done 1000 out of 1000 | elapsed:   50.2s finished\n"
     ]
    }
   ],
   "source": [
    "test_pred = RF.predict(test.drop(['id','ps_car_01_cat','ps_car_02_cat','ps_car_03_cat','ps_car_05_cat',\n",
    "                          'ps_car_07_cat','ps_car_09_cat','ps_car_11','ps_car_12','ps_car_14','ps_ind_02_cat',\n",
    "                          'ps_ind_04_cat','ps_ind_05_cat','ps_reg_03'], axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission = pd.concat([test['id'], pd.DataFrame({'target':test_pred})], axis=1)\n",
    "submission.to_csv('submission.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using XGBoost Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install xgboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost as xgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up classifier\n",
    "xg_cl = xgb.XGBClassifier(    \n",
    "                        n_estimators=500, #172\n",
    "                        max_depth=4,\n",
    "                        objective=\"binary:logistic\",\n",
    "                        learning_rate=0.07, \n",
    "                        subsample=.8,\n",
    "                        min_child_weight=6,\n",
    "                        colsample_bytree=.8,\n",
    "                        scale_pos_weight=1,\n",
    "                        gamma=10,\n",
    "                        reg_alpha=8,\n",
    "                        reg_lambda=1.3,\n",
    "                        random_state=123\n",
    "                        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'xg_cl = xgb.XGBClassifier(n_estimators=200,\\n                        max_depth=4,\\n                        objective=\"binary:logistic\",\\n                        learning_rate=.1, \\n                        subsample=.8, \\n                        colsample_bytree=.8,\\n                        gamma=1,\\n                        reg_alpha=0,\\n                        reg_lambda=1,\\n                        nthread=2)'"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''xg_cl = xgb.XGBClassifier(n_estimators=200,\n",
    "                        max_depth=4,\n",
    "                        objective=\"binary:logistic\",\n",
    "                        learning_rate=.1, \n",
    "                        subsample=.8, \n",
    "                        colsample_bytree=.8,\n",
    "                        gamma=1,\n",
    "                        reg_alpha=0,\n",
    "                        reg_lambda=1,\n",
    "                        nthread=2)'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gini_xgb(preds, dtrain):\n",
    "    labels = dtrain.get_label()\n",
    "    gini_score = 1 - gini_normalized(labels, preds)\n",
    "    return [('gini', gini_score)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\tvalidation_0-error:0.036197\tvalidation_1-error:0.037449\tvalidation_0-gini:0.934294\tvalidation_1-gini:0.903067\n",
      "Multiple eval metrics have been passed: 'validation_1-gini' will be used for early stopping.\n",
      "\n",
      "Will train until validation_1-gini hasn't improved in 50 rounds.\n",
      "[1]\tvalidation_0-error:0.036197\tvalidation_1-error:0.037449\tvalidation_0-gini:0.891728\tvalidation_1-gini:0.861215\n",
      "[2]\tvalidation_0-error:0.036197\tvalidation_1-error:0.037449\tvalidation_0-gini:0.830153\tvalidation_1-gini:0.813576\n",
      "[3]\tvalidation_0-error:0.036197\tvalidation_1-error:0.037449\tvalidation_0-gini:0.820547\tvalidation_1-gini:0.805174\n",
      "[4]\tvalidation_0-error:0.036197\tvalidation_1-error:0.037449\tvalidation_0-gini:0.815579\tvalidation_1-gini:0.805589\n",
      "[5]\tvalidation_0-error:0.036197\tvalidation_1-error:0.037449\tvalidation_0-gini:0.805036\tvalidation_1-gini:0.795314\n",
      "[6]\tvalidation_0-error:0.036197\tvalidation_1-error:0.037449\tvalidation_0-gini:0.805701\tvalidation_1-gini:0.795406\n",
      "[7]\tvalidation_0-error:0.036197\tvalidation_1-error:0.037449\tvalidation_0-gini:0.797709\tvalidation_1-gini:0.78892\n",
      "[8]\tvalidation_0-error:0.036197\tvalidation_1-error:0.037449\tvalidation_0-gini:0.792718\tvalidation_1-gini:0.78504\n",
      "[9]\tvalidation_0-error:0.036197\tvalidation_1-error:0.037449\tvalidation_0-gini:0.793514\tvalidation_1-gini:0.786943\n",
      "[10]\tvalidation_0-error:0.036197\tvalidation_1-error:0.037449\tvalidation_0-gini:0.796133\tvalidation_1-gini:0.789096\n",
      "[11]\tvalidation_0-error:0.036197\tvalidation_1-error:0.037449\tvalidation_0-gini:0.796343\tvalidation_1-gini:0.789751\n",
      "[12]\tvalidation_0-error:0.036197\tvalidation_1-error:0.037449\tvalidation_0-gini:0.796781\tvalidation_1-gini:0.790183\n",
      "[13]\tvalidation_0-error:0.036197\tvalidation_1-error:0.037449\tvalidation_0-gini:0.794758\tvalidation_1-gini:0.787011\n",
      "[14]\tvalidation_0-error:0.036197\tvalidation_1-error:0.037449\tvalidation_0-gini:0.787791\tvalidation_1-gini:0.782176\n",
      "[15]\tvalidation_0-error:0.036197\tvalidation_1-error:0.037449\tvalidation_0-gini:0.785377\tvalidation_1-gini:0.78044\n",
      "[16]\tvalidation_0-error:0.036197\tvalidation_1-error:0.037449\tvalidation_0-gini:0.784609\tvalidation_1-gini:0.781135\n",
      "[17]\tvalidation_0-error:0.036197\tvalidation_1-error:0.037449\tvalidation_0-gini:0.783989\tvalidation_1-gini:0.781419\n",
      "[18]\tvalidation_0-error:0.036197\tvalidation_1-error:0.037449\tvalidation_0-gini:0.781821\tvalidation_1-gini:0.7797\n",
      "[19]\tvalidation_0-error:0.036197\tvalidation_1-error:0.037449\tvalidation_0-gini:0.780432\tvalidation_1-gini:0.778013\n",
      "[20]\tvalidation_0-error:0.036197\tvalidation_1-error:0.037449\tvalidation_0-gini:0.780153\tvalidation_1-gini:0.779059\n",
      "[21]\tvalidation_0-error:0.036197\tvalidation_1-error:0.037449\tvalidation_0-gini:0.780641\tvalidation_1-gini:0.778889\n",
      "[22]\tvalidation_0-error:0.036197\tvalidation_1-error:0.037449\tvalidation_0-gini:0.779875\tvalidation_1-gini:0.779201\n",
      "[23]\tvalidation_0-error:0.036197\tvalidation_1-error:0.037449\tvalidation_0-gini:0.774092\tvalidation_1-gini:0.774827\n",
      "[24]\tvalidation_0-error:0.036197\tvalidation_1-error:0.037449\tvalidation_0-gini:0.773885\tvalidation_1-gini:0.773975\n",
      "[25]\tvalidation_0-error:0.036197\tvalidation_1-error:0.037449\tvalidation_0-gini:0.774095\tvalidation_1-gini:0.774618\n",
      "[26]\tvalidation_0-error:0.036197\tvalidation_1-error:0.037449\tvalidation_0-gini:0.77293\tvalidation_1-gini:0.774945\n",
      "[27]\tvalidation_0-error:0.036197\tvalidation_1-error:0.037449\tvalidation_0-gini:0.771342\tvalidation_1-gini:0.773949\n",
      "[28]\tvalidation_0-error:0.036197\tvalidation_1-error:0.037449\tvalidation_0-gini:0.769192\tvalidation_1-gini:0.772353\n",
      "[29]\tvalidation_0-error:0.036197\tvalidation_1-error:0.037449\tvalidation_0-gini:0.768924\tvalidation_1-gini:0.771942\n",
      "[30]\tvalidation_0-error:0.036197\tvalidation_1-error:0.037449\tvalidation_0-gini:0.767586\tvalidation_1-gini:0.771164\n",
      "[31]\tvalidation_0-error:0.036197\tvalidation_1-error:0.037449\tvalidation_0-gini:0.766126\tvalidation_1-gini:0.769759\n",
      "[32]\tvalidation_0-error:0.036197\tvalidation_1-error:0.037449\tvalidation_0-gini:0.763276\tvalidation_1-gini:0.767253\n",
      "[33]\tvalidation_0-error:0.036197\tvalidation_1-error:0.037449\tvalidation_0-gini:0.761822\tvalidation_1-gini:0.765448\n",
      "[34]\tvalidation_0-error:0.036197\tvalidation_1-error:0.037449\tvalidation_0-gini:0.761432\tvalidation_1-gini:0.765395\n",
      "[35]\tvalidation_0-error:0.036197\tvalidation_1-error:0.037449\tvalidation_0-gini:0.759971\tvalidation_1-gini:0.76422\n",
      "[36]\tvalidation_0-error:0.036197\tvalidation_1-error:0.037449\tvalidation_0-gini:0.759659\tvalidation_1-gini:0.764267\n",
      "[37]\tvalidation_0-error:0.036197\tvalidation_1-error:0.037449\tvalidation_0-gini:0.759559\tvalidation_1-gini:0.764706\n",
      "[38]\tvalidation_0-error:0.036197\tvalidation_1-error:0.037449\tvalidation_0-gini:0.759225\tvalidation_1-gini:0.764617\n",
      "[39]\tvalidation_0-error:0.036197\tvalidation_1-error:0.037449\tvalidation_0-gini:0.75865\tvalidation_1-gini:0.764735\n",
      "[40]\tvalidation_0-error:0.036197\tvalidation_1-error:0.037449\tvalidation_0-gini:0.756295\tvalidation_1-gini:0.76167\n",
      "[41]\tvalidation_0-error:0.036197\tvalidation_1-error:0.037449\tvalidation_0-gini:0.755843\tvalidation_1-gini:0.761368\n",
      "[42]\tvalidation_0-error:0.036197\tvalidation_1-error:0.037449\tvalidation_0-gini:0.754632\tvalidation_1-gini:0.760056\n",
      "[43]\tvalidation_0-error:0.036197\tvalidation_1-error:0.037449\tvalidation_0-gini:0.754096\tvalidation_1-gini:0.759466\n",
      "[44]\tvalidation_0-error:0.036197\tvalidation_1-error:0.037449\tvalidation_0-gini:0.753085\tvalidation_1-gini:0.758786\n",
      "[45]\tvalidation_0-error:0.036197\tvalidation_1-error:0.037449\tvalidation_0-gini:0.751497\tvalidation_1-gini:0.757706\n",
      "[46]\tvalidation_0-error:0.036197\tvalidation_1-error:0.037449\tvalidation_0-gini:0.751483\tvalidation_1-gini:0.757247\n",
      "[47]\tvalidation_0-error:0.036197\tvalidation_1-error:0.037449\tvalidation_0-gini:0.750431\tvalidation_1-gini:0.756645\n",
      "[48]\tvalidation_0-error:0.036197\tvalidation_1-error:0.037449\tvalidation_0-gini:0.74983\tvalidation_1-gini:0.756539\n",
      "[49]\tvalidation_0-error:0.036197\tvalidation_1-error:0.037449\tvalidation_0-gini:0.748763\tvalidation_1-gini:0.756023\n",
      "[50]\tvalidation_0-error:0.036197\tvalidation_1-error:0.037449\tvalidation_0-gini:0.747521\tvalidation_1-gini:0.755428\n",
      "[51]\tvalidation_0-error:0.036197\tvalidation_1-error:0.037449\tvalidation_0-gini:0.74624\tvalidation_1-gini:0.754427\n",
      "[52]\tvalidation_0-error:0.036197\tvalidation_1-error:0.037449\tvalidation_0-gini:0.744501\tvalidation_1-gini:0.752877\n",
      "[53]\tvalidation_0-error:0.036197\tvalidation_1-error:0.037449\tvalidation_0-gini:0.743056\tvalidation_1-gini:0.751365\n",
      "[54]\tvalidation_0-error:0.036197\tvalidation_1-error:0.037449\tvalidation_0-gini:0.741861\tvalidation_1-gini:0.750346\n",
      "[55]\tvalidation_0-error:0.036197\tvalidation_1-error:0.037449\tvalidation_0-gini:0.74022\tvalidation_1-gini:0.748502\n",
      "[56]\tvalidation_0-error:0.036197\tvalidation_1-error:0.037449\tvalidation_0-gini:0.739373\tvalidation_1-gini:0.74797\n",
      "[57]\tvalidation_0-error:0.036197\tvalidation_1-error:0.037449\tvalidation_0-gini:0.737888\tvalidation_1-gini:0.746725\n",
      "[58]\tvalidation_0-error:0.036197\tvalidation_1-error:0.037449\tvalidation_0-gini:0.737454\tvalidation_1-gini:0.746593\n",
      "[59]\tvalidation_0-error:0.036197\tvalidation_1-error:0.037449\tvalidation_0-gini:0.736849\tvalidation_1-gini:0.745951\n",
      "[60]\tvalidation_0-error:0.036197\tvalidation_1-error:0.037449\tvalidation_0-gini:0.735072\tvalidation_1-gini:0.744207\n",
      "[61]\tvalidation_0-error:0.036197\tvalidation_1-error:0.037449\tvalidation_0-gini:0.734403\tvalidation_1-gini:0.743969\n",
      "[62]\tvalidation_0-error:0.036197\tvalidation_1-error:0.037449\tvalidation_0-gini:0.733771\tvalidation_1-gini:0.743394\n",
      "[63]\tvalidation_0-error:0.036197\tvalidation_1-error:0.037449\tvalidation_0-gini:0.733177\tvalidation_1-gini:0.742751\n",
      "[64]\tvalidation_0-error:0.036197\tvalidation_1-error:0.037449\tvalidation_0-gini:0.732133\tvalidation_1-gini:0.741724\n",
      "[65]\tvalidation_0-error:0.036197\tvalidation_1-error:0.037449\tvalidation_0-gini:0.730533\tvalidation_1-gini:0.740642\n",
      "[66]\tvalidation_0-error:0.036197\tvalidation_1-error:0.037449\tvalidation_0-gini:0.729811\tvalidation_1-gini:0.740049\n",
      "[67]\tvalidation_0-error:0.036197\tvalidation_1-error:0.037449\tvalidation_0-gini:0.729236\tvalidation_1-gini:0.739765\n",
      "[68]\tvalidation_0-error:0.036197\tvalidation_1-error:0.037449\tvalidation_0-gini:0.728813\tvalidation_1-gini:0.739242\n",
      "[69]\tvalidation_0-error:0.036197\tvalidation_1-error:0.037449\tvalidation_0-gini:0.728052\tvalidation_1-gini:0.73877\n",
      "[70]\tvalidation_0-error:0.036197\tvalidation_1-error:0.037449\tvalidation_0-gini:0.727503\tvalidation_1-gini:0.738317\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[71]\tvalidation_0-error:0.036197\tvalidation_1-error:0.037449\tvalidation_0-gini:0.726664\tvalidation_1-gini:0.737385\n",
      "[72]\tvalidation_0-error:0.036197\tvalidation_1-error:0.037449\tvalidation_0-gini:0.725593\tvalidation_1-gini:0.736604\n",
      "[73]\tvalidation_0-error:0.036197\tvalidation_1-error:0.037449\tvalidation_0-gini:0.724843\tvalidation_1-gini:0.73609\n",
      "[74]\tvalidation_0-error:0.036197\tvalidation_1-error:0.037449\tvalidation_0-gini:0.724296\tvalidation_1-gini:0.736099\n",
      "[75]\tvalidation_0-error:0.036197\tvalidation_1-error:0.037449\tvalidation_0-gini:0.723468\tvalidation_1-gini:0.73552\n",
      "[76]\tvalidation_0-error:0.036197\tvalidation_1-error:0.037449\tvalidation_0-gini:0.723172\tvalidation_1-gini:0.735327\n",
      "[77]\tvalidation_0-error:0.036197\tvalidation_1-error:0.037449\tvalidation_0-gini:0.722626\tvalidation_1-gini:0.734761\n",
      "[78]\tvalidation_0-error:0.036197\tvalidation_1-error:0.037449\tvalidation_0-gini:0.722406\tvalidation_1-gini:0.734541\n",
      "[79]\tvalidation_0-error:0.036197\tvalidation_1-error:0.037449\tvalidation_0-gini:0.721929\tvalidation_1-gini:0.734041\n",
      "[80]\tvalidation_0-error:0.036197\tvalidation_1-error:0.037449\tvalidation_0-gini:0.7209\tvalidation_1-gini:0.73353\n",
      "[81]\tvalidation_0-error:0.036197\tvalidation_1-error:0.037449\tvalidation_0-gini:0.720681\tvalidation_1-gini:0.733501\n",
      "[82]\tvalidation_0-error:0.036197\tvalidation_1-error:0.037449\tvalidation_0-gini:0.720409\tvalidation_1-gini:0.733142\n",
      "[83]\tvalidation_0-error:0.036197\tvalidation_1-error:0.037449\tvalidation_0-gini:0.719752\tvalidation_1-gini:0.732267\n",
      "[84]\tvalidation_0-error:0.036197\tvalidation_1-error:0.037449\tvalidation_0-gini:0.719498\tvalidation_1-gini:0.731967\n",
      "[85]\tvalidation_0-error:0.036197\tvalidation_1-error:0.037449\tvalidation_0-gini:0.719156\tvalidation_1-gini:0.73161\n",
      "[86]\tvalidation_0-error:0.036197\tvalidation_1-error:0.037449\tvalidation_0-gini:0.718337\tvalidation_1-gini:0.731116\n",
      "[87]\tvalidation_0-error:0.036197\tvalidation_1-error:0.037449\tvalidation_0-gini:0.718034\tvalidation_1-gini:0.730797\n",
      "[88]\tvalidation_0-error:0.036197\tvalidation_1-error:0.037449\tvalidation_0-gini:0.717629\tvalidation_1-gini:0.730296\n",
      "[89]\tvalidation_0-error:0.036197\tvalidation_1-error:0.037449\tvalidation_0-gini:0.717334\tvalidation_1-gini:0.729983\n",
      "[90]\tvalidation_0-error:0.036197\tvalidation_1-error:0.037449\tvalidation_0-gini:0.716638\tvalidation_1-gini:0.729589\n",
      "[91]\tvalidation_0-error:0.036197\tvalidation_1-error:0.037449\tvalidation_0-gini:0.716596\tvalidation_1-gini:0.729556\n",
      "[92]\tvalidation_0-error:0.036197\tvalidation_1-error:0.037449\tvalidation_0-gini:0.716387\tvalidation_1-gini:0.729524\n",
      "[93]\tvalidation_0-error:0.036197\tvalidation_1-error:0.037449\tvalidation_0-gini:0.715771\tvalidation_1-gini:0.729179\n",
      "[94]\tvalidation_0-error:0.036197\tvalidation_1-error:0.037449\tvalidation_0-gini:0.71522\tvalidation_1-gini:0.728937\n",
      "[95]\tvalidation_0-error:0.036197\tvalidation_1-error:0.037449\tvalidation_0-gini:0.714946\tvalidation_1-gini:0.728888\n",
      "[96]\tvalidation_0-error:0.036197\tvalidation_1-error:0.037449\tvalidation_0-gini:0.714934\tvalidation_1-gini:0.728807\n",
      "[97]\tvalidation_0-error:0.036197\tvalidation_1-error:0.037449\tvalidation_0-gini:0.714275\tvalidation_1-gini:0.728196\n",
      "[98]\tvalidation_0-error:0.036197\tvalidation_1-error:0.037449\tvalidation_0-gini:0.713919\tvalidation_1-gini:0.727792\n",
      "[99]\tvalidation_0-error:0.036197\tvalidation_1-error:0.037449\tvalidation_0-gini:0.713743\tvalidation_1-gini:0.727878\n",
      "[100]\tvalidation_0-error:0.036197\tvalidation_1-error:0.037449\tvalidation_0-gini:0.713649\tvalidation_1-gini:0.727782\n",
      "[101]\tvalidation_0-error:0.036197\tvalidation_1-error:0.037449\tvalidation_0-gini:0.713539\tvalidation_1-gini:0.727724\n",
      "[102]\tvalidation_0-error:0.036197\tvalidation_1-error:0.037449\tvalidation_0-gini:0.713101\tvalidation_1-gini:0.727444\n",
      "[103]\tvalidation_0-error:0.036197\tvalidation_1-error:0.037449\tvalidation_0-gini:0.712715\tvalidation_1-gini:0.727071\n",
      "[104]\tvalidation_0-error:0.036197\tvalidation_1-error:0.037449\tvalidation_0-gini:0.71242\tvalidation_1-gini:0.726667\n",
      "[105]\tvalidation_0-error:0.036197\tvalidation_1-error:0.037449\tvalidation_0-gini:0.71242\tvalidation_1-gini:0.726632\n",
      "[106]\tvalidation_0-error:0.036197\tvalidation_1-error:0.037449\tvalidation_0-gini:0.712048\tvalidation_1-gini:0.726349\n",
      "[107]\tvalidation_0-error:0.036197\tvalidation_1-error:0.037449\tvalidation_0-gini:0.71188\tvalidation_1-gini:0.72607\n",
      "[108]\tvalidation_0-error:0.036197\tvalidation_1-error:0.037449\tvalidation_0-gini:0.711608\tvalidation_1-gini:0.725869\n",
      "[109]\tvalidation_0-error:0.036197\tvalidation_1-error:0.037449\tvalidation_0-gini:0.711493\tvalidation_1-gini:0.725804\n",
      "[110]\tvalidation_0-error:0.036197\tvalidation_1-error:0.037449\tvalidation_0-gini:0.711208\tvalidation_1-gini:0.725556\n",
      "[111]\tvalidation_0-error:0.036197\tvalidation_1-error:0.037449\tvalidation_0-gini:0.711008\tvalidation_1-gini:0.725472\n",
      "[112]\tvalidation_0-error:0.036197\tvalidation_1-error:0.037449\tvalidation_0-gini:0.710746\tvalidation_1-gini:0.725149\n",
      "[113]\tvalidation_0-error:0.036197\tvalidation_1-error:0.037449\tvalidation_0-gini:0.710317\tvalidation_1-gini:0.724783\n",
      "[114]\tvalidation_0-error:0.036197\tvalidation_1-error:0.037449\tvalidation_0-gini:0.710035\tvalidation_1-gini:0.724451\n",
      "[115]\tvalidation_0-error:0.036197\tvalidation_1-error:0.037449\tvalidation_0-gini:0.709886\tvalidation_1-gini:0.724412\n",
      "[116]\tvalidation_0-error:0.036197\tvalidation_1-error:0.037449\tvalidation_0-gini:0.709797\tvalidation_1-gini:0.724405\n",
      "[117]\tvalidation_0-error:0.036197\tvalidation_1-error:0.037449\tvalidation_0-gini:0.709631\tvalidation_1-gini:0.724165\n",
      "[118]\tvalidation_0-error:0.036197\tvalidation_1-error:0.037449\tvalidation_0-gini:0.709414\tvalidation_1-gini:0.723953\n",
      "[119]\tvalidation_0-error:0.036197\tvalidation_1-error:0.037449\tvalidation_0-gini:0.709144\tvalidation_1-gini:0.723601\n",
      "[120]\tvalidation_0-error:0.036197\tvalidation_1-error:0.037449\tvalidation_0-gini:0.709025\tvalidation_1-gini:0.72337\n",
      "[121]\tvalidation_0-error:0.036197\tvalidation_1-error:0.037449\tvalidation_0-gini:0.708705\tvalidation_1-gini:0.723238\n",
      "[122]\tvalidation_0-error:0.036197\tvalidation_1-error:0.037449\tvalidation_0-gini:0.708653\tvalidation_1-gini:0.723138\n",
      "[123]\tvalidation_0-error:0.036197\tvalidation_1-error:0.037449\tvalidation_0-gini:0.708653\tvalidation_1-gini:0.723138\n",
      "[124]\tvalidation_0-error:0.036197\tvalidation_1-error:0.037449\tvalidation_0-gini:0.708562\tvalidation_1-gini:0.723101\n",
      "[125]\tvalidation_0-error:0.036197\tvalidation_1-error:0.037449\tvalidation_0-gini:0.708432\tvalidation_1-gini:0.722939\n",
      "[126]\tvalidation_0-error:0.036197\tvalidation_1-error:0.037449\tvalidation_0-gini:0.70841\tvalidation_1-gini:0.722887\n",
      "[127]\tvalidation_0-error:0.036197\tvalidation_1-error:0.037449\tvalidation_0-gini:0.708324\tvalidation_1-gini:0.722854\n",
      "[128]\tvalidation_0-error:0.036197\tvalidation_1-error:0.037449\tvalidation_0-gini:0.708189\tvalidation_1-gini:0.722629\n",
      "[129]\tvalidation_0-error:0.036197\tvalidation_1-error:0.037449\tvalidation_0-gini:0.708132\tvalidation_1-gini:0.722586\n",
      "[130]\tvalidation_0-error:0.036197\tvalidation_1-error:0.037449\tvalidation_0-gini:0.708056\tvalidation_1-gini:0.722581\n",
      "[131]\tvalidation_0-error:0.036197\tvalidation_1-error:0.037449\tvalidation_0-gini:0.707936\tvalidation_1-gini:0.72243\n",
      "[132]\tvalidation_0-error:0.036197\tvalidation_1-error:0.037449\tvalidation_0-gini:0.707731\tvalidation_1-gini:0.72238\n",
      "[133]\tvalidation_0-error:0.036197\tvalidation_1-error:0.037449\tvalidation_0-gini:0.707685\tvalidation_1-gini:0.722407\n",
      "[134]\tvalidation_0-error:0.036197\tvalidation_1-error:0.037449\tvalidation_0-gini:0.707566\tvalidation_1-gini:0.722235\n",
      "[135]\tvalidation_0-error:0.036197\tvalidation_1-error:0.037449\tvalidation_0-gini:0.707435\tvalidation_1-gini:0.722239\n",
      "[136]\tvalidation_0-error:0.036197\tvalidation_1-error:0.037449\tvalidation_0-gini:0.707222\tvalidation_1-gini:0.722164\n",
      "[137]\tvalidation_0-error:0.036197\tvalidation_1-error:0.037449\tvalidation_0-gini:0.706964\tvalidation_1-gini:0.721995\n",
      "[138]\tvalidation_0-error:0.036197\tvalidation_1-error:0.037449\tvalidation_0-gini:0.706799\tvalidation_1-gini:0.721732\n",
      "[139]\tvalidation_0-error:0.036197\tvalidation_1-error:0.037449\tvalidation_0-gini:0.706732\tvalidation_1-gini:0.721823\n",
      "[140]\tvalidation_0-error:0.036197\tvalidation_1-error:0.037449\tvalidation_0-gini:0.706559\tvalidation_1-gini:0.721678\n",
      "[141]\tvalidation_0-error:0.036197\tvalidation_1-error:0.037449\tvalidation_0-gini:0.706524\tvalidation_1-gini:0.721643\n",
      "[142]\tvalidation_0-error:0.036197\tvalidation_1-error:0.037449\tvalidation_0-gini:0.706342\tvalidation_1-gini:0.721542\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[143]\tvalidation_0-error:0.036197\tvalidation_1-error:0.037449\tvalidation_0-gini:0.705944\tvalidation_1-gini:0.721121\n",
      "[144]\tvalidation_0-error:0.036197\tvalidation_1-error:0.037449\tvalidation_0-gini:0.705679\tvalidation_1-gini:0.720957\n",
      "[145]\tvalidation_0-error:0.036197\tvalidation_1-error:0.037449\tvalidation_0-gini:0.705679\tvalidation_1-gini:0.720957\n",
      "[146]\tvalidation_0-error:0.036197\tvalidation_1-error:0.037449\tvalidation_0-gini:0.705679\tvalidation_1-gini:0.720957\n",
      "[147]\tvalidation_0-error:0.036197\tvalidation_1-error:0.037449\tvalidation_0-gini:0.705679\tvalidation_1-gini:0.720957\n",
      "[148]\tvalidation_0-error:0.036197\tvalidation_1-error:0.037449\tvalidation_0-gini:0.705565\tvalidation_1-gini:0.720851\n",
      "[149]\tvalidation_0-error:0.036197\tvalidation_1-error:0.037449\tvalidation_0-gini:0.705565\tvalidation_1-gini:0.720851\n",
      "[150]\tvalidation_0-error:0.036197\tvalidation_1-error:0.037449\tvalidation_0-gini:0.705565\tvalidation_1-gini:0.720851\n",
      "[151]\tvalidation_0-error:0.036197\tvalidation_1-error:0.037449\tvalidation_0-gini:0.705565\tvalidation_1-gini:0.720851\n",
      "[152]\tvalidation_0-error:0.036197\tvalidation_1-error:0.037449\tvalidation_0-gini:0.705565\tvalidation_1-gini:0.720851\n",
      "[153]\tvalidation_0-error:0.036197\tvalidation_1-error:0.037449\tvalidation_0-gini:0.705565\tvalidation_1-gini:0.720851\n",
      "[154]\tvalidation_0-error:0.036197\tvalidation_1-error:0.037449\tvalidation_0-gini:0.705565\tvalidation_1-gini:0.720851\n",
      "[155]\tvalidation_0-error:0.036197\tvalidation_1-error:0.037449\tvalidation_0-gini:0.70554\tvalidation_1-gini:0.720891\n",
      "[156]\tvalidation_0-error:0.036197\tvalidation_1-error:0.037449\tvalidation_0-gini:0.705487\tvalidation_1-gini:0.720866\n",
      "[157]\tvalidation_0-error:0.036197\tvalidation_1-error:0.037449\tvalidation_0-gini:0.705354\tvalidation_1-gini:0.720886\n",
      "[158]\tvalidation_0-error:0.036197\tvalidation_1-error:0.037449\tvalidation_0-gini:0.705354\tvalidation_1-gini:0.720886\n",
      "[159]\tvalidation_0-error:0.036197\tvalidation_1-error:0.037449\tvalidation_0-gini:0.705354\tvalidation_1-gini:0.720886\n",
      "[160]\tvalidation_0-error:0.036197\tvalidation_1-error:0.037449\tvalidation_0-gini:0.705218\tvalidation_1-gini:0.720822\n",
      "[161]\tvalidation_0-error:0.036197\tvalidation_1-error:0.037449\tvalidation_0-gini:0.705106\tvalidation_1-gini:0.720736\n",
      "[162]\tvalidation_0-error:0.036197\tvalidation_1-error:0.037449\tvalidation_0-gini:0.705106\tvalidation_1-gini:0.720736\n",
      "[163]\tvalidation_0-error:0.036197\tvalidation_1-error:0.037449\tvalidation_0-gini:0.705106\tvalidation_1-gini:0.720736\n",
      "[164]\tvalidation_0-error:0.036197\tvalidation_1-error:0.037449\tvalidation_0-gini:0.705106\tvalidation_1-gini:0.720736\n",
      "[165]\tvalidation_0-error:0.036197\tvalidation_1-error:0.037449\tvalidation_0-gini:0.705106\tvalidation_1-gini:0.720736\n",
      "[166]\tvalidation_0-error:0.036197\tvalidation_1-error:0.037449\tvalidation_0-gini:0.705106\tvalidation_1-gini:0.720736\n",
      "[167]\tvalidation_0-error:0.036197\tvalidation_1-error:0.037449\tvalidation_0-gini:0.705106\tvalidation_1-gini:0.720736\n",
      "[168]\tvalidation_0-error:0.036197\tvalidation_1-error:0.037449\tvalidation_0-gini:0.705106\tvalidation_1-gini:0.720736\n",
      "[169]\tvalidation_0-error:0.036197\tvalidation_1-error:0.037449\tvalidation_0-gini:0.705046\tvalidation_1-gini:0.720735\n",
      "[170]\tvalidation_0-error:0.036197\tvalidation_1-error:0.037449\tvalidation_0-gini:0.705013\tvalidation_1-gini:0.72073\n",
      "[171]\tvalidation_0-error:0.036197\tvalidation_1-error:0.037449\tvalidation_0-gini:0.705013\tvalidation_1-gini:0.72073\n",
      "[172]\tvalidation_0-error:0.036197\tvalidation_1-error:0.037449\tvalidation_0-gini:0.704811\tvalidation_1-gini:0.720706\n",
      "[173]\tvalidation_0-error:0.036197\tvalidation_1-error:0.037449\tvalidation_0-gini:0.704646\tvalidation_1-gini:0.720498\n",
      "[174]\tvalidation_0-error:0.036197\tvalidation_1-error:0.037449\tvalidation_0-gini:0.704646\tvalidation_1-gini:0.720498\n",
      "[175]\tvalidation_0-error:0.036197\tvalidation_1-error:0.037449\tvalidation_0-gini:0.704511\tvalidation_1-gini:0.720506\n",
      "[176]\tvalidation_0-error:0.036197\tvalidation_1-error:0.037449\tvalidation_0-gini:0.704511\tvalidation_1-gini:0.720506\n",
      "[177]\tvalidation_0-error:0.036197\tvalidation_1-error:0.037449\tvalidation_0-gini:0.704511\tvalidation_1-gini:0.720506\n",
      "[178]\tvalidation_0-error:0.036197\tvalidation_1-error:0.037449\tvalidation_0-gini:0.704414\tvalidation_1-gini:0.720479\n",
      "[179]\tvalidation_0-error:0.036197\tvalidation_1-error:0.037449\tvalidation_0-gini:0.704414\tvalidation_1-gini:0.720479\n",
      "[180]\tvalidation_0-error:0.036197\tvalidation_1-error:0.037449\tvalidation_0-gini:0.704414\tvalidation_1-gini:0.720479\n",
      "[181]\tvalidation_0-error:0.036197\tvalidation_1-error:0.037449\tvalidation_0-gini:0.704414\tvalidation_1-gini:0.720479\n",
      "[182]\tvalidation_0-error:0.036197\tvalidation_1-error:0.037449\tvalidation_0-gini:0.704374\tvalidation_1-gini:0.720403\n",
      "[183]\tvalidation_0-error:0.036197\tvalidation_1-error:0.037449\tvalidation_0-gini:0.704374\tvalidation_1-gini:0.720403\n",
      "[184]\tvalidation_0-error:0.036197\tvalidation_1-error:0.037449\tvalidation_0-gini:0.704374\tvalidation_1-gini:0.720403\n",
      "[185]\tvalidation_0-error:0.036197\tvalidation_1-error:0.037449\tvalidation_0-gini:0.704299\tvalidation_1-gini:0.72024\n",
      "[186]\tvalidation_0-error:0.036197\tvalidation_1-error:0.037449\tvalidation_0-gini:0.704299\tvalidation_1-gini:0.72024\n",
      "[187]\tvalidation_0-error:0.036197\tvalidation_1-error:0.037449\tvalidation_0-gini:0.704299\tvalidation_1-gini:0.72024\n",
      "[188]\tvalidation_0-error:0.036197\tvalidation_1-error:0.037449\tvalidation_0-gini:0.704299\tvalidation_1-gini:0.72024\n",
      "[189]\tvalidation_0-error:0.036197\tvalidation_1-error:0.037449\tvalidation_0-gini:0.704299\tvalidation_1-gini:0.72024\n",
      "[190]\tvalidation_0-error:0.036197\tvalidation_1-error:0.037449\tvalidation_0-gini:0.704299\tvalidation_1-gini:0.72024\n",
      "[191]\tvalidation_0-error:0.036197\tvalidation_1-error:0.037449\tvalidation_0-gini:0.704299\tvalidation_1-gini:0.72024\n",
      "[192]\tvalidation_0-error:0.036197\tvalidation_1-error:0.037449\tvalidation_0-gini:0.704299\tvalidation_1-gini:0.72024\n",
      "[193]\tvalidation_0-error:0.036197\tvalidation_1-error:0.037449\tvalidation_0-gini:0.704182\tvalidation_1-gini:0.720197\n",
      "[194]\tvalidation_0-error:0.036197\tvalidation_1-error:0.037449\tvalidation_0-gini:0.704182\tvalidation_1-gini:0.720197\n",
      "[195]\tvalidation_0-error:0.036197\tvalidation_1-error:0.037449\tvalidation_0-gini:0.704182\tvalidation_1-gini:0.720197\n",
      "[196]\tvalidation_0-error:0.036197\tvalidation_1-error:0.037449\tvalidation_0-gini:0.704091\tvalidation_1-gini:0.720064\n",
      "[197]\tvalidation_0-error:0.036197\tvalidation_1-error:0.037449\tvalidation_0-gini:0.70404\tvalidation_1-gini:0.720029\n",
      "[198]\tvalidation_0-error:0.036197\tvalidation_1-error:0.037449\tvalidation_0-gini:0.703873\tvalidation_1-gini:0.719996\n",
      "[199]\tvalidation_0-error:0.036197\tvalidation_1-error:0.037449\tvalidation_0-gini:0.703873\tvalidation_1-gini:0.719996\n",
      "[200]\tvalidation_0-error:0.036197\tvalidation_1-error:0.037449\tvalidation_0-gini:0.703873\tvalidation_1-gini:0.719996\n",
      "[201]\tvalidation_0-error:0.036197\tvalidation_1-error:0.037449\tvalidation_0-gini:0.703873\tvalidation_1-gini:0.719996\n",
      "[202]\tvalidation_0-error:0.036197\tvalidation_1-error:0.037449\tvalidation_0-gini:0.703873\tvalidation_1-gini:0.719996\n",
      "[203]\tvalidation_0-error:0.036197\tvalidation_1-error:0.037449\tvalidation_0-gini:0.703749\tvalidation_1-gini:0.719981\n",
      "[204]\tvalidation_0-error:0.036197\tvalidation_1-error:0.037449\tvalidation_0-gini:0.703617\tvalidation_1-gini:0.719911\n",
      "[205]\tvalidation_0-error:0.036197\tvalidation_1-error:0.037449\tvalidation_0-gini:0.703617\tvalidation_1-gini:0.719911\n",
      "[206]\tvalidation_0-error:0.036197\tvalidation_1-error:0.037449\tvalidation_0-gini:0.703617\tvalidation_1-gini:0.719911\n",
      "[207]\tvalidation_0-error:0.036197\tvalidation_1-error:0.037449\tvalidation_0-gini:0.703617\tvalidation_1-gini:0.719911\n",
      "[208]\tvalidation_0-error:0.036197\tvalidation_1-error:0.037449\tvalidation_0-gini:0.703617\tvalidation_1-gini:0.719911\n",
      "[209]\tvalidation_0-error:0.036197\tvalidation_1-error:0.037449\tvalidation_0-gini:0.703617\tvalidation_1-gini:0.719911\n",
      "[210]\tvalidation_0-error:0.036197\tvalidation_1-error:0.037449\tvalidation_0-gini:0.703617\tvalidation_1-gini:0.719911\n",
      "[211]\tvalidation_0-error:0.036197\tvalidation_1-error:0.037449\tvalidation_0-gini:0.703617\tvalidation_1-gini:0.719911\n",
      "[212]\tvalidation_0-error:0.036197\tvalidation_1-error:0.037449\tvalidation_0-gini:0.703617\tvalidation_1-gini:0.719911\n",
      "[213]\tvalidation_0-error:0.036197\tvalidation_1-error:0.037449\tvalidation_0-gini:0.703476\tvalidation_1-gini:0.719874\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[214]\tvalidation_0-error:0.036197\tvalidation_1-error:0.037449\tvalidation_0-gini:0.703476\tvalidation_1-gini:0.719874\n",
      "[215]\tvalidation_0-error:0.036197\tvalidation_1-error:0.037449\tvalidation_0-gini:0.703476\tvalidation_1-gini:0.719874\n",
      "[216]\tvalidation_0-error:0.036197\tvalidation_1-error:0.037449\tvalidation_0-gini:0.703423\tvalidation_1-gini:0.719812\n",
      "[217]\tvalidation_0-error:0.036197\tvalidation_1-error:0.037449\tvalidation_0-gini:0.703423\tvalidation_1-gini:0.719812\n",
      "[218]\tvalidation_0-error:0.036197\tvalidation_1-error:0.037449\tvalidation_0-gini:0.703423\tvalidation_1-gini:0.719812\n",
      "[219]\tvalidation_0-error:0.036197\tvalidation_1-error:0.037449\tvalidation_0-gini:0.703321\tvalidation_1-gini:0.71983\n",
      "[220]\tvalidation_0-error:0.036197\tvalidation_1-error:0.037449\tvalidation_0-gini:0.703321\tvalidation_1-gini:0.71983\n",
      "[221]\tvalidation_0-error:0.036197\tvalidation_1-error:0.037449\tvalidation_0-gini:0.703238\tvalidation_1-gini:0.719859\n",
      "[222]\tvalidation_0-error:0.036197\tvalidation_1-error:0.037449\tvalidation_0-gini:0.703238\tvalidation_1-gini:0.719859\n",
      "[223]\tvalidation_0-error:0.036197\tvalidation_1-error:0.037449\tvalidation_0-gini:0.703238\tvalidation_1-gini:0.719859\n",
      "[224]\tvalidation_0-error:0.036197\tvalidation_1-error:0.037449\tvalidation_0-gini:0.703238\tvalidation_1-gini:0.719859\n",
      "[225]\tvalidation_0-error:0.036197\tvalidation_1-error:0.037449\tvalidation_0-gini:0.703238\tvalidation_1-gini:0.719859\n",
      "[226]\tvalidation_0-error:0.036197\tvalidation_1-error:0.037449\tvalidation_0-gini:0.703238\tvalidation_1-gini:0.719859\n",
      "[227]\tvalidation_0-error:0.036197\tvalidation_1-error:0.037449\tvalidation_0-gini:0.703238\tvalidation_1-gini:0.719859\n",
      "[228]\tvalidation_0-error:0.036197\tvalidation_1-error:0.037449\tvalidation_0-gini:0.703238\tvalidation_1-gini:0.719859\n",
      "[229]\tvalidation_0-error:0.036197\tvalidation_1-error:0.037449\tvalidation_0-gini:0.703122\tvalidation_1-gini:0.719928\n",
      "[230]\tvalidation_0-error:0.036197\tvalidation_1-error:0.037449\tvalidation_0-gini:0.703122\tvalidation_1-gini:0.719928\n",
      "[231]\tvalidation_0-error:0.036197\tvalidation_1-error:0.037449\tvalidation_0-gini:0.703122\tvalidation_1-gini:0.719928\n",
      "[232]\tvalidation_0-error:0.036197\tvalidation_1-error:0.037449\tvalidation_0-gini:0.703122\tvalidation_1-gini:0.719928\n",
      "[233]\tvalidation_0-error:0.036197\tvalidation_1-error:0.037449\tvalidation_0-gini:0.703122\tvalidation_1-gini:0.719928\n",
      "[234]\tvalidation_0-error:0.036197\tvalidation_1-error:0.037449\tvalidation_0-gini:0.703122\tvalidation_1-gini:0.719928\n",
      "[235]\tvalidation_0-error:0.036197\tvalidation_1-error:0.037449\tvalidation_0-gini:0.703122\tvalidation_1-gini:0.719928\n",
      "[236]\tvalidation_0-error:0.036197\tvalidation_1-error:0.037449\tvalidation_0-gini:0.703122\tvalidation_1-gini:0.719928\n",
      "[237]\tvalidation_0-error:0.036197\tvalidation_1-error:0.037449\tvalidation_0-gini:0.703122\tvalidation_1-gini:0.719928\n",
      "[238]\tvalidation_0-error:0.036197\tvalidation_1-error:0.037449\tvalidation_0-gini:0.702944\tvalidation_1-gini:0.719767\n",
      "[239]\tvalidation_0-error:0.036197\tvalidation_1-error:0.037449\tvalidation_0-gini:0.702862\tvalidation_1-gini:0.719679\n",
      "[240]\tvalidation_0-error:0.036197\tvalidation_1-error:0.037449\tvalidation_0-gini:0.702797\tvalidation_1-gini:0.719598\n",
      "[241]\tvalidation_0-error:0.036197\tvalidation_1-error:0.037449\tvalidation_0-gini:0.702797\tvalidation_1-gini:0.719598\n",
      "[242]\tvalidation_0-error:0.036197\tvalidation_1-error:0.037449\tvalidation_0-gini:0.702797\tvalidation_1-gini:0.719598\n",
      "[243]\tvalidation_0-error:0.036197\tvalidation_1-error:0.037449\tvalidation_0-gini:0.702797\tvalidation_1-gini:0.719598\n",
      "[244]\tvalidation_0-error:0.036197\tvalidation_1-error:0.037449\tvalidation_0-gini:0.702797\tvalidation_1-gini:0.719598\n",
      "[245]\tvalidation_0-error:0.036197\tvalidation_1-error:0.037449\tvalidation_0-gini:0.702797\tvalidation_1-gini:0.719598\n",
      "[246]\tvalidation_0-error:0.036197\tvalidation_1-error:0.037449\tvalidation_0-gini:0.702797\tvalidation_1-gini:0.719598\n",
      "[247]\tvalidation_0-error:0.036197\tvalidation_1-error:0.037449\tvalidation_0-gini:0.702797\tvalidation_1-gini:0.719598\n",
      "[248]\tvalidation_0-error:0.036197\tvalidation_1-error:0.037449\tvalidation_0-gini:0.702755\tvalidation_1-gini:0.719588\n",
      "[249]\tvalidation_0-error:0.036197\tvalidation_1-error:0.037449\tvalidation_0-gini:0.702545\tvalidation_1-gini:0.719451\n",
      "[250]\tvalidation_0-error:0.036197\tvalidation_1-error:0.037449\tvalidation_0-gini:0.702545\tvalidation_1-gini:0.719451\n",
      "[251]\tvalidation_0-error:0.036197\tvalidation_1-error:0.037449\tvalidation_0-gini:0.702408\tvalidation_1-gini:0.719459\n",
      "[252]\tvalidation_0-error:0.036197\tvalidation_1-error:0.037449\tvalidation_0-gini:0.702317\tvalidation_1-gini:0.719459\n",
      "[253]\tvalidation_0-error:0.036197\tvalidation_1-error:0.037449\tvalidation_0-gini:0.702317\tvalidation_1-gini:0.719459\n",
      "[254]\tvalidation_0-error:0.036197\tvalidation_1-error:0.037449\tvalidation_0-gini:0.702138\tvalidation_1-gini:0.719478\n",
      "[255]\tvalidation_0-error:0.036197\tvalidation_1-error:0.037449\tvalidation_0-gini:0.702108\tvalidation_1-gini:0.719384\n",
      "[256]\tvalidation_0-error:0.036197\tvalidation_1-error:0.037449\tvalidation_0-gini:0.702108\tvalidation_1-gini:0.719384\n",
      "[257]\tvalidation_0-error:0.036197\tvalidation_1-error:0.037449\tvalidation_0-gini:0.702108\tvalidation_1-gini:0.719384\n",
      "[258]\tvalidation_0-error:0.036197\tvalidation_1-error:0.037449\tvalidation_0-gini:0.702108\tvalidation_1-gini:0.719384\n",
      "[259]\tvalidation_0-error:0.036197\tvalidation_1-error:0.037449\tvalidation_0-gini:0.702108\tvalidation_1-gini:0.719384\n",
      "[260]\tvalidation_0-error:0.036197\tvalidation_1-error:0.037449\tvalidation_0-gini:0.702031\tvalidation_1-gini:0.719315\n",
      "[261]\tvalidation_0-error:0.036197\tvalidation_1-error:0.037449\tvalidation_0-gini:0.702031\tvalidation_1-gini:0.719315\n",
      "[262]\tvalidation_0-error:0.036197\tvalidation_1-error:0.037449\tvalidation_0-gini:0.702031\tvalidation_1-gini:0.719315\n",
      "[263]\tvalidation_0-error:0.036197\tvalidation_1-error:0.037449\tvalidation_0-gini:0.702031\tvalidation_1-gini:0.719315\n",
      "[264]\tvalidation_0-error:0.036197\tvalidation_1-error:0.037449\tvalidation_0-gini:0.702031\tvalidation_1-gini:0.719315\n",
      "[265]\tvalidation_0-error:0.036197\tvalidation_1-error:0.037449\tvalidation_0-gini:0.702031\tvalidation_1-gini:0.719315\n",
      "[266]\tvalidation_0-error:0.036197\tvalidation_1-error:0.037449\tvalidation_0-gini:0.702031\tvalidation_1-gini:0.719315\n",
      "[267]\tvalidation_0-error:0.036197\tvalidation_1-error:0.037449\tvalidation_0-gini:0.702031\tvalidation_1-gini:0.719315\n",
      "[268]\tvalidation_0-error:0.036197\tvalidation_1-error:0.037449\tvalidation_0-gini:0.702031\tvalidation_1-gini:0.719315\n",
      "[269]\tvalidation_0-error:0.036197\tvalidation_1-error:0.037449\tvalidation_0-gini:0.702031\tvalidation_1-gini:0.719315\n",
      "[270]\tvalidation_0-error:0.036197\tvalidation_1-error:0.037449\tvalidation_0-gini:0.702031\tvalidation_1-gini:0.719315\n",
      "[271]\tvalidation_0-error:0.036197\tvalidation_1-error:0.037449\tvalidation_0-gini:0.702031\tvalidation_1-gini:0.719315\n",
      "[272]\tvalidation_0-error:0.036197\tvalidation_1-error:0.037449\tvalidation_0-gini:0.701917\tvalidation_1-gini:0.719316\n",
      "[273]\tvalidation_0-error:0.036197\tvalidation_1-error:0.037449\tvalidation_0-gini:0.701917\tvalidation_1-gini:0.719316\n",
      "[274]\tvalidation_0-error:0.036197\tvalidation_1-error:0.037449\tvalidation_0-gini:0.701917\tvalidation_1-gini:0.719316\n",
      "[275]\tvalidation_0-error:0.036197\tvalidation_1-error:0.037449\tvalidation_0-gini:0.701917\tvalidation_1-gini:0.719316\n",
      "[276]\tvalidation_0-error:0.036197\tvalidation_1-error:0.037449\tvalidation_0-gini:0.701917\tvalidation_1-gini:0.719316\n",
      "[277]\tvalidation_0-error:0.036197\tvalidation_1-error:0.037449\tvalidation_0-gini:0.701917\tvalidation_1-gini:0.719316\n",
      "[278]\tvalidation_0-error:0.036197\tvalidation_1-error:0.037449\tvalidation_0-gini:0.701917\tvalidation_1-gini:0.719316\n",
      "[279]\tvalidation_0-error:0.036197\tvalidation_1-error:0.037449\tvalidation_0-gini:0.701917\tvalidation_1-gini:0.719316\n",
      "[280]\tvalidation_0-error:0.036197\tvalidation_1-error:0.037449\tvalidation_0-gini:0.701917\tvalidation_1-gini:0.719316\n",
      "[281]\tvalidation_0-error:0.036197\tvalidation_1-error:0.037449\tvalidation_0-gini:0.701917\tvalidation_1-gini:0.719316\n",
      "[282]\tvalidation_0-error:0.036197\tvalidation_1-error:0.037449\tvalidation_0-gini:0.701917\tvalidation_1-gini:0.719316\n",
      "[283]\tvalidation_0-error:0.036197\tvalidation_1-error:0.037449\tvalidation_0-gini:0.701917\tvalidation_1-gini:0.719316\n",
      "[284]\tvalidation_0-error:0.036197\tvalidation_1-error:0.037449\tvalidation_0-gini:0.701917\tvalidation_1-gini:0.719316\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[285]\tvalidation_0-error:0.036197\tvalidation_1-error:0.037449\tvalidation_0-gini:0.701917\tvalidation_1-gini:0.719316\n",
      "[286]\tvalidation_0-error:0.036197\tvalidation_1-error:0.037449\tvalidation_0-gini:0.701847\tvalidation_1-gini:0.719183\n",
      "[287]\tvalidation_0-error:0.036197\tvalidation_1-error:0.037449\tvalidation_0-gini:0.701847\tvalidation_1-gini:0.719183\n",
      "[288]\tvalidation_0-error:0.036197\tvalidation_1-error:0.037449\tvalidation_0-gini:0.701768\tvalidation_1-gini:0.719149\n",
      "[289]\tvalidation_0-error:0.036197\tvalidation_1-error:0.037449\tvalidation_0-gini:0.701768\tvalidation_1-gini:0.719149\n",
      "[290]\tvalidation_0-error:0.036197\tvalidation_1-error:0.037449\tvalidation_0-gini:0.701768\tvalidation_1-gini:0.719149\n",
      "[291]\tvalidation_0-error:0.036197\tvalidation_1-error:0.037449\tvalidation_0-gini:0.701768\tvalidation_1-gini:0.719149\n",
      "[292]\tvalidation_0-error:0.036197\tvalidation_1-error:0.037449\tvalidation_0-gini:0.701768\tvalidation_1-gini:0.719149\n",
      "[293]\tvalidation_0-error:0.036197\tvalidation_1-error:0.037449\tvalidation_0-gini:0.701768\tvalidation_1-gini:0.719149\n",
      "[294]\tvalidation_0-error:0.036197\tvalidation_1-error:0.037449\tvalidation_0-gini:0.701752\tvalidation_1-gini:0.719113\n",
      "[295]\tvalidation_0-error:0.036197\tvalidation_1-error:0.037449\tvalidation_0-gini:0.701752\tvalidation_1-gini:0.719113\n",
      "[296]\tvalidation_0-error:0.036197\tvalidation_1-error:0.037449\tvalidation_0-gini:0.701752\tvalidation_1-gini:0.719113\n",
      "[297]\tvalidation_0-error:0.036197\tvalidation_1-error:0.037449\tvalidation_0-gini:0.701752\tvalidation_1-gini:0.719113\n",
      "[298]\tvalidation_0-error:0.036197\tvalidation_1-error:0.037449\tvalidation_0-gini:0.701752\tvalidation_1-gini:0.719113\n",
      "[299]\tvalidation_0-error:0.036197\tvalidation_1-error:0.037449\tvalidation_0-gini:0.701752\tvalidation_1-gini:0.719113\n",
      "[300]\tvalidation_0-error:0.036197\tvalidation_1-error:0.037449\tvalidation_0-gini:0.701752\tvalidation_1-gini:0.719113\n",
      "[301]\tvalidation_0-error:0.036197\tvalidation_1-error:0.037449\tvalidation_0-gini:0.701752\tvalidation_1-gini:0.719113\n",
      "[302]\tvalidation_0-error:0.036197\tvalidation_1-error:0.037449\tvalidation_0-gini:0.701752\tvalidation_1-gini:0.719113\n",
      "[303]\tvalidation_0-error:0.036197\tvalidation_1-error:0.037449\tvalidation_0-gini:0.701752\tvalidation_1-gini:0.719113\n",
      "[304]\tvalidation_0-error:0.036197\tvalidation_1-error:0.037449\tvalidation_0-gini:0.701752\tvalidation_1-gini:0.719113\n",
      "[305]\tvalidation_0-error:0.036197\tvalidation_1-error:0.037449\tvalidation_0-gini:0.701752\tvalidation_1-gini:0.719113\n",
      "[306]\tvalidation_0-error:0.036197\tvalidation_1-error:0.037449\tvalidation_0-gini:0.701752\tvalidation_1-gini:0.719113\n",
      "[307]\tvalidation_0-error:0.036197\tvalidation_1-error:0.037449\tvalidation_0-gini:0.701752\tvalidation_1-gini:0.719113\n",
      "[308]\tvalidation_0-error:0.036197\tvalidation_1-error:0.037449\tvalidation_0-gini:0.701752\tvalidation_1-gini:0.719113\n",
      "[309]\tvalidation_0-error:0.036197\tvalidation_1-error:0.037449\tvalidation_0-gini:0.701752\tvalidation_1-gini:0.719113\n",
      "[310]\tvalidation_0-error:0.036197\tvalidation_1-error:0.037449\tvalidation_0-gini:0.701752\tvalidation_1-gini:0.719113\n",
      "[311]\tvalidation_0-error:0.036197\tvalidation_1-error:0.037449\tvalidation_0-gini:0.701752\tvalidation_1-gini:0.719113\n",
      "[312]\tvalidation_0-error:0.036197\tvalidation_1-error:0.037449\tvalidation_0-gini:0.701752\tvalidation_1-gini:0.719113\n",
      "[313]\tvalidation_0-error:0.036197\tvalidation_1-error:0.037449\tvalidation_0-gini:0.701703\tvalidation_1-gini:0.719025\n",
      "[314]\tvalidation_0-error:0.036197\tvalidation_1-error:0.037449\tvalidation_0-gini:0.701703\tvalidation_1-gini:0.719025\n",
      "[315]\tvalidation_0-error:0.036197\tvalidation_1-error:0.037449\tvalidation_0-gini:0.701703\tvalidation_1-gini:0.719025\n",
      "[316]\tvalidation_0-error:0.036197\tvalidation_1-error:0.037449\tvalidation_0-gini:0.701703\tvalidation_1-gini:0.719025\n",
      "[317]\tvalidation_0-error:0.036197\tvalidation_1-error:0.037449\tvalidation_0-gini:0.701574\tvalidation_1-gini:0.718924\n",
      "[318]\tvalidation_0-error:0.036197\tvalidation_1-error:0.037449\tvalidation_0-gini:0.701574\tvalidation_1-gini:0.718924\n",
      "[319]\tvalidation_0-error:0.036197\tvalidation_1-error:0.037449\tvalidation_0-gini:0.701574\tvalidation_1-gini:0.718924\n",
      "[320]\tvalidation_0-error:0.036197\tvalidation_1-error:0.037449\tvalidation_0-gini:0.701574\tvalidation_1-gini:0.718924\n",
      "[321]\tvalidation_0-error:0.036197\tvalidation_1-error:0.037449\tvalidation_0-gini:0.70147\tvalidation_1-gini:0.718876\n",
      "[322]\tvalidation_0-error:0.036197\tvalidation_1-error:0.037449\tvalidation_0-gini:0.70147\tvalidation_1-gini:0.718876\n",
      "[323]\tvalidation_0-error:0.036197\tvalidation_1-error:0.037449\tvalidation_0-gini:0.70147\tvalidation_1-gini:0.718876\n",
      "[324]\tvalidation_0-error:0.036197\tvalidation_1-error:0.037449\tvalidation_0-gini:0.70147\tvalidation_1-gini:0.718876\n",
      "[325]\tvalidation_0-error:0.036197\tvalidation_1-error:0.037449\tvalidation_0-gini:0.70147\tvalidation_1-gini:0.718876\n",
      "[326]\tvalidation_0-error:0.036197\tvalidation_1-error:0.037449\tvalidation_0-gini:0.70147\tvalidation_1-gini:0.718876\n",
      "[327]\tvalidation_0-error:0.036197\tvalidation_1-error:0.037449\tvalidation_0-gini:0.70134\tvalidation_1-gini:0.718858\n",
      "[328]\tvalidation_0-error:0.036197\tvalidation_1-error:0.037449\tvalidation_0-gini:0.70134\tvalidation_1-gini:0.718858\n",
      "[329]\tvalidation_0-error:0.036197\tvalidation_1-error:0.037449\tvalidation_0-gini:0.70134\tvalidation_1-gini:0.718858\n",
      "[330]\tvalidation_0-error:0.036197\tvalidation_1-error:0.037449\tvalidation_0-gini:0.70134\tvalidation_1-gini:0.718858\n",
      "[331]\tvalidation_0-error:0.036197\tvalidation_1-error:0.037449\tvalidation_0-gini:0.70134\tvalidation_1-gini:0.718858\n",
      "[332]\tvalidation_0-error:0.036197\tvalidation_1-error:0.037449\tvalidation_0-gini:0.70121\tvalidation_1-gini:0.718786\n",
      "[333]\tvalidation_0-error:0.036197\tvalidation_1-error:0.037449\tvalidation_0-gini:0.70121\tvalidation_1-gini:0.718786\n",
      "[334]\tvalidation_0-error:0.036197\tvalidation_1-error:0.037449\tvalidation_0-gini:0.70121\tvalidation_1-gini:0.718786\n",
      "[335]\tvalidation_0-error:0.036197\tvalidation_1-error:0.037449\tvalidation_0-gini:0.70121\tvalidation_1-gini:0.718786\n",
      "[336]\tvalidation_0-error:0.036197\tvalidation_1-error:0.037449\tvalidation_0-gini:0.70121\tvalidation_1-gini:0.718786\n",
      "[337]\tvalidation_0-error:0.036197\tvalidation_1-error:0.037449\tvalidation_0-gini:0.70121\tvalidation_1-gini:0.718786\n",
      "[338]\tvalidation_0-error:0.036197\tvalidation_1-error:0.037449\tvalidation_0-gini:0.701159\tvalidation_1-gini:0.718751\n",
      "[339]\tvalidation_0-error:0.036197\tvalidation_1-error:0.037449\tvalidation_0-gini:0.701159\tvalidation_1-gini:0.718751\n",
      "[340]\tvalidation_0-error:0.036197\tvalidation_1-error:0.037449\tvalidation_0-gini:0.701159\tvalidation_1-gini:0.718751\n",
      "[341]\tvalidation_0-error:0.036197\tvalidation_1-error:0.037449\tvalidation_0-gini:0.701159\tvalidation_1-gini:0.718751\n",
      "[342]\tvalidation_0-error:0.036197\tvalidation_1-error:0.037449\tvalidation_0-gini:0.70104\tvalidation_1-gini:0.718797\n",
      "[343]\tvalidation_0-error:0.036197\tvalidation_1-error:0.037449\tvalidation_0-gini:0.70104\tvalidation_1-gini:0.718797\n",
      "[344]\tvalidation_0-error:0.036197\tvalidation_1-error:0.037449\tvalidation_0-gini:0.70104\tvalidation_1-gini:0.718797\n",
      "[345]\tvalidation_0-error:0.036197\tvalidation_1-error:0.037449\tvalidation_0-gini:0.70104\tvalidation_1-gini:0.718797\n",
      "[346]\tvalidation_0-error:0.036197\tvalidation_1-error:0.037449\tvalidation_0-gini:0.70104\tvalidation_1-gini:0.718797\n",
      "[347]\tvalidation_0-error:0.036197\tvalidation_1-error:0.037449\tvalidation_0-gini:0.70104\tvalidation_1-gini:0.718797\n",
      "[348]\tvalidation_0-error:0.036197\tvalidation_1-error:0.037449\tvalidation_0-gini:0.70104\tvalidation_1-gini:0.718797\n",
      "[349]\tvalidation_0-error:0.036197\tvalidation_1-error:0.037449\tvalidation_0-gini:0.70104\tvalidation_1-gini:0.718797\n",
      "[350]\tvalidation_0-error:0.036197\tvalidation_1-error:0.037449\tvalidation_0-gini:0.70104\tvalidation_1-gini:0.718797\n",
      "[351]\tvalidation_0-error:0.036197\tvalidation_1-error:0.037449\tvalidation_0-gini:0.700964\tvalidation_1-gini:0.718782\n",
      "[352]\tvalidation_0-error:0.036197\tvalidation_1-error:0.037449\tvalidation_0-gini:0.7009\tvalidation_1-gini:0.718837\n",
      "[353]\tvalidation_0-error:0.036197\tvalidation_1-error:0.037449\tvalidation_0-gini:0.70083\tvalidation_1-gini:0.718704\n",
      "[354]\tvalidation_0-error:0.036197\tvalidation_1-error:0.037449\tvalidation_0-gini:0.70083\tvalidation_1-gini:0.718704\n",
      "[355]\tvalidation_0-error:0.036197\tvalidation_1-error:0.037449\tvalidation_0-gini:0.70083\tvalidation_1-gini:0.718704\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[356]\tvalidation_0-error:0.036197\tvalidation_1-error:0.037449\tvalidation_0-gini:0.70083\tvalidation_1-gini:0.718704\n",
      "[357]\tvalidation_0-error:0.036197\tvalidation_1-error:0.037449\tvalidation_0-gini:0.70083\tvalidation_1-gini:0.718704\n",
      "[358]\tvalidation_0-error:0.036197\tvalidation_1-error:0.037449\tvalidation_0-gini:0.70083\tvalidation_1-gini:0.718704\n",
      "[359]\tvalidation_0-error:0.036197\tvalidation_1-error:0.037449\tvalidation_0-gini:0.70083\tvalidation_1-gini:0.718704\n",
      "[360]\tvalidation_0-error:0.036197\tvalidation_1-error:0.037449\tvalidation_0-gini:0.700755\tvalidation_1-gini:0.718711\n",
      "[361]\tvalidation_0-error:0.036197\tvalidation_1-error:0.037449\tvalidation_0-gini:0.700755\tvalidation_1-gini:0.718711\n",
      "[362]\tvalidation_0-error:0.036197\tvalidation_1-error:0.037449\tvalidation_0-gini:0.700755\tvalidation_1-gini:0.718711\n",
      "[363]\tvalidation_0-error:0.036197\tvalidation_1-error:0.037449\tvalidation_0-gini:0.700755\tvalidation_1-gini:0.718711\n",
      "[364]\tvalidation_0-error:0.036197\tvalidation_1-error:0.037449\tvalidation_0-gini:0.700755\tvalidation_1-gini:0.718711\n",
      "[365]\tvalidation_0-error:0.036197\tvalidation_1-error:0.037449\tvalidation_0-gini:0.700755\tvalidation_1-gini:0.718711\n",
      "[366]\tvalidation_0-error:0.036197\tvalidation_1-error:0.037449\tvalidation_0-gini:0.700755\tvalidation_1-gini:0.718711\n",
      "[367]\tvalidation_0-error:0.036197\tvalidation_1-error:0.037449\tvalidation_0-gini:0.700755\tvalidation_1-gini:0.718711\n",
      "[368]\tvalidation_0-error:0.036197\tvalidation_1-error:0.037449\tvalidation_0-gini:0.700755\tvalidation_1-gini:0.718711\n",
      "[369]\tvalidation_0-error:0.036197\tvalidation_1-error:0.037449\tvalidation_0-gini:0.700755\tvalidation_1-gini:0.718711\n",
      "[370]\tvalidation_0-error:0.036197\tvalidation_1-error:0.037449\tvalidation_0-gini:0.700755\tvalidation_1-gini:0.718711\n",
      "[371]\tvalidation_0-error:0.036197\tvalidation_1-error:0.037449\tvalidation_0-gini:0.700755\tvalidation_1-gini:0.718711\n",
      "[372]\tvalidation_0-error:0.036197\tvalidation_1-error:0.037449\tvalidation_0-gini:0.700655\tvalidation_1-gini:0.718634\n",
      "[373]\tvalidation_0-error:0.036197\tvalidation_1-error:0.037449\tvalidation_0-gini:0.700655\tvalidation_1-gini:0.718634\n",
      "[374]\tvalidation_0-error:0.036197\tvalidation_1-error:0.037449\tvalidation_0-gini:0.700655\tvalidation_1-gini:0.718634\n",
      "[375]\tvalidation_0-error:0.036197\tvalidation_1-error:0.037449\tvalidation_0-gini:0.700655\tvalidation_1-gini:0.718634\n",
      "[376]\tvalidation_0-error:0.036197\tvalidation_1-error:0.037449\tvalidation_0-gini:0.700655\tvalidation_1-gini:0.718634\n",
      "[377]\tvalidation_0-error:0.036197\tvalidation_1-error:0.037449\tvalidation_0-gini:0.700655\tvalidation_1-gini:0.718634\n",
      "[378]\tvalidation_0-error:0.036197\tvalidation_1-error:0.037449\tvalidation_0-gini:0.700655\tvalidation_1-gini:0.718634\n",
      "[379]\tvalidation_0-error:0.036197\tvalidation_1-error:0.037449\tvalidation_0-gini:0.700507\tvalidation_1-gini:0.718633\n",
      "[380]\tvalidation_0-error:0.036197\tvalidation_1-error:0.037449\tvalidation_0-gini:0.700507\tvalidation_1-gini:0.718633\n",
      "[381]\tvalidation_0-error:0.036197\tvalidation_1-error:0.037449\tvalidation_0-gini:0.700507\tvalidation_1-gini:0.718633\n",
      "[382]\tvalidation_0-error:0.036197\tvalidation_1-error:0.037449\tvalidation_0-gini:0.700507\tvalidation_1-gini:0.718633\n",
      "[383]\tvalidation_0-error:0.036197\tvalidation_1-error:0.037449\tvalidation_0-gini:0.700507\tvalidation_1-gini:0.718633\n",
      "[384]\tvalidation_0-error:0.036197\tvalidation_1-error:0.037449\tvalidation_0-gini:0.700507\tvalidation_1-gini:0.718633\n",
      "[385]\tvalidation_0-error:0.036197\tvalidation_1-error:0.037449\tvalidation_0-gini:0.700507\tvalidation_1-gini:0.718633\n",
      "[386]\tvalidation_0-error:0.036197\tvalidation_1-error:0.037449\tvalidation_0-gini:0.700395\tvalidation_1-gini:0.718576\n",
      "[387]\tvalidation_0-error:0.036197\tvalidation_1-error:0.037449\tvalidation_0-gini:0.700318\tvalidation_1-gini:0.718492\n",
      "[388]\tvalidation_0-error:0.036197\tvalidation_1-error:0.037449\tvalidation_0-gini:0.700318\tvalidation_1-gini:0.718492\n",
      "[389]\tvalidation_0-error:0.036197\tvalidation_1-error:0.037449\tvalidation_0-gini:0.700318\tvalidation_1-gini:0.718492\n",
      "[390]\tvalidation_0-error:0.036197\tvalidation_1-error:0.037449\tvalidation_0-gini:0.700318\tvalidation_1-gini:0.718492\n",
      "[391]\tvalidation_0-error:0.036197\tvalidation_1-error:0.037449\tvalidation_0-gini:0.700318\tvalidation_1-gini:0.718492\n",
      "[392]\tvalidation_0-error:0.036197\tvalidation_1-error:0.037449\tvalidation_0-gini:0.700348\tvalidation_1-gini:0.718569\n",
      "[393]\tvalidation_0-error:0.036197\tvalidation_1-error:0.037449\tvalidation_0-gini:0.700348\tvalidation_1-gini:0.718569\n",
      "[394]\tvalidation_0-error:0.036197\tvalidation_1-error:0.037449\tvalidation_0-gini:0.700348\tvalidation_1-gini:0.718569\n",
      "[395]\tvalidation_0-error:0.036197\tvalidation_1-error:0.037449\tvalidation_0-gini:0.700348\tvalidation_1-gini:0.718569\n",
      "[396]\tvalidation_0-error:0.036197\tvalidation_1-error:0.037449\tvalidation_0-gini:0.700348\tvalidation_1-gini:0.718569\n",
      "[397]\tvalidation_0-error:0.036197\tvalidation_1-error:0.037449\tvalidation_0-gini:0.700348\tvalidation_1-gini:0.718569\n",
      "[398]\tvalidation_0-error:0.036197\tvalidation_1-error:0.037449\tvalidation_0-gini:0.700275\tvalidation_1-gini:0.718449\n",
      "[399]\tvalidation_0-error:0.036197\tvalidation_1-error:0.037449\tvalidation_0-gini:0.700129\tvalidation_1-gini:0.718472\n",
      "[400]\tvalidation_0-error:0.036197\tvalidation_1-error:0.037449\tvalidation_0-gini:0.700129\tvalidation_1-gini:0.718472\n",
      "[401]\tvalidation_0-error:0.036197\tvalidation_1-error:0.037449\tvalidation_0-gini:0.700129\tvalidation_1-gini:0.718472\n",
      "[402]\tvalidation_0-error:0.036197\tvalidation_1-error:0.037449\tvalidation_0-gini:0.700129\tvalidation_1-gini:0.718472\n",
      "[403]\tvalidation_0-error:0.036197\tvalidation_1-error:0.037449\tvalidation_0-gini:0.700129\tvalidation_1-gini:0.718472\n",
      "[404]\tvalidation_0-error:0.036197\tvalidation_1-error:0.037449\tvalidation_0-gini:0.700129\tvalidation_1-gini:0.718472\n",
      "[405]\tvalidation_0-error:0.036197\tvalidation_1-error:0.037449\tvalidation_0-gini:0.700129\tvalidation_1-gini:0.718472\n",
      "[406]\tvalidation_0-error:0.036197\tvalidation_1-error:0.037449\tvalidation_0-gini:0.700053\tvalidation_1-gini:0.71839\n",
      "[407]\tvalidation_0-error:0.036197\tvalidation_1-error:0.037449\tvalidation_0-gini:0.700053\tvalidation_1-gini:0.71839\n",
      "[408]\tvalidation_0-error:0.036197\tvalidation_1-error:0.037449\tvalidation_0-gini:0.700053\tvalidation_1-gini:0.71839\n",
      "[409]\tvalidation_0-error:0.036197\tvalidation_1-error:0.037449\tvalidation_0-gini:0.700053\tvalidation_1-gini:0.71839\n",
      "[410]\tvalidation_0-error:0.036197\tvalidation_1-error:0.037449\tvalidation_0-gini:0.700053\tvalidation_1-gini:0.71839\n",
      "[411]\tvalidation_0-error:0.036197\tvalidation_1-error:0.037449\tvalidation_0-gini:0.700053\tvalidation_1-gini:0.71839\n",
      "[412]\tvalidation_0-error:0.036197\tvalidation_1-error:0.037449\tvalidation_0-gini:0.700053\tvalidation_1-gini:0.71839\n",
      "[413]\tvalidation_0-error:0.036197\tvalidation_1-error:0.037449\tvalidation_0-gini:0.700053\tvalidation_1-gini:0.71839\n",
      "[414]\tvalidation_0-error:0.036197\tvalidation_1-error:0.037449\tvalidation_0-gini:0.700053\tvalidation_1-gini:0.71839\n",
      "[415]\tvalidation_0-error:0.036197\tvalidation_1-error:0.037449\tvalidation_0-gini:0.700053\tvalidation_1-gini:0.71839\n",
      "[416]\tvalidation_0-error:0.036197\tvalidation_1-error:0.037449\tvalidation_0-gini:0.699961\tvalidation_1-gini:0.718418\n",
      "[417]\tvalidation_0-error:0.036197\tvalidation_1-error:0.037449\tvalidation_0-gini:0.699915\tvalidation_1-gini:0.718359\n",
      "[418]\tvalidation_0-error:0.036197\tvalidation_1-error:0.037449\tvalidation_0-gini:0.699915\tvalidation_1-gini:0.718359\n",
      "[419]\tvalidation_0-error:0.036197\tvalidation_1-error:0.037449\tvalidation_0-gini:0.699915\tvalidation_1-gini:0.718359\n",
      "[420]\tvalidation_0-error:0.036197\tvalidation_1-error:0.037449\tvalidation_0-gini:0.699915\tvalidation_1-gini:0.718359\n",
      "[421]\tvalidation_0-error:0.036197\tvalidation_1-error:0.037449\tvalidation_0-gini:0.699915\tvalidation_1-gini:0.718359\n",
      "[422]\tvalidation_0-error:0.036197\tvalidation_1-error:0.037449\tvalidation_0-gini:0.699915\tvalidation_1-gini:0.718359\n",
      "[423]\tvalidation_0-error:0.036197\tvalidation_1-error:0.037449\tvalidation_0-gini:0.699915\tvalidation_1-gini:0.718359\n",
      "[424]\tvalidation_0-error:0.036197\tvalidation_1-error:0.037449\tvalidation_0-gini:0.699915\tvalidation_1-gini:0.718359\n",
      "[425]\tvalidation_0-error:0.036197\tvalidation_1-error:0.037449\tvalidation_0-gini:0.699915\tvalidation_1-gini:0.718359\n",
      "[426]\tvalidation_0-error:0.036197\tvalidation_1-error:0.037449\tvalidation_0-gini:0.699915\tvalidation_1-gini:0.718359\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[427]\tvalidation_0-error:0.036197\tvalidation_1-error:0.037449\tvalidation_0-gini:0.699915\tvalidation_1-gini:0.718359\n",
      "[428]\tvalidation_0-error:0.036197\tvalidation_1-error:0.037449\tvalidation_0-gini:0.699915\tvalidation_1-gini:0.718359\n",
      "[429]\tvalidation_0-error:0.036197\tvalidation_1-error:0.037449\tvalidation_0-gini:0.699915\tvalidation_1-gini:0.718359\n",
      "[430]\tvalidation_0-error:0.036197\tvalidation_1-error:0.037449\tvalidation_0-gini:0.699817\tvalidation_1-gini:0.718285\n",
      "[431]\tvalidation_0-error:0.036197\tvalidation_1-error:0.037449\tvalidation_0-gini:0.699683\tvalidation_1-gini:0.718233\n",
      "[432]\tvalidation_0-error:0.036197\tvalidation_1-error:0.037449\tvalidation_0-gini:0.699683\tvalidation_1-gini:0.718233\n",
      "[433]\tvalidation_0-error:0.036197\tvalidation_1-error:0.037449\tvalidation_0-gini:0.699683\tvalidation_1-gini:0.718233\n",
      "[434]\tvalidation_0-error:0.036197\tvalidation_1-error:0.037449\tvalidation_0-gini:0.699652\tvalidation_1-gini:0.718234\n",
      "[435]\tvalidation_0-error:0.036197\tvalidation_1-error:0.037449\tvalidation_0-gini:0.699652\tvalidation_1-gini:0.718234\n",
      "[436]\tvalidation_0-error:0.036197\tvalidation_1-error:0.037449\tvalidation_0-gini:0.699578\tvalidation_1-gini:0.718243\n",
      "[437]\tvalidation_0-error:0.036197\tvalidation_1-error:0.037449\tvalidation_0-gini:0.699551\tvalidation_1-gini:0.718236\n",
      "[438]\tvalidation_0-error:0.036197\tvalidation_1-error:0.037449\tvalidation_0-gini:0.699551\tvalidation_1-gini:0.718236\n",
      "[439]\tvalidation_0-error:0.036197\tvalidation_1-error:0.037449\tvalidation_0-gini:0.699551\tvalidation_1-gini:0.718236\n",
      "[440]\tvalidation_0-error:0.036197\tvalidation_1-error:0.037449\tvalidation_0-gini:0.699551\tvalidation_1-gini:0.718236\n",
      "[441]\tvalidation_0-error:0.036197\tvalidation_1-error:0.037449\tvalidation_0-gini:0.699551\tvalidation_1-gini:0.718236\n",
      "[442]\tvalidation_0-error:0.036197\tvalidation_1-error:0.037449\tvalidation_0-gini:0.699551\tvalidation_1-gini:0.718236\n",
      "[443]\tvalidation_0-error:0.036197\tvalidation_1-error:0.037449\tvalidation_0-gini:0.699551\tvalidation_1-gini:0.718236\n",
      "[444]\tvalidation_0-error:0.036197\tvalidation_1-error:0.037449\tvalidation_0-gini:0.699551\tvalidation_1-gini:0.718236\n",
      "[445]\tvalidation_0-error:0.036197\tvalidation_1-error:0.037449\tvalidation_0-gini:0.699551\tvalidation_1-gini:0.718236\n",
      "[446]\tvalidation_0-error:0.036197\tvalidation_1-error:0.037449\tvalidation_0-gini:0.699551\tvalidation_1-gini:0.718236\n",
      "[447]\tvalidation_0-error:0.036197\tvalidation_1-error:0.037449\tvalidation_0-gini:0.699551\tvalidation_1-gini:0.718236\n",
      "[448]\tvalidation_0-error:0.036197\tvalidation_1-error:0.037449\tvalidation_0-gini:0.699551\tvalidation_1-gini:0.718236\n",
      "[449]\tvalidation_0-error:0.036197\tvalidation_1-error:0.037449\tvalidation_0-gini:0.699551\tvalidation_1-gini:0.718236\n",
      "[450]\tvalidation_0-error:0.036197\tvalidation_1-error:0.037449\tvalidation_0-gini:0.699551\tvalidation_1-gini:0.718236\n",
      "[451]\tvalidation_0-error:0.036197\tvalidation_1-error:0.037449\tvalidation_0-gini:0.699551\tvalidation_1-gini:0.718236\n",
      "[452]\tvalidation_0-error:0.036197\tvalidation_1-error:0.037449\tvalidation_0-gini:0.699551\tvalidation_1-gini:0.718236\n",
      "[453]\tvalidation_0-error:0.036197\tvalidation_1-error:0.037449\tvalidation_0-gini:0.699433\tvalidation_1-gini:0.718063\n",
      "[454]\tvalidation_0-error:0.036197\tvalidation_1-error:0.037449\tvalidation_0-gini:0.699433\tvalidation_1-gini:0.718063\n",
      "[455]\tvalidation_0-error:0.036197\tvalidation_1-error:0.037449\tvalidation_0-gini:0.699433\tvalidation_1-gini:0.718063\n",
      "[456]\tvalidation_0-error:0.036197\tvalidation_1-error:0.037449\tvalidation_0-gini:0.699433\tvalidation_1-gini:0.718063\n",
      "[457]\tvalidation_0-error:0.036197\tvalidation_1-error:0.037449\tvalidation_0-gini:0.699433\tvalidation_1-gini:0.718063\n",
      "[458]\tvalidation_0-error:0.036197\tvalidation_1-error:0.037449\tvalidation_0-gini:0.699433\tvalidation_1-gini:0.718063\n",
      "[459]\tvalidation_0-error:0.036197\tvalidation_1-error:0.037449\tvalidation_0-gini:0.699433\tvalidation_1-gini:0.718063\n",
      "[460]\tvalidation_0-error:0.036197\tvalidation_1-error:0.037449\tvalidation_0-gini:0.699433\tvalidation_1-gini:0.718063\n",
      "[461]\tvalidation_0-error:0.036197\tvalidation_1-error:0.037449\tvalidation_0-gini:0.699433\tvalidation_1-gini:0.718063\n",
      "[462]\tvalidation_0-error:0.036197\tvalidation_1-error:0.037449\tvalidation_0-gini:0.699433\tvalidation_1-gini:0.718063\n",
      "[463]\tvalidation_0-error:0.036197\tvalidation_1-error:0.037449\tvalidation_0-gini:0.699433\tvalidation_1-gini:0.718063\n",
      "[464]\tvalidation_0-error:0.036197\tvalidation_1-error:0.037449\tvalidation_0-gini:0.699433\tvalidation_1-gini:0.718063\n",
      "[465]\tvalidation_0-error:0.036197\tvalidation_1-error:0.037449\tvalidation_0-gini:0.699433\tvalidation_1-gini:0.718063\n",
      "[466]\tvalidation_0-error:0.036197\tvalidation_1-error:0.037449\tvalidation_0-gini:0.699433\tvalidation_1-gini:0.718063\n",
      "[467]\tvalidation_0-error:0.036197\tvalidation_1-error:0.037449\tvalidation_0-gini:0.699433\tvalidation_1-gini:0.718063\n",
      "[468]\tvalidation_0-error:0.036197\tvalidation_1-error:0.037449\tvalidation_0-gini:0.699433\tvalidation_1-gini:0.718063\n",
      "[469]\tvalidation_0-error:0.036197\tvalidation_1-error:0.037449\tvalidation_0-gini:0.699433\tvalidation_1-gini:0.718063\n",
      "[470]\tvalidation_0-error:0.036197\tvalidation_1-error:0.037449\tvalidation_0-gini:0.699433\tvalidation_1-gini:0.718063\n",
      "[471]\tvalidation_0-error:0.036197\tvalidation_1-error:0.037449\tvalidation_0-gini:0.699433\tvalidation_1-gini:0.718063\n",
      "[472]\tvalidation_0-error:0.036197\tvalidation_1-error:0.037449\tvalidation_0-gini:0.699433\tvalidation_1-gini:0.718063\n",
      "[473]\tvalidation_0-error:0.036197\tvalidation_1-error:0.037449\tvalidation_0-gini:0.699433\tvalidation_1-gini:0.718063\n",
      "[474]\tvalidation_0-error:0.036197\tvalidation_1-error:0.037449\tvalidation_0-gini:0.699433\tvalidation_1-gini:0.718063\n",
      "[475]\tvalidation_0-error:0.036197\tvalidation_1-error:0.037449\tvalidation_0-gini:0.699433\tvalidation_1-gini:0.718063\n",
      "[476]\tvalidation_0-error:0.036197\tvalidation_1-error:0.037449\tvalidation_0-gini:0.699433\tvalidation_1-gini:0.718063\n",
      "[477]\tvalidation_0-error:0.036197\tvalidation_1-error:0.037449\tvalidation_0-gini:0.699433\tvalidation_1-gini:0.718063\n",
      "[478]\tvalidation_0-error:0.036197\tvalidation_1-error:0.037449\tvalidation_0-gini:0.699433\tvalidation_1-gini:0.718063\n",
      "[479]\tvalidation_0-error:0.036197\tvalidation_1-error:0.037449\tvalidation_0-gini:0.699433\tvalidation_1-gini:0.718063\n",
      "[480]\tvalidation_0-error:0.036197\tvalidation_1-error:0.037449\tvalidation_0-gini:0.699433\tvalidation_1-gini:0.718063\n",
      "[481]\tvalidation_0-error:0.036197\tvalidation_1-error:0.037449\tvalidation_0-gini:0.699433\tvalidation_1-gini:0.718063\n",
      "[482]\tvalidation_0-error:0.036197\tvalidation_1-error:0.037449\tvalidation_0-gini:0.699433\tvalidation_1-gini:0.718063\n",
      "[483]\tvalidation_0-error:0.036197\tvalidation_1-error:0.037449\tvalidation_0-gini:0.699433\tvalidation_1-gini:0.718063\n",
      "[484]\tvalidation_0-error:0.036197\tvalidation_1-error:0.037449\tvalidation_0-gini:0.699433\tvalidation_1-gini:0.718063\n",
      "[485]\tvalidation_0-error:0.036197\tvalidation_1-error:0.037449\tvalidation_0-gini:0.699433\tvalidation_1-gini:0.718063\n",
      "[486]\tvalidation_0-error:0.036197\tvalidation_1-error:0.037449\tvalidation_0-gini:0.699433\tvalidation_1-gini:0.718063\n",
      "[487]\tvalidation_0-error:0.036197\tvalidation_1-error:0.037449\tvalidation_0-gini:0.699433\tvalidation_1-gini:0.718063\n",
      "[488]\tvalidation_0-error:0.036197\tvalidation_1-error:0.037449\tvalidation_0-gini:0.699433\tvalidation_1-gini:0.718063\n",
      "[489]\tvalidation_0-error:0.036197\tvalidation_1-error:0.037449\tvalidation_0-gini:0.699433\tvalidation_1-gini:0.718063\n",
      "[490]\tvalidation_0-error:0.036197\tvalidation_1-error:0.037449\tvalidation_0-gini:0.699356\tvalidation_1-gini:0.718078\n",
      "[491]\tvalidation_0-error:0.036197\tvalidation_1-error:0.037449\tvalidation_0-gini:0.699356\tvalidation_1-gini:0.718078\n",
      "[492]\tvalidation_0-error:0.036197\tvalidation_1-error:0.037449\tvalidation_0-gini:0.699356\tvalidation_1-gini:0.718078\n",
      "[493]\tvalidation_0-error:0.036197\tvalidation_1-error:0.037449\tvalidation_0-gini:0.69927\tvalidation_1-gini:0.717851\n",
      "[494]\tvalidation_0-error:0.036197\tvalidation_1-error:0.037449\tvalidation_0-gini:0.69927\tvalidation_1-gini:0.717851\n",
      "[495]\tvalidation_0-error:0.036197\tvalidation_1-error:0.037449\tvalidation_0-gini:0.69927\tvalidation_1-gini:0.717851\n",
      "[496]\tvalidation_0-error:0.036197\tvalidation_1-error:0.037449\tvalidation_0-gini:0.69927\tvalidation_1-gini:0.717851\n",
      "[497]\tvalidation_0-error:0.036197\tvalidation_1-error:0.037449\tvalidation_0-gini:0.69927\tvalidation_1-gini:0.717851\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[498]\tvalidation_0-error:0.036197\tvalidation_1-error:0.037449\tvalidation_0-gini:0.699119\tvalidation_1-gini:0.717831\n",
      "[499]\tvalidation_0-error:0.036197\tvalidation_1-error:0.037449\tvalidation_0-gini:0.699119\tvalidation_1-gini:0.717831\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "       colsample_bynode=1, colsample_bytree=0.8, gamma=10,\n",
       "       learning_rate=0.07, max_delta_step=0, max_depth=4,\n",
       "       min_child_weight=6, missing=None, n_estimators=500, n_jobs=1,\n",
       "       nthread=None, objective='binary:logistic', random_state=123,\n",
       "       reg_alpha=8, reg_lambda=1.3, scale_pos_weight=1, seed=None,\n",
       "       silent=None, subsample=0.8, verbosity=1)"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eval_set = [(X_train_orig, y_train_orig), (X_test_orig, y_test_orig)]\n",
    "xg_cl.fit(X_train_orig, y_train_orig, early_stopping_rounds=50, eval_metric=gini_xgb, eval_set=eval_set, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\tvalidation_0-error:0.44068\tvalidation_1-error:0.445033\tvalidation_0-gini:0.814985\tvalidation_1-gini:0.820908\n",
      "Multiple eval metrics have been passed: 'validation_1-gini' will be used for early stopping.\n",
      "\n",
      "Will train until validation_1-gini hasn't improved in 50 rounds.\n",
      "[1]\tvalidation_0-error:0.423596\tvalidation_1-error:0.427287\tvalidation_0-gini:0.77465\tvalidation_1-gini:0.779562\n",
      "[2]\tvalidation_0-error:0.41501\tvalidation_1-error:0.414957\tvalidation_0-gini:0.757424\tvalidation_1-gini:0.761591\n",
      "[3]\tvalidation_0-error:0.414549\tvalidation_1-error:0.415764\tvalidation_0-gini:0.757062\tvalidation_1-gini:0.759868\n",
      "[4]\tvalidation_0-error:0.414866\tvalidation_1-error:0.41392\tvalidation_0-gini:0.752634\tvalidation_1-gini:0.75714\n",
      "[5]\tvalidation_0-error:0.413858\tvalidation_1-error:0.413575\tvalidation_0-gini:0.751532\tvalidation_1-gini:0.758018\n",
      "[6]\tvalidation_0-error:0.414751\tvalidation_1-error:0.41392\tvalidation_0-gini:0.753839\tvalidation_1-gini:0.760337\n",
      "[7]\tvalidation_0-error:0.413598\tvalidation_1-error:0.412192\tvalidation_0-gini:0.74939\tvalidation_1-gini:0.758815\n",
      "[8]\tvalidation_0-error:0.412993\tvalidation_1-error:0.410233\tvalidation_0-gini:0.749371\tvalidation_1-gini:0.757825\n",
      "[9]\tvalidation_0-error:0.413166\tvalidation_1-error:0.410002\tvalidation_0-gini:0.748626\tvalidation_1-gini:0.756125\n",
      "[10]\tvalidation_0-error:0.413685\tvalidation_1-error:0.408274\tvalidation_0-gini:0.745963\tvalidation_1-gini:0.754031\n",
      "[11]\tvalidation_0-error:0.411524\tvalidation_1-error:0.408965\tvalidation_0-gini:0.742401\tvalidation_1-gini:0.750207\n",
      "[12]\tvalidation_0-error:0.411063\tvalidation_1-error:0.407006\tvalidation_0-gini:0.740989\tvalidation_1-gini:0.749063\n",
      "[13]\tvalidation_0-error:0.409334\tvalidation_1-error:0.406545\tvalidation_0-gini:0.738597\tvalidation_1-gini:0.747\n",
      "[14]\tvalidation_0-error:0.408845\tvalidation_1-error:0.404932\tvalidation_0-gini:0.737143\tvalidation_1-gini:0.745306\n",
      "[15]\tvalidation_0-error:0.408326\tvalidation_1-error:0.405969\tvalidation_0-gini:0.736355\tvalidation_1-gini:0.745249\n",
      "[16]\tvalidation_0-error:0.40919\tvalidation_1-error:0.405393\tvalidation_0-gini:0.735439\tvalidation_1-gini:0.744071\n",
      "[17]\tvalidation_0-error:0.408557\tvalidation_1-error:0.403319\tvalidation_0-gini:0.734027\tvalidation_1-gini:0.741844\n",
      "[18]\tvalidation_0-error:0.408614\tvalidation_1-error:0.401821\tvalidation_0-gini:0.732834\tvalidation_1-gini:0.740531\n",
      "[19]\tvalidation_0-error:0.407836\tvalidation_1-error:0.401705\tvalidation_0-gini:0.731255\tvalidation_1-gini:0.739715\n",
      "[20]\tvalidation_0-error:0.406799\tvalidation_1-error:0.402627\tvalidation_0-gini:0.730033\tvalidation_1-gini:0.737602\n",
      "[21]\tvalidation_0-error:0.406742\tvalidation_1-error:0.40378\tvalidation_0-gini:0.728889\tvalidation_1-gini:0.736894\n",
      "[22]\tvalidation_0-error:0.406079\tvalidation_1-error:0.402397\tvalidation_0-gini:0.728595\tvalidation_1-gini:0.736928\n",
      "[23]\tvalidation_0-error:0.407001\tvalidation_1-error:0.404586\tvalidation_0-gini:0.727607\tvalidation_1-gini:0.73535\n",
      "[24]\tvalidation_0-error:0.405503\tvalidation_1-error:0.404932\tvalidation_0-gini:0.726353\tvalidation_1-gini:0.733104\n",
      "[25]\tvalidation_0-error:0.405647\tvalidation_1-error:0.403088\tvalidation_0-gini:0.725869\tvalidation_1-gini:0.732933\n",
      "[26]\tvalidation_0-error:0.404466\tvalidation_1-error:0.403895\tvalidation_0-gini:0.724177\tvalidation_1-gini:0.731005\n",
      "[27]\tvalidation_0-error:0.403947\tvalidation_1-error:0.402743\tvalidation_0-gini:0.723066\tvalidation_1-gini:0.730469\n",
      "[28]\tvalidation_0-error:0.403918\tvalidation_1-error:0.403088\tvalidation_0-gini:0.722031\tvalidation_1-gini:0.730348\n",
      "[29]\tvalidation_0-error:0.402535\tvalidation_1-error:0.404356\tvalidation_0-gini:0.720954\tvalidation_1-gini:0.728939\n",
      "[30]\tvalidation_0-error:0.401325\tvalidation_1-error:0.404125\tvalidation_0-gini:0.720286\tvalidation_1-gini:0.728154\n",
      "[31]\tvalidation_0-error:0.401786\tvalidation_1-error:0.403204\tvalidation_0-gini:0.719929\tvalidation_1-gini:0.727696\n",
      "[32]\tvalidation_0-error:0.40193\tvalidation_1-error:0.402973\tvalidation_0-gini:0.719677\tvalidation_1-gini:0.727026\n",
      "[33]\tvalidation_0-error:0.401152\tvalidation_1-error:0.40159\tvalidation_0-gini:0.719101\tvalidation_1-gini:0.72596\n",
      "[34]\tvalidation_0-error:0.401613\tvalidation_1-error:0.400899\tvalidation_0-gini:0.718761\tvalidation_1-gini:0.725327\n",
      "[35]\tvalidation_0-error:0.400519\tvalidation_1-error:0.402051\tvalidation_0-gini:0.717951\tvalidation_1-gini:0.725421\n",
      "[36]\tvalidation_0-error:0.40049\tvalidation_1-error:0.40159\tvalidation_0-gini:0.71702\tvalidation_1-gini:0.724134\n",
      "[37]\tvalidation_0-error:0.400547\tvalidation_1-error:0.401245\tvalidation_0-gini:0.717133\tvalidation_1-gini:0.724426\n",
      "[38]\tvalidation_0-error:0.400259\tvalidation_1-error:0.399631\tvalidation_0-gini:0.715924\tvalidation_1-gini:0.724372\n",
      "[39]\tvalidation_0-error:0.400058\tvalidation_1-error:0.40136\tvalidation_0-gini:0.715286\tvalidation_1-gini:0.724046\n",
      "[40]\tvalidation_0-error:0.399395\tvalidation_1-error:0.40136\tvalidation_0-gini:0.714835\tvalidation_1-gini:0.72354\n",
      "[41]\tvalidation_0-error:0.399049\tvalidation_1-error:0.401245\tvalidation_0-gini:0.713712\tvalidation_1-gini:0.722797\n",
      "[42]\tvalidation_0-error:0.399251\tvalidation_1-error:0.400668\tvalidation_0-gini:0.71337\tvalidation_1-gini:0.722271\n",
      "[43]\tvalidation_0-error:0.399136\tvalidation_1-error:0.401705\tvalidation_0-gini:0.71293\tvalidation_1-gini:0.721655\n",
      "[44]\tvalidation_0-error:0.398992\tvalidation_1-error:0.400899\tvalidation_0-gini:0.712832\tvalidation_1-gini:0.720962\n",
      "[45]\tvalidation_0-error:0.398271\tvalidation_1-error:0.402512\tvalidation_0-gini:0.712241\tvalidation_1-gini:0.721068\n",
      "[46]\tvalidation_0-error:0.397436\tvalidation_1-error:0.40159\tvalidation_0-gini:0.711484\tvalidation_1-gini:0.721096\n",
      "[47]\tvalidation_0-error:0.397926\tvalidation_1-error:0.40136\tvalidation_0-gini:0.710919\tvalidation_1-gini:0.72087\n",
      "[48]\tvalidation_0-error:0.398185\tvalidation_1-error:0.400899\tvalidation_0-gini:0.71046\tvalidation_1-gini:0.720519\n",
      "[49]\tvalidation_0-error:0.397551\tvalidation_1-error:0.401475\tvalidation_0-gini:0.710086\tvalidation_1-gini:0.720372\n",
      "[50]\tvalidation_0-error:0.397205\tvalidation_1-error:0.401245\tvalidation_0-gini:0.710036\tvalidation_1-gini:0.720621\n",
      "[51]\tvalidation_0-error:0.397839\tvalidation_1-error:0.401014\tvalidation_0-gini:0.709842\tvalidation_1-gini:0.719937\n",
      "[52]\tvalidation_0-error:0.397465\tvalidation_1-error:0.401245\tvalidation_0-gini:0.708797\tvalidation_1-gini:0.71907\n",
      "[53]\tvalidation_0-error:0.397551\tvalidation_1-error:0.401245\tvalidation_0-gini:0.708398\tvalidation_1-gini:0.718628\n",
      "[54]\tvalidation_0-error:0.397177\tvalidation_1-error:0.402282\tvalidation_0-gini:0.708083\tvalidation_1-gini:0.718313\n",
      "[55]\tvalidation_0-error:0.397666\tvalidation_1-error:0.403088\tvalidation_0-gini:0.707569\tvalidation_1-gini:0.71795\n",
      "[56]\tvalidation_0-error:0.397638\tvalidation_1-error:0.401245\tvalidation_0-gini:0.707069\tvalidation_1-gini:0.717643\n",
      "[57]\tvalidation_0-error:0.397321\tvalidation_1-error:0.401705\tvalidation_0-gini:0.706598\tvalidation_1-gini:0.717531\n",
      "[58]\tvalidation_0-error:0.397292\tvalidation_1-error:0.400668\tvalidation_0-gini:0.706153\tvalidation_1-gini:0.717819\n",
      "[59]\tvalidation_0-error:0.396975\tvalidation_1-error:0.400438\tvalidation_0-gini:0.706038\tvalidation_1-gini:0.717642\n",
      "[60]\tvalidation_0-error:0.396514\tvalidation_1-error:0.400092\tvalidation_0-gini:0.70576\tvalidation_1-gini:0.717397\n",
      "[61]\tvalidation_0-error:0.396658\tvalidation_1-error:0.400668\tvalidation_0-gini:0.70565\tvalidation_1-gini:0.717171\n",
      "[62]\tvalidation_0-error:0.396456\tvalidation_1-error:0.400092\tvalidation_0-gini:0.705255\tvalidation_1-gini:0.717017\n",
      "[63]\tvalidation_0-error:0.395851\tvalidation_1-error:0.399516\tvalidation_0-gini:0.705036\tvalidation_1-gini:0.71705\n",
      "[64]\tvalidation_0-error:0.396111\tvalidation_1-error:0.40136\tvalidation_0-gini:0.704569\tvalidation_1-gini:0.717123\n",
      "[65]\tvalidation_0-error:0.396283\tvalidation_1-error:0.401129\tvalidation_0-gini:0.704615\tvalidation_1-gini:0.717159\n",
      "[66]\tvalidation_0-error:0.396082\tvalidation_1-error:0.400668\tvalidation_0-gini:0.704101\tvalidation_1-gini:0.717219\n",
      "[67]\tvalidation_0-error:0.396283\tvalidation_1-error:0.400553\tvalidation_0-gini:0.704079\tvalidation_1-gini:0.717149\n",
      "[68]\tvalidation_0-error:0.395995\tvalidation_1-error:0.400668\tvalidation_0-gini:0.703798\tvalidation_1-gini:0.716777\n",
      "[69]\tvalidation_0-error:0.395794\tvalidation_1-error:0.400438\tvalidation_0-gini:0.7037\tvalidation_1-gini:0.716831\n",
      "[70]\tvalidation_0-error:0.395592\tvalidation_1-error:0.400207\tvalidation_0-gini:0.703628\tvalidation_1-gini:0.716372\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[71]\tvalidation_0-error:0.395621\tvalidation_1-error:0.399401\tvalidation_0-gini:0.70334\tvalidation_1-gini:0.716037\n",
      "[72]\tvalidation_0-error:0.395765\tvalidation_1-error:0.399401\tvalidation_0-gini:0.703065\tvalidation_1-gini:0.716008\n",
      "[73]\tvalidation_0-error:0.395477\tvalidation_1-error:0.399286\tvalidation_0-gini:0.7029\tvalidation_1-gini:0.715944\n",
      "[74]\tvalidation_0-error:0.395448\tvalidation_1-error:0.399286\tvalidation_0-gini:0.7029\tvalidation_1-gini:0.715944\n",
      "[75]\tvalidation_0-error:0.395736\tvalidation_1-error:0.399516\tvalidation_0-gini:0.702791\tvalidation_1-gini:0.715969\n",
      "[76]\tvalidation_0-error:0.395707\tvalidation_1-error:0.400323\tvalidation_0-gini:0.702703\tvalidation_1-gini:0.71575\n",
      "[77]\tvalidation_0-error:0.395678\tvalidation_1-error:0.399977\tvalidation_0-gini:0.702577\tvalidation_1-gini:0.715176\n",
      "[78]\tvalidation_0-error:0.395851\tvalidation_1-error:0.400207\tvalidation_0-gini:0.702577\tvalidation_1-gini:0.715176\n",
      "[79]\tvalidation_0-error:0.395707\tvalidation_1-error:0.399977\tvalidation_0-gini:0.702577\tvalidation_1-gini:0.715176\n",
      "[80]\tvalidation_0-error:0.395707\tvalidation_1-error:0.399977\tvalidation_0-gini:0.702577\tvalidation_1-gini:0.715176\n",
      "[81]\tvalidation_0-error:0.396168\tvalidation_1-error:0.399516\tvalidation_0-gini:0.702304\tvalidation_1-gini:0.714953\n",
      "[82]\tvalidation_0-error:0.396111\tvalidation_1-error:0.399401\tvalidation_0-gini:0.702253\tvalidation_1-gini:0.71487\n",
      "[83]\tvalidation_0-error:0.396082\tvalidation_1-error:0.399401\tvalidation_0-gini:0.702253\tvalidation_1-gini:0.71487\n",
      "[84]\tvalidation_0-error:0.396197\tvalidation_1-error:0.398709\tvalidation_0-gini:0.702107\tvalidation_1-gini:0.714389\n",
      "[85]\tvalidation_0-error:0.395851\tvalidation_1-error:0.398248\tvalidation_0-gini:0.701759\tvalidation_1-gini:0.714627\n",
      "[86]\tvalidation_0-error:0.395794\tvalidation_1-error:0.398364\tvalidation_0-gini:0.701475\tvalidation_1-gini:0.71471\n",
      "[87]\tvalidation_0-error:0.395304\tvalidation_1-error:0.398248\tvalidation_0-gini:0.701339\tvalidation_1-gini:0.714496\n",
      "[88]\tvalidation_0-error:0.395362\tvalidation_1-error:0.398364\tvalidation_0-gini:0.701339\tvalidation_1-gini:0.714496\n",
      "[89]\tvalidation_0-error:0.395621\tvalidation_1-error:0.398248\tvalidation_0-gini:0.701339\tvalidation_1-gini:0.714496\n",
      "[90]\tvalidation_0-error:0.395707\tvalidation_1-error:0.398364\tvalidation_0-gini:0.701326\tvalidation_1-gini:0.714316\n",
      "[91]\tvalidation_0-error:0.395707\tvalidation_1-error:0.398364\tvalidation_0-gini:0.701326\tvalidation_1-gini:0.714316\n",
      "[92]\tvalidation_0-error:0.39565\tvalidation_1-error:0.397557\tvalidation_0-gini:0.701033\tvalidation_1-gini:0.714108\n",
      "[93]\tvalidation_0-error:0.395333\tvalidation_1-error:0.397788\tvalidation_0-gini:0.701033\tvalidation_1-gini:0.714108\n",
      "[94]\tvalidation_0-error:0.395419\tvalidation_1-error:0.397672\tvalidation_0-gini:0.701033\tvalidation_1-gini:0.714108\n",
      "[95]\tvalidation_0-error:0.39565\tvalidation_1-error:0.397557\tvalidation_0-gini:0.700781\tvalidation_1-gini:0.71423\n",
      "[96]\tvalidation_0-error:0.39565\tvalidation_1-error:0.397672\tvalidation_0-gini:0.700781\tvalidation_1-gini:0.714231\n",
      "[97]\tvalidation_0-error:0.39565\tvalidation_1-error:0.397672\tvalidation_0-gini:0.700781\tvalidation_1-gini:0.714231\n",
      "[98]\tvalidation_0-error:0.395678\tvalidation_1-error:0.397788\tvalidation_0-gini:0.700781\tvalidation_1-gini:0.71423\n",
      "[99]\tvalidation_0-error:0.395506\tvalidation_1-error:0.397672\tvalidation_0-gini:0.700781\tvalidation_1-gini:0.71423\n",
      "[100]\tvalidation_0-error:0.395419\tvalidation_1-error:0.398364\tvalidation_0-gini:0.700628\tvalidation_1-gini:0.71426\n",
      "[101]\tvalidation_0-error:0.395506\tvalidation_1-error:0.398594\tvalidation_0-gini:0.700628\tvalidation_1-gini:0.71426\n",
      "[102]\tvalidation_0-error:0.395448\tvalidation_1-error:0.398594\tvalidation_0-gini:0.700628\tvalidation_1-gini:0.71426\n",
      "[103]\tvalidation_0-error:0.395448\tvalidation_1-error:0.398594\tvalidation_0-gini:0.700628\tvalidation_1-gini:0.71426\n",
      "[104]\tvalidation_0-error:0.395448\tvalidation_1-error:0.398364\tvalidation_0-gini:0.700628\tvalidation_1-gini:0.71426\n",
      "[105]\tvalidation_0-error:0.395678\tvalidation_1-error:0.397672\tvalidation_0-gini:0.700612\tvalidation_1-gini:0.714255\n",
      "[106]\tvalidation_0-error:0.395678\tvalidation_1-error:0.397672\tvalidation_0-gini:0.700612\tvalidation_1-gini:0.714255\n",
      "[107]\tvalidation_0-error:0.39565\tvalidation_1-error:0.398018\tvalidation_0-gini:0.700612\tvalidation_1-gini:0.714255\n",
      "[108]\tvalidation_0-error:0.395333\tvalidation_1-error:0.398248\tvalidation_0-gini:0.700401\tvalidation_1-gini:0.714217\n",
      "[109]\tvalidation_0-error:0.395218\tvalidation_1-error:0.398709\tvalidation_0-gini:0.700333\tvalidation_1-gini:0.713972\n",
      "[110]\tvalidation_0-error:0.395362\tvalidation_1-error:0.398825\tvalidation_0-gini:0.700333\tvalidation_1-gini:0.713972\n",
      "[111]\tvalidation_0-error:0.39516\tvalidation_1-error:0.398825\tvalidation_0-gini:0.700333\tvalidation_1-gini:0.713972\n",
      "[112]\tvalidation_0-error:0.394555\tvalidation_1-error:0.397788\tvalidation_0-gini:0.700018\tvalidation_1-gini:0.713571\n",
      "[113]\tvalidation_0-error:0.394958\tvalidation_1-error:0.397903\tvalidation_0-gini:0.69999\tvalidation_1-gini:0.713644\n",
      "[114]\tvalidation_0-error:0.395016\tvalidation_1-error:0.397903\tvalidation_0-gini:0.69999\tvalidation_1-gini:0.713644\n",
      "[115]\tvalidation_0-error:0.395218\tvalidation_1-error:0.397903\tvalidation_0-gini:0.69999\tvalidation_1-gini:0.713644\n",
      "[116]\tvalidation_0-error:0.395073\tvalidation_1-error:0.397903\tvalidation_0-gini:0.69999\tvalidation_1-gini:0.713644\n",
      "[117]\tvalidation_0-error:0.395073\tvalidation_1-error:0.397903\tvalidation_0-gini:0.69999\tvalidation_1-gini:0.713644\n",
      "[118]\tvalidation_0-error:0.394843\tvalidation_1-error:0.397903\tvalidation_0-gini:0.69999\tvalidation_1-gini:0.713644\n",
      "[119]\tvalidation_0-error:0.394699\tvalidation_1-error:0.397442\tvalidation_0-gini:0.699862\tvalidation_1-gini:0.713532\n",
      "[120]\tvalidation_0-error:0.394584\tvalidation_1-error:0.396981\tvalidation_0-gini:0.699671\tvalidation_1-gini:0.713446\n",
      "[121]\tvalidation_0-error:0.394612\tvalidation_1-error:0.396866\tvalidation_0-gini:0.699671\tvalidation_1-gini:0.713445\n",
      "[122]\tvalidation_0-error:0.394612\tvalidation_1-error:0.39675\tvalidation_0-gini:0.699671\tvalidation_1-gini:0.713445\n",
      "[123]\tvalidation_0-error:0.394612\tvalidation_1-error:0.396866\tvalidation_0-gini:0.699671\tvalidation_1-gini:0.713446\n",
      "[124]\tvalidation_0-error:0.394555\tvalidation_1-error:0.39675\tvalidation_0-gini:0.699671\tvalidation_1-gini:0.713446\n",
      "[125]\tvalidation_0-error:0.39467\tvalidation_1-error:0.396866\tvalidation_0-gini:0.699671\tvalidation_1-gini:0.713446\n",
      "[126]\tvalidation_0-error:0.394612\tvalidation_1-error:0.397211\tvalidation_0-gini:0.699537\tvalidation_1-gini:0.713566\n",
      "[127]\tvalidation_0-error:0.394699\tvalidation_1-error:0.397096\tvalidation_0-gini:0.699537\tvalidation_1-gini:0.713566\n",
      "[128]\tvalidation_0-error:0.39467\tvalidation_1-error:0.396981\tvalidation_0-gini:0.699537\tvalidation_1-gini:0.713566\n",
      "[129]\tvalidation_0-error:0.39467\tvalidation_1-error:0.396981\tvalidation_0-gini:0.699537\tvalidation_1-gini:0.713566\n",
      "[130]\tvalidation_0-error:0.394353\tvalidation_1-error:0.397327\tvalidation_0-gini:0.699114\tvalidation_1-gini:0.713572\n",
      "[131]\tvalidation_0-error:0.394324\tvalidation_1-error:0.397211\tvalidation_0-gini:0.699114\tvalidation_1-gini:0.713572\n",
      "[132]\tvalidation_0-error:0.394411\tvalidation_1-error:0.397327\tvalidation_0-gini:0.699114\tvalidation_1-gini:0.713572\n",
      "[133]\tvalidation_0-error:0.393777\tvalidation_1-error:0.397903\tvalidation_0-gini:0.698668\tvalidation_1-gini:0.713375\n",
      "[134]\tvalidation_0-error:0.39395\tvalidation_1-error:0.397903\tvalidation_0-gini:0.698668\tvalidation_1-gini:0.713374\n",
      "[135]\tvalidation_0-error:0.39395\tvalidation_1-error:0.397903\tvalidation_0-gini:0.698668\tvalidation_1-gini:0.713374\n",
      "[136]\tvalidation_0-error:0.393777\tvalidation_1-error:0.397903\tvalidation_0-gini:0.698668\tvalidation_1-gini:0.713374\n",
      "[137]\tvalidation_0-error:0.393748\tvalidation_1-error:0.397903\tvalidation_0-gini:0.698668\tvalidation_1-gini:0.713374\n",
      "[138]\tvalidation_0-error:0.394065\tvalidation_1-error:0.397788\tvalidation_0-gini:0.698606\tvalidation_1-gini:0.713279\n",
      "[139]\tvalidation_0-error:0.394036\tvalidation_1-error:0.398018\tvalidation_0-gini:0.698606\tvalidation_1-gini:0.713279\n",
      "[140]\tvalidation_0-error:0.394123\tvalidation_1-error:0.397672\tvalidation_0-gini:0.698606\tvalidation_1-gini:0.713279\n",
      "[141]\tvalidation_0-error:0.394123\tvalidation_1-error:0.397672\tvalidation_0-gini:0.698606\tvalidation_1-gini:0.713279\n",
      "[142]\tvalidation_0-error:0.394065\tvalidation_1-error:0.397557\tvalidation_0-gini:0.698606\tvalidation_1-gini:0.713279\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[143]\tvalidation_0-error:0.394008\tvalidation_1-error:0.397788\tvalidation_0-gini:0.698606\tvalidation_1-gini:0.713279\n",
      "[144]\tvalidation_0-error:0.394036\tvalidation_1-error:0.397672\tvalidation_0-gini:0.698606\tvalidation_1-gini:0.713279\n",
      "[145]\tvalidation_0-error:0.394008\tvalidation_1-error:0.398018\tvalidation_0-gini:0.698449\tvalidation_1-gini:0.713019\n",
      "[146]\tvalidation_0-error:0.394008\tvalidation_1-error:0.398018\tvalidation_0-gini:0.698449\tvalidation_1-gini:0.713019\n",
      "[147]\tvalidation_0-error:0.394008\tvalidation_1-error:0.398018\tvalidation_0-gini:0.698448\tvalidation_1-gini:0.713019\n",
      "[148]\tvalidation_0-error:0.393921\tvalidation_1-error:0.397788\tvalidation_0-gini:0.698459\tvalidation_1-gini:0.713183\n",
      "[149]\tvalidation_0-error:0.393748\tvalidation_1-error:0.397903\tvalidation_0-gini:0.698352\tvalidation_1-gini:0.713064\n",
      "[150]\tvalidation_0-error:0.393863\tvalidation_1-error:0.398248\tvalidation_0-gini:0.698352\tvalidation_1-gini:0.713064\n",
      "[151]\tvalidation_0-error:0.394036\tvalidation_1-error:0.397788\tvalidation_0-gini:0.698047\tvalidation_1-gini:0.71277\n",
      "[152]\tvalidation_0-error:0.394036\tvalidation_1-error:0.397788\tvalidation_0-gini:0.698047\tvalidation_1-gini:0.71277\n",
      "[153]\tvalidation_0-error:0.393172\tvalidation_1-error:0.398133\tvalidation_0-gini:0.697906\tvalidation_1-gini:0.71255\n",
      "[154]\tvalidation_0-error:0.393086\tvalidation_1-error:0.398133\tvalidation_0-gini:0.697906\tvalidation_1-gini:0.712551\n",
      "[155]\tvalidation_0-error:0.393258\tvalidation_1-error:0.398018\tvalidation_0-gini:0.697906\tvalidation_1-gini:0.712551\n",
      "[156]\tvalidation_0-error:0.393201\tvalidation_1-error:0.398133\tvalidation_0-gini:0.697906\tvalidation_1-gini:0.712551\n",
      "[157]\tvalidation_0-error:0.393258\tvalidation_1-error:0.398018\tvalidation_0-gini:0.697906\tvalidation_1-gini:0.71255\n",
      "[158]\tvalidation_0-error:0.393114\tvalidation_1-error:0.398133\tvalidation_0-gini:0.697906\tvalidation_1-gini:0.712551\n",
      "[159]\tvalidation_0-error:0.393201\tvalidation_1-error:0.398133\tvalidation_0-gini:0.697906\tvalidation_1-gini:0.712551\n",
      "[160]\tvalidation_0-error:0.393316\tvalidation_1-error:0.397903\tvalidation_0-gini:0.697906\tvalidation_1-gini:0.712551\n",
      "[161]\tvalidation_0-error:0.393287\tvalidation_1-error:0.398133\tvalidation_0-gini:0.697906\tvalidation_1-gini:0.71255\n",
      "[162]\tvalidation_0-error:0.393172\tvalidation_1-error:0.398018\tvalidation_0-gini:0.697906\tvalidation_1-gini:0.712551\n",
      "[163]\tvalidation_0-error:0.393172\tvalidation_1-error:0.398018\tvalidation_0-gini:0.697906\tvalidation_1-gini:0.712551\n",
      "[164]\tvalidation_0-error:0.393201\tvalidation_1-error:0.398018\tvalidation_0-gini:0.697906\tvalidation_1-gini:0.712551\n",
      "[165]\tvalidation_0-error:0.39323\tvalidation_1-error:0.397903\tvalidation_0-gini:0.697838\tvalidation_1-gini:0.712541\n",
      "[166]\tvalidation_0-error:0.393143\tvalidation_1-error:0.398018\tvalidation_0-gini:0.697838\tvalidation_1-gini:0.712542\n",
      "[167]\tvalidation_0-error:0.393114\tvalidation_1-error:0.398018\tvalidation_0-gini:0.697838\tvalidation_1-gini:0.712542\n",
      "[168]\tvalidation_0-error:0.393201\tvalidation_1-error:0.397903\tvalidation_0-gini:0.697838\tvalidation_1-gini:0.712542\n",
      "[169]\tvalidation_0-error:0.393258\tvalidation_1-error:0.398133\tvalidation_0-gini:0.697695\tvalidation_1-gini:0.712295\n",
      "[170]\tvalidation_0-error:0.393143\tvalidation_1-error:0.397557\tvalidation_0-gini:0.697568\tvalidation_1-gini:0.712198\n",
      "[171]\tvalidation_0-error:0.392884\tvalidation_1-error:0.396635\tvalidation_0-gini:0.697341\tvalidation_1-gini:0.711913\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "       colsample_bynode=1, colsample_bytree=0.8, gamma=10,\n",
       "       learning_rate=0.07, max_delta_step=0, max_depth=4,\n",
       "       min_child_weight=6, missing=None, n_estimators=172, n_jobs=1,\n",
       "       nthread=None, objective='binary:logistic', random_state=123,\n",
       "       reg_alpha=8, reg_lambda=1.3, scale_pos_weight=1, seed=None,\n",
       "       silent=None, subsample=0.8, verbosity=1)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eval_set = [(X_train, y_train), (X_test, y_test)]\n",
    "xg_cl.fit(X_train, y_train, early_stopping_rounds=50, eval_metric=gini_xgb, eval_set=eval_set, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = xg_cl.evals_result()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "\"fig, ax = plt.subplots()\\nax.plot(x_axis, results['validation_0']['error'], label='Train')\\nax.plot(x_axis, results['validation_1']['error'], label='Test')\\nax.legend()\\nplt.ylabel('Classification Error')\\nplt.title('XGBoost Classification Error')\\nplt.show()\""
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "epochs = len(results['validation_0']['gini'])\n",
    "x_axis = range(0, epochs)\n",
    "# plot log loss\n",
    "fig, ax = plt.subplots()\n",
    "ax.plot(x_axis, results['validation_0']['gini'], label='Train')\n",
    "ax.plot(x_axis, results['validation_1']['gini'], label='Test')\n",
    "ax.legend()\n",
    "plt.ylabel('Normalized Gini')\n",
    "plt.title('XGBoost Gini')\n",
    "plt.show()\n",
    "# plot classification error\n",
    "'''fig, ax = plt.subplots()\n",
    "ax.plot(x_axis, results['validation_0']['error'], label='Train')\n",
    "ax.plot(x_axis, results['validation_1']['error'], label='Test')\n",
    "ax.legend()\n",
    "plt.ylabel('Classification Error')\n",
    "plt.title('XGBoost Classification Error')\n",
    "plt.show()'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_xg = xg_cl.predict(X_test_orig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_xg = xg_cl.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy_score:  0.9625513469922633\n",
      "confusion_matrix: \n",
      " [[114585      0]\n",
      " [  4458      0]]\n",
      "classification_report: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      1.00      0.98    114585\n",
      "           1       0.00      0.00      0.00      4458\n",
      "\n",
      "   micro avg       0.96      0.96      0.96    119043\n",
      "   macro avg       0.48      0.50      0.49    119043\n",
      "weighted avg       0.93      0.96      0.94    119043\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Supratik\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Supratik\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Supratik\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "print(\"accuracy_score: \", accuracy_score(y_test_orig, pred_xg))\n",
    "print(\"confusion_matrix: \\n\", confusion_matrix(y_test_orig, pred_xg))\n",
    "print(\"classification_report: \\n\", classification_report(y_test_orig, pred_xg))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy_score:  0.6033648306061304\n",
      "confusion_matrix: \n",
      " [[2671 1570]\n",
      " [1872 2565]]\n",
      "classification_report: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.59      0.63      0.61      4241\n",
      "           1       0.62      0.58      0.60      4437\n",
      "\n",
      "   micro avg       0.60      0.60      0.60      8678\n",
      "   macro avg       0.60      0.60      0.60      8678\n",
      "weighted avg       0.60      0.60      0.60      8678\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"accuracy_score: \", accuracy_score(y_test, pred_xg))\n",
    "print(\"confusion_matrix: \\n\", confusion_matrix(y_test, pred_xg))\n",
    "print(\"classification_report: \\n\", classification_report(y_test, pred_xg))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gini: 0.050, Max. Gini: 0.244, Normalized Gini: 0.203\n"
     ]
    }
   ],
   "source": [
    "gini_predictions = gini(y_test_orig, pred_xg)\n",
    "gini_max = gini(y_test_orig, y_test_orig)\n",
    "ngini= gini_normalized(y_test_orig, pred_xg)\n",
    "print('Gini: %.3f, Max. Gini: %.3f, Normalized Gini: %.3f' % (gini_predictions, gini_max, ngini))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gini: 0.052, Max. Gini: 0.244, Normalized Gini: 0.212\n"
     ]
    }
   ],
   "source": [
    "gini_predictions = gini(y_test, pred_xg)\n",
    "gini_max = gini(y_test, y_test)\n",
    "ngini= gini_normalized(y_test, pred_xg)\n",
    "print('Gini: %.3f, Max. Gini: %.3f, Normalized Gini: %.3f' % (gini_predictions, gini_max, ngini))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "XGB_pred_prob = list(map(lambda x: x[1],xg_cl.predict_proba(X_test_orig)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "XGB_pred_prob = list(map(lambda x: x[1],xg_cl.predict_proba(X_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gini: 0.069, Max. Gini: 0.244, Normalized Gini: 0.281\n"
     ]
    }
   ],
   "source": [
    "gini_predictions = gini(y_test_orig, XGB_pred_prob)\n",
    "gini_max = gini(y_test_orig, y_test_orig)\n",
    "ngini= gini_normalized(y_test_orig, XGB_pred_prob)\n",
    "print('Gini: %.3f, Max. Gini: %.3f, Normalized Gini: %.3f' % (gini_predictions, gini_max, ngini))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gini: 0.070, Max. Gini: 0.244, Normalized Gini: 0.288\n"
     ]
    }
   ],
   "source": [
    "gini_predictions = gini(y_test, XGB_pred_prob)\n",
    "gini_max = gini(y_test, y_test)\n",
    "ngini= gini_normalized(y_test, XGB_pred_prob)\n",
    "print('Gini: %.3f, Max. Gini: %.3f, Normalized Gini: %.3f' % (gini_predictions, gini_max, ngini))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(34710, 34)"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_orig.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_unscaled = test.drop(['id','ps_car_01_cat','ps_car_02_cat','ps_car_03_cat','ps_car_05_cat',\n",
    "                          'ps_car_07_cat','ps_car_09_cat','ps_car_11','ps_car_12','ps_car_14','ps_ind_02_cat',\n",
    "                          'ps_ind_04_cat','ps_ind_05_cat','ps_reg_03','ps_car_04_cat_enc', 'ps_car_06_cat_enc', 'ps_car_08_cat_enc',\n",
    "       'ps_car_10_cat_enc', 'ps_car_11_cat_enc', 'ps_car_01_cat_mod_enc',\n",
    "       'ps_car_02_cat_mod_enc', 'ps_car_07_cat_mod_enc',\n",
    "       'ps_car_09_cat_mod_enc', 'ps_ind_02_cat_mod_enc',\n",
    "       'ps_ind_04_cat_mod_enc', 'ps_ind_05_cat_mod_enc'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_unscaled = test_unscaled.drop(col_to_drop, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_pred = list(map(lambda x: x[1],xg_cl.predict_proba(test_unscaled)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_pred = list(map(lambda x: x[1],xg_cl.predict_proba(test_unscaled)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission = pd.concat([test['id'], pd.DataFrame({'target':test_pred})], axis=1)\n",
    "submission.to_csv('submission.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Light GBM Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install lightgbm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "import lightgbm as lgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Supratik\\Anaconda3\\lib\\site-packages\\lightgbm\\engine.py:118: UserWarning: Found `num_iterations` in params. Will use it instead of argument\n",
      "  warnings.warn(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n"
     ]
    }
   ],
   "source": [
    "lgb_params = {\n",
    "                'learning_rate': 0.02,\n",
    "                'num_iterations': 700,\n",
    "                'max_bin': 15,\n",
    "                'subsample': 0.8,\n",
    "                'subsample_freq': 10,\n",
    "                'colsample_bytree': 0.8,\n",
    "                'min_child_samples': 800,\n",
    "                'random_state': 123,\n",
    "                'scale_pos_weight':3\n",
    "             }\n",
    "\n",
    "model_lgb = lgb.train(lgb_params, lgb.Dataset(X_train_orig, label=y_train_orig), 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [],
   "source": [
    "lgb_params = {\n",
    "               'feature_fraction': 0.70, #0.50\n",
    "               'feature_fraction_seed':1000,\n",
    "               'metric': 'binary_logloss',\n",
    "               'nthread':-1, \n",
    "               'min_data_in_leaf': 2**4, \n",
    "               'bagging_fraction': 0.50, #0.50\n",
    "               'bagging_freq':1,\n",
    "               'learning_rate': 0.03, #0.03\n",
    "               'objective': 'binary', \n",
    "               'bagging_seed': 1000, \n",
    "               'num_leaves': 2**17,#2**15\n",
    "               'max_depth':2**10,\n",
    "               'verbose':1,\n",
    "               'random_state':123,\n",
    "               #'categorical_feature': '''name:ps_calc_15_bin,ps_calc_16_bin,ps_calc_17_bin,ps_calc_18_bin,\n",
    "                #                         ps_calc_19_bin,ps_calc_20_bin,ps_ind_02_cat_mod,ps_ind_04_cat_mod,\n",
    "                 #                        ps_ind_05_cat_mod,ps_ind_06_bin,ps_ind_07_bin,ps_ind_08_bin,ps_ind_09_bin,\n",
    "                 #                        ps_ind_10_bin,ps_ind_11_bin,ps_ind_12_bin,ps_ind_13_bin,ps_ind_16_bin,\n",
    "                  #                       ps_ind_17_bin,ps_ind_18_bin,ps_car_01_cat_mod,ps_car_02_cat_mod,\n",
    "                  #                       ps_car_04_cat,ps_car_06_cat,ps_car_07_cat_mod,ps_car_08_cat,\n",
    "                   #                      ps_car_09_cat_mod,ps_car_10_cat,ps_car_11_cat'''\n",
    "              }\n",
    "\n",
    "model_lgb = lgb.train(lgb_params, lgb.Dataset(X_train, label=y_train), 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test R-squared for LightGBM is 0.011037\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import r2_score\n",
    "pred_lgb = model_lgb.predict(X_test_orig)\n",
    "print('Test R-squared for LightGBM is %f' % r2_score(y_test_orig, pred_lgb))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test R-squared for LightGBM is 0.032001\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import r2_score\n",
    "pred_lgb = model_lgb.predict(X_test)\n",
    "print('Test R-squared for LightGBM is %f' % r2_score(y_test, pred_lgb))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.038880264928686174\n"
     ]
    }
   ],
   "source": [
    "fpr, tpr, thresholds =roc_curve(y_test_orig, pred_lgb)\n",
    "\n",
    "threshold=cutoff_youdens_j(fpr,tpr,thresholds)\n",
    "\n",
    "print(threshold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.47667327541317334\n"
     ]
    }
   ],
   "source": [
    "fpr, tpr, thresholds =roc_curve(y_test, pred_lgb)\n",
    "\n",
    "threshold=cutoff_youdens_j(fpr,tpr,thresholds)\n",
    "\n",
    "print(threshold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions_lgb = list(map(lambda x: 1 if x > threshold else 0,pred_lgb))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions_lgb = list(map(lambda x: 1 if x > threshold else 0,pred_lgb))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy_score:  0.6075132519013597\n",
      "confusion_matrix: \n",
      " [[2639 1602]\n",
      " [1804 2633]]\n",
      "classification_report: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.59      0.62      0.61      4241\n",
      "           1       0.62      0.59      0.61      4437\n",
      "\n",
      "   micro avg       0.61      0.61      0.61      8678\n",
      "   macro avg       0.61      0.61      0.61      8678\n",
      "weighted avg       0.61      0.61      0.61      8678\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"accuracy_score: \", accuracy_score(y_test_orig, predictions_lgb))\n",
    "print(\"confusion_matrix: \\n\", confusion_matrix(y_test_orig, predictions_lgb))\n",
    "print(\"classification_report: \\n\", classification_report(y_test_orig, predictions_lgb))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy_score:  0.5826227241299838\n",
      "confusion_matrix: \n",
      " [[2239 2002]\n",
      " [1620 2817]]\n",
      "classification_report: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.58      0.53      0.55      4241\n",
      "           1       0.58      0.63      0.61      4437\n",
      "\n",
      "   micro avg       0.58      0.58      0.58      8678\n",
      "   macro avg       0.58      0.58      0.58      8678\n",
      "weighted avg       0.58      0.58      0.58      8678\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"accuracy_score: \", accuracy_score(y_test, predictions_lgb))\n",
    "print(\"confusion_matrix: \\n\", confusion_matrix(y_test, predictions_lgb))\n",
    "print(\"classification_report: \\n\", classification_report(y_test, predictions_lgb))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gini: 0.054, Max. Gini: 0.244, Normalized Gini: 0.222\n"
     ]
    }
   ],
   "source": [
    "gini_predictions = gini(y_test_orig, predictions_lgb)\n",
    "gini_max = gini(y_test_orig, y_test_orig)\n",
    "ngini= gini_normalized(y_test_orig, predictions_lgb)\n",
    "print('Gini: %.3f, Max. Gini: %.3f, Normalized Gini: %.3f' % (gini_predictions, gini_max, ngini))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gini: 0.041, Max. Gini: 0.244, Normalized Gini: 0.169\n"
     ]
    }
   ],
   "source": [
    "gini_predictions = gini(y_test, predictions_lgb)\n",
    "gini_max = gini(y_test, y_test)\n",
    "ngini= gini_normalized(y_test, predictions_lgb)\n",
    "print('Gini: %.3f, Max. Gini: %.3f, Normalized Gini: %.3f' % (gini_predictions, gini_max, ngini))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gini: 0.136, Max. Gini: 0.481, Normalized Gini: 0.282\n"
     ]
    }
   ],
   "source": [
    "gini_predictions = gini(y_test_orig, pred_lgb)\n",
    "gini_max = gini(y_test_orig, y_test_orig)\n",
    "ngini= gini_normalized(y_test_orig, pred_lgb)\n",
    "print('Gini: %.3f, Max. Gini: %.3f, Normalized Gini: %.3f' % (gini_predictions, gini_max, ngini))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gini: 0.054, Max. Gini: 0.244, Normalized Gini: 0.222\n"
     ]
    }
   ],
   "source": [
    "gini_predictions = gini(y_test, pred_lgb)\n",
    "gini_max = gini(y_test, y_test)\n",
    "ngini= gini_normalized(y_test, pred_lgb)\n",
    "print('Gini: %.3f, Max. Gini: %.3f, Normalized Gini: %.3f' % (gini_predictions, gini_max, ngini))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_pred = model_lgb.predict(test_unscaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission = pd.concat([test['id'], pd.DataFrame({'target':test_pred})], axis=1)\n",
    "submission.to_csv('submission.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# K Nearest Neighbors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 301,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Supratik\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\data.py:645: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by StandardScaler.\n",
      "  return self.partial_fit(X, y)\n",
      "C:\\Users\\Supratik\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:3: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by StandardScaler.\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n",
      "C:\\Users\\Supratik\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:4: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by StandardScaler.\n",
      "  after removing the cwd from sys.path.\n"
     ]
    }
   ],
   "source": [
    "'''scaler = StandardScaler()\n",
    "scaler.fit(X_train)\n",
    "scaled_X_train = scaler.transform(X_train)\n",
    "scaled_X_test = scaler.transform(X_test)'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''df_scaled_X_train = pd.DataFrame(scaled_X_train,columns=X_train.columns)\n",
    "df_scaled_X_test = pd.DataFrame(scaled_X_test,columns=X_test.columns)'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "errors = []\n",
    "for i in range(1,40):\n",
    "    KNN = KNeighborsClassifier(n_neighbors=i)\n",
    "    KNN.fit(X_train, y_train)\n",
    "    pred_i = KNN.predict(X_test)\n",
    "    errors.append(np.mean(np.abs(y_test - pred_i)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0, 0.5, 'Error Rate')"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(10,6))\n",
    "plt.plot(range(1,40),errors,color='blue', linestyle='dashed', marker='o',\n",
    "     markerfacecolor='red', markersize=10)\n",
    "plt.title('Error Rate vs. K Value')\n",
    "plt.xlabel('K')\n",
    "plt.ylabel('Error Rate')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 302,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn = KNeighborsClassifier(n_neighbors=37) # NOW WITH K=30\n",
    "\n",
    "knn.fit(X_train,y_train)\n",
    "pred_KNN = knn.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 303,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WITH K=37\n",
      "\n",
      "\n",
      "0.5472459091956672\n",
      "\n",
      "\n",
      "[[2550 1691]\n",
      " [2238 2199]]\n",
      "\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.53      0.60      0.56      4241\n",
      "           1       0.57      0.50      0.53      4437\n",
      "\n",
      "   micro avg       0.55      0.55      0.55      8678\n",
      "   macro avg       0.55      0.55      0.55      8678\n",
      "weighted avg       0.55      0.55      0.55      8678\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "\n",
    "print('WITH K=37')\n",
    "print('\\n')\n",
    "print(accuracy_score(y_test,pred_KNN))\n",
    "print('\\n')\n",
    "print(confusion_matrix(y_test,pred_KNN))\n",
    "print('\\n')\n",
    "print(classification_report(y_test,pred_KNN))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 304,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gini: 0.026, Max. Gini: 0.244, Normalized Gini: 0.105\n"
     ]
    }
   ],
   "source": [
    "gini_predictions = gini(y_test, pred_KNN)\n",
    "gini_max = gini(y_test, y_test)\n",
    "ngini= gini_normalized(y_test, pred_KNN)\n",
    "print('Gini: %.3f, Max. Gini: %.3f, Normalized Gini: %.3f' % (gini_predictions, gini_max, ngini))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 305,
   "metadata": {},
   "outputs": [],
   "source": [
    "KNN_pred_prob = list(map(lambda x: x[1],knn.predict_proba(X_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 306,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gini: 0.033, Max. Gini: 0.244, Normalized Gini: 0.136\n"
     ]
    }
   ],
   "source": [
    "gini_predictions = gini(y_test, KNN_pred_prob)\n",
    "gini_max = gini(y_test, y_test)\n",
    "ngini= gini_normalized(y_test, KNN_pred_prob)\n",
    "print('Gini: %.3f, Max. Gini: %.3f, Normalized Gini: %.3f' % (gini_predictions, gini_max, ngini))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_pred = knn.predict_proba(test.drop(['id','ps_car_01_cat','ps_car_02_cat','ps_car_03_cat','ps_car_05_cat',\n",
    "                          'ps_car_07_cat','ps_car_09_cat','ps_car_11','ps_car_12','ps_car_14','ps_ind_02_cat',\n",
    "                          'ps_ind_04_cat','ps_ind_05_cat','ps_reg_03'], axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "KNN_pred_prob = list(map(lambda x: x[1],test_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission = pd.concat([test['id'], pd.DataFrame({'target':KNN_pred_prob})], axis=1)\n",
    "submission.to_csv('submission.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SVM Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 307,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 308,
   "metadata": {},
   "outputs": [],
   "source": [
    "SVC_Mod = SVC(C=2, gamma = 0.1, kernel='rbf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 309,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(C=2, cache_size=200, class_weight=None, coef0=0.0,\n",
       "  decision_function_shape='ovr', degree=3, gamma=0.1, kernel='rbf',\n",
       "  max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
       "  tol=0.001, verbose=False)"
      ]
     },
     "execution_count": 309,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "SVC_Mod.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 310,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_SVM = SVC_Mod.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 311,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5419451486517631\n",
      "\n",
      "\n",
      "[[2266 1975]\n",
      " [2000 2437]]\n",
      "\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.53      0.53      0.53      4241\n",
      "           1       0.55      0.55      0.55      4437\n",
      "\n",
      "   micro avg       0.54      0.54      0.54      8678\n",
      "   macro avg       0.54      0.54      0.54      8678\n",
      "weighted avg       0.54      0.54      0.54      8678\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(accuracy_score(y_test,pred_SVM))\n",
    "print('\\n')\n",
    "print(confusion_matrix(y_test,pred_SVM))\n",
    "print('\\n')\n",
    "print(classification_report(y_test,pred_SVM))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 312,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gini: 0.022, Max. Gini: 0.244, Normalized Gini: 0.091\n"
     ]
    }
   ],
   "source": [
    "gini_predictions = gini(y_test, pred_SVM)\n",
    "gini_max = gini(y_test, y_test)\n",
    "ngini= gini_normalized(y_test, pred_SVM)\n",
    "print('Gini: %.3f, Max. Gini: %.3f, Normalized Gini: %.3f' % (gini_predictions, gini_max, ngini))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''SVC_pred_prob = list(map(lambda x: x[1],SVC_Mod.predict_proba(X_test)))'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''gini_predictions = gini(y_test, SVC_pred_prob)\n",
    "gini_max = gini(y_test, y_test)\n",
    "ngini= gini_normalized(y_test, SVC_pred_prob)\n",
    "print('Gini: %.3f, Max. Gini: %.3f, Normalized Gini: %.3f' % (gini_predictions, gini_max, ngini))'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SVM using Grid Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = {'C' : [0.1,0.5,1,2,5], 'gamma' : [0.1, 0.01, 0.001, 1], 'kernel' : ['rbf','poly']}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "Grid = GridSearchCV(SVC(),param_grid, cv=5, refit=True, verbose=3, n_jobs=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 40 candidates, totalling 200 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n"
     ]
    }
   ],
   "source": [
    "Grid.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(Grid.best_params_)\n",
    "print(Grid.best_estimator_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_grid = Grid.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(accuracy_score(y_test,pred_grid))\n",
    "print('\\n')\n",
    "print(confusion_matrix(y_test,pred_grid))\n",
    "print('\\n')\n",
    "print(classification_report(y_test,pred_grid))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using tensorflow estimator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [],
   "source": [
    "feat_cols = []\n",
    "for col in X_train_orig.columns:\n",
    "    feat_cols.append(tf.feature_column.numeric_column(col))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_func = tf.estimator.inputs.pandas_input_fn(x=X_train_orig,y=y_train_orig,\n",
    "                                                 batch_size=1000,num_epochs=5, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using default config.\n",
      "WARNING:tensorflow:Using temporary folder as model directory: C:\\Users\\Supratik\\AppData\\Local\\Temp\\tmp1kwqos24\n",
      "INFO:tensorflow:Using config: {'_model_dir': 'C:\\\\Users\\\\Supratik\\\\AppData\\\\Local\\\\Temp\\\\tmp1kwqos24', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': allow_soft_placement: true\n",
      "graph_options {\n",
      "  rewrite_options {\n",
      "    meta_optimizer_iterations: ONE\n",
      "  }\n",
      "}\n",
      ", '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x000002A41B42C9E8>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}\n"
     ]
    }
   ],
   "source": [
    "classifier = tf.estimator.DNNClassifier(hidden_units=[54, 27, 10, 1], n_classes=2,feature_columns=feat_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Saving checkpoints for 0 into C:\\Users\\Supratik\\AppData\\Local\\Temp\\tmp1kwqos24\\model.ckpt.\n",
      "INFO:tensorflow:loss = 695.0956, step = 1\n",
      "INFO:tensorflow:Saving checkpoints for 50 into C:\\Users\\Supratik\\AppData\\Local\\Temp\\tmp1kwqos24\\model.ckpt.\n",
      "INFO:tensorflow:Loss for final step: 693.6463.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow_estimator.python.estimator.canned.dnn.DNNClassifier at 0x2a41b42c438>"
      ]
     },
     "execution_count": 261,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier.train(input_fn=input_func,steps=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from C:\\Users\\Supratik\\AppData\\Local\\Temp\\tmp1kwqos24\\model.ckpt-50\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n"
     ]
    }
   ],
   "source": [
    "pred_fn = tf.estimator.inputs.pandas_input_fn(x=X_test_orig,batch_size=len(X_test_orig),shuffle=False)\n",
    "note_predictions = list(classifier.predict(input_fn=pred_fn))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_preds  = []\n",
    "for pred in note_predictions:\n",
    "    final_preds.append(pred['class_ids'][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, classification_report,confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.48870707536298685\n",
      "\n",
      "\n",
      "[[4241    0]\n",
      " [4437    0]]\n",
      "\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.49      1.00      0.66      4241\n",
      "           1       0.00      0.00      0.00      4437\n",
      "\n",
      "   micro avg       0.49      0.49      0.49      8678\n",
      "   macro avg       0.24      0.50      0.33      8678\n",
      "weighted avg       0.24      0.49      0.32      8678\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Supratik\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Supratik\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Supratik\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "print(accuracy_score(y_test_orig,final_preds))\n",
    "print('\\n')\n",
    "print(confusion_matrix(y_test_orig,final_preds))\n",
    "print('\\n')\n",
    "print(classification_report(y_test_orig,final_preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gini: 0.003, Max. Gini: 0.244, Normalized Gini: 0.014\n"
     ]
    }
   ],
   "source": [
    "# Gini with predicted probabilities\n",
    "gini_predictions = gini(y_test_orig, final_preds)\n",
    "gini_max = gini(y_test_orig, y_test_orig)\n",
    "ngini= gini_normalized(y_test_orig, final_preds)\n",
    "print('Gini: %.3f, Max. Gini: %.3f, Normalized Gini: %.3f' % (gini_predictions, gini_max, ngini))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Keras Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: keras in c:\\users\\supratik\\anaconda3\\lib\\site-packages (2.2.4)\n",
      "Requirement already satisfied: pyyaml in c:\\users\\supratik\\anaconda3\\lib\\site-packages (from keras) (5.1)\n",
      "Requirement already satisfied: keras-preprocessing>=1.0.5 in c:\\users\\supratik\\anaconda3\\lib\\site-packages (from keras) (1.1.0)\n",
      "Requirement already satisfied: keras-applications>=1.0.6 in c:\\users\\supratik\\anaconda3\\lib\\site-packages (from keras) (1.0.8)\n",
      "Requirement already satisfied: six>=1.9.0 in c:\\users\\supratik\\anaconda3\\lib\\site-packages (from keras) (1.12.0)\n",
      "Requirement already satisfied: scipy>=0.14 in c:\\users\\supratik\\anaconda3\\lib\\site-packages (from keras) (1.2.1)\n",
      "Requirement already satisfied: numpy>=1.9.1 in c:\\users\\supratik\\anaconda3\\lib\\site-packages (from keras) (1.16.2)\n",
      "Requirement already satisfied: h5py in c:\\users\\supratik\\anaconda3\\lib\\site-packages (from keras) (2.9.0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "!pip install keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers.core import Dense\n",
    "from keras.wrappers.scikit_learn import KerasClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create model\n",
    "from keras.optimizers import Adam\n",
    "model = Sequential()\n",
    "model.add(Dense(71, input_dim=X_train.shape[1], kernel_initializer='normal', activation='relu'))\n",
    "model.add(Dense(10, kernel_initializer='normal', activation='relu'))\n",
    "model.add(Dense(1, kernel_initializer='normal'))\n",
    "# Compile model\n",
    "model.compile(loss='mean_squared_error', optimizer='adam')\n",
    "seed = 7\n",
    "np.random.seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\Supratik\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "Epoch 1/100\n",
      "34710/34710 [==============================] - 1s 17us/step - loss: 0.2797\n",
      "Epoch 2/100\n",
      "34710/34710 [==============================] - 0s 11us/step - loss: 0.2407\n",
      "Epoch 3/100\n",
      "34710/34710 [==============================] - 0s 10us/step - loss: 0.2405\n",
      "Epoch 4/100\n",
      "34710/34710 [==============================] - 0s 9us/step - loss: 0.2402\n",
      "Epoch 5/100\n",
      "34710/34710 [==============================] - 0s 9us/step - loss: 0.2397\n",
      "Epoch 6/100\n",
      "34710/34710 [==============================] - 0s 9us/step - loss: 0.2392\n",
      "Epoch 7/100\n",
      "34710/34710 [==============================] - ETA: 0s - loss: 0.238 - 0s 9us/step - loss: 0.2386\n",
      "Epoch 8/100\n",
      "34710/34710 [==============================] - 0s 12us/step - loss: 0.2380\n",
      "Epoch 9/100\n",
      "34710/34710 [==============================] - 0s 14us/step - loss: 0.2373\n",
      "Epoch 10/100\n",
      "34710/34710 [==============================] - 0s 10us/step - loss: 0.2367\n",
      "Epoch 11/100\n",
      "34710/34710 [==============================] - 0s 11us/step - loss: 0.2362\n",
      "Epoch 12/100\n",
      "34710/34710 [==============================] - 0s 12us/step - loss: 0.2355\n",
      "Epoch 13/100\n",
      "34710/34710 [==============================] - 0s 13us/step - loss: 0.2351\n",
      "Epoch 14/100\n",
      "34710/34710 [==============================] - 0s 11us/step - loss: 0.2345\n",
      "Epoch 15/100\n",
      "34710/34710 [==============================] - 0s 11us/step - loss: 0.2339\n",
      "Epoch 16/100\n",
      "34710/34710 [==============================] - 0s 10us/step - loss: 0.2335\n",
      "Epoch 17/100\n",
      "34710/34710 [==============================] - 0s 10us/step - loss: 0.2332\n",
      "Epoch 18/100\n",
      "34710/34710 [==============================] - 0s 9us/step - loss: 0.2327\n",
      "Epoch 19/100\n",
      "34710/34710 [==============================] - 0s 9us/step - loss: 0.2324\n",
      "Epoch 20/100\n",
      "34710/34710 [==============================] - 0s 9us/step - loss: 0.2318\n",
      "Epoch 21/100\n",
      "34710/34710 [==============================] - 0s 9us/step - loss: 0.2318\n",
      "Epoch 22/100\n",
      "34710/34710 [==============================] - 0s 9us/step - loss: 0.2310\n",
      "Epoch 23/100\n",
      "34710/34710 [==============================] - 0s 9us/step - loss: 0.2306\n",
      "Epoch 24/100\n",
      "34710/34710 [==============================] - 0s 9us/step - loss: 0.2304\n",
      "Epoch 25/100\n",
      "34710/34710 [==============================] - 0s 9us/step - loss: 0.2300\n",
      "Epoch 26/100\n",
      "34710/34710 [==============================] - 1s 25us/step - loss: 0.2294\n",
      "Epoch 27/100\n",
      "34710/34710 [==============================] - 0s 9us/step - loss: 0.2290\n",
      "Epoch 28/100\n",
      "34710/34710 [==============================] - 1s 16us/step - loss: 0.2290\n",
      "Epoch 29/100\n",
      "34710/34710 [==============================] - 0s 11us/step - loss: 0.2287\n",
      "Epoch 30/100\n",
      "34710/34710 [==============================] - 0s 10us/step - loss: 0.2283\n",
      "Epoch 31/100\n",
      "34710/34710 [==============================] - 0s 12us/step - loss: 0.2278\n",
      "Epoch 32/100\n",
      "34710/34710 [==============================] - 0s 12us/step - loss: 0.2281\n",
      "Epoch 33/100\n",
      "34710/34710 [==============================] - 0s 10us/step - loss: 0.2273\n",
      "Epoch 34/100\n",
      "34710/34710 [==============================] - 0s 10us/step - loss: 0.2274\n",
      "Epoch 35/100\n",
      "34710/34710 [==============================] - 0s 9us/step - loss: 0.2267\n",
      "Epoch 36/100\n",
      "34710/34710 [==============================] - 0s 9us/step - loss: 0.2263\n",
      "Epoch 37/100\n",
      "34710/34710 [==============================] - 0s 10us/step - loss: 0.2262\n",
      "Epoch 38/100\n",
      "34710/34710 [==============================] - 0s 9us/step - loss: 0.2254\n",
      "Epoch 39/100\n",
      "34710/34710 [==============================] - 0s 9us/step - loss: 0.2253\n",
      "Epoch 40/100\n",
      "34710/34710 [==============================] - 0s 9us/step - loss: 0.2251\n",
      "Epoch 41/100\n",
      "34710/34710 [==============================] - 0s 9us/step - loss: 0.2245\n",
      "Epoch 42/100\n",
      "34710/34710 [==============================] - 0s 9us/step - loss: 0.2239\n",
      "Epoch 43/100\n",
      "34710/34710 [==============================] - 0s 9us/step - loss: 0.2239\n",
      "Epoch 44/100\n",
      "34710/34710 [==============================] - 0s 9us/step - loss: 0.2235\n",
      "Epoch 45/100\n",
      "34710/34710 [==============================] - 0s 11us/step - loss: 0.2228\n",
      "Epoch 46/100\n",
      "34710/34710 [==============================] - 0s 9us/step - loss: 0.2223\n",
      "Epoch 47/100\n",
      "34710/34710 [==============================] - 0s 9us/step - loss: 0.2218\n",
      "Epoch 48/100\n",
      "34710/34710 [==============================] - 0s 10us/step - loss: 0.2214\n",
      "Epoch 49/100\n",
      "34710/34710 [==============================] - 0s 9us/step - loss: 0.2211\n",
      "Epoch 50/100\n",
      "34710/34710 [==============================] - 0s 9us/step - loss: 0.2211\n",
      "Epoch 51/100\n",
      "34710/34710 [==============================] - 0s 9us/step - loss: 0.2206\n",
      "Epoch 52/100\n",
      "34710/34710 [==============================] - 0s 9us/step - loss: 0.2202\n",
      "Epoch 53/100\n",
      "34710/34710 [==============================] - 0s 9us/step - loss: 0.2193\n",
      "Epoch 54/100\n",
      "34710/34710 [==============================] - 0s 9us/step - loss: 0.2188\n",
      "Epoch 55/100\n",
      "34710/34710 [==============================] - 0s 10us/step - loss: 0.2184\n",
      "Epoch 56/100\n",
      "34710/34710 [==============================] - 0s 8us/step - loss: 0.2180\n",
      "Epoch 57/100\n",
      "34710/34710 [==============================] - 0s 11us/step - loss: 0.2179\n",
      "Epoch 58/100\n",
      "34710/34710 [==============================] - 0s 12us/step - loss: 0.2171\n",
      "Epoch 59/100\n",
      "34710/34710 [==============================] - 0s 13us/step - loss: 0.2166\n",
      "Epoch 60/100\n",
      "34710/34710 [==============================] - 0s 11us/step - loss: 0.2164\n",
      "Epoch 61/100\n",
      "34710/34710 [==============================] - 0s 10us/step - loss: 0.2159\n",
      "Epoch 62/100\n",
      "34710/34710 [==============================] - 0s 9us/step - loss: 0.2161\n",
      "Epoch 63/100\n",
      "34710/34710 [==============================] - 0s 8us/step - loss: 0.2158\n",
      "Epoch 64/100\n",
      "34710/34710 [==============================] - 0s 9us/step - loss: 0.2151\n",
      "Epoch 65/100\n",
      "34710/34710 [==============================] - 0s 9us/step - loss: 0.2148\n",
      "Epoch 66/100\n",
      "34710/34710 [==============================] - 0s 9us/step - loss: 0.2148\n",
      "Epoch 67/100\n",
      "34710/34710 [==============================] - 0s 9us/step - loss: 0.2142\n",
      "Epoch 68/100\n",
      "34710/34710 [==============================] - 0s 9us/step - loss: 0.2134\n",
      "Epoch 69/100\n",
      "34710/34710 [==============================] - 0s 9us/step - loss: 0.2134\n",
      "Epoch 70/100\n",
      "34710/34710 [==============================] - 0s 9us/step - loss: 0.2134\n",
      "Epoch 71/100\n",
      "34710/34710 [==============================] - 0s 9us/step - loss: 0.2124\n",
      "Epoch 72/100\n",
      "34710/34710 [==============================] - 0s 9us/step - loss: 0.2126\n",
      "Epoch 73/100\n",
      "34710/34710 [==============================] - 0s 9us/step - loss: 0.2125\n",
      "Epoch 74/100\n",
      "34710/34710 [==============================] - 0s 9us/step - loss: 0.2119\n",
      "Epoch 75/100\n",
      "34710/34710 [==============================] - 0s 9us/step - loss: 0.2119\n",
      "Epoch 76/100\n",
      "34710/34710 [==============================] - 0s 9us/step - loss: 0.2113\n",
      "Epoch 77/100\n",
      "34710/34710 [==============================] - 0s 9us/step - loss: 0.2111\n",
      "Epoch 78/100\n",
      "34710/34710 [==============================] - 0s 9us/step - loss: 0.2109\n",
      "Epoch 79/100\n",
      "34710/34710 [==============================] - 0s 9us/step - loss: 0.2108\n",
      "Epoch 80/100\n",
      "34710/34710 [==============================] - 0s 9us/step - loss: 0.2104\n",
      "Epoch 81/100\n",
      "34710/34710 [==============================] - 0s 9us/step - loss: 0.2108\n",
      "Epoch 82/100\n",
      "34710/34710 [==============================] - 0s 9us/step - loss: 0.2102\n",
      "Epoch 83/100\n",
      "34710/34710 [==============================] - 0s 8us/step - loss: 0.2102\n",
      "Epoch 84/100\n",
      "34710/34710 [==============================] - 0s 9us/step - loss: 0.2099\n",
      "Epoch 85/100\n",
      "34710/34710 [==============================] - ETA: 0s - loss: 0.209 - 0s 9us/step - loss: 0.2097\n",
      "Epoch 86/100\n",
      "34710/34710 [==============================] - 0s 8us/step - loss: 0.2094\n",
      "Epoch 87/100\n",
      "34710/34710 [==============================] - 0s 9us/step - loss: 0.2090\n",
      "Epoch 88/100\n",
      "34710/34710 [==============================] - 0s 9us/step - loss: 0.2090\n",
      "Epoch 89/100\n",
      "34710/34710 [==============================] - 0s 9us/step - loss: 0.2087\n",
      "Epoch 90/100\n",
      "34710/34710 [==============================] - 0s 10us/step - loss: 0.2085\n",
      "Epoch 91/100\n",
      "34710/34710 [==============================] - 0s 10us/step - loss: 0.2084\n",
      "Epoch 92/100\n",
      "34710/34710 [==============================] - 0s 9us/step - loss: 0.2081\n",
      "Epoch 93/100\n",
      "34710/34710 [==============================] - 0s 9us/step - loss: 0.2081\n",
      "Epoch 94/100\n",
      "34710/34710 [==============================] - 0s 9us/step - loss: 0.2085\n",
      "Epoch 95/100\n",
      "34710/34710 [==============================] - 0s 9us/step - loss: 0.2074\n",
      "Epoch 96/100\n",
      "34710/34710 [==============================] - 0s 9us/step - loss: 0.2072\n",
      "Epoch 97/100\n",
      "34710/34710 [==============================] - 0s 9us/step - loss: 0.2071\n",
      "Epoch 98/100\n",
      "34710/34710 [==============================] - 0s 8us/step - loss: 0.2075\n",
      "Epoch 99/100\n",
      "34710/34710 [==============================] - 0s 8us/step - loss: 0.2068\n",
      "Epoch 100/100\n",
      "34710/34710 [==============================] - 0s 9us/step - loss: 0.2071\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x2a41b1b21d0>"
      ]
     },
     "execution_count": 244,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train, y_train, epochs=100, batch_size=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds_keras = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds_keras=preds_keras.flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gini: 0.035, Max. Gini: 0.244, Normalized Gini: 0.145\n"
     ]
    }
   ],
   "source": [
    "gini_predictions = gini(y_test, preds_keras)\n",
    "gini_max = gini(y_test, y_test)\n",
    "ngini= gini_normalized(y_test, preds_keras)\n",
    "print('Gini: %.3f, Max. Gini: %.3f, Normalized Gini: %.3f' % (gini_predictions, gini_max, ngini))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Naive Bayes Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {},
   "outputs": [],
   "source": [
    "nbayes_model = MultinomialNB().fit(X_train_orig, y_train_orig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = nbayes_model.predict(X_test_orig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 0, ..., 0, 0, 1], dtype=int64)"
      ]
     },
     "execution_count": 240,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gini: 0.029, Max. Gini: 0.244, Normalized Gini: 0.119\n"
     ]
    }
   ],
   "source": [
    "gini_predictions = gini(y_test, y_pred)\n",
    "gini_max = gini(y_test, y_test)\n",
    "ngini= gini_normalized(y_test, y_pred)\n",
    "print('Gini: %.3f, Max. Gini: %.3f, Normalized Gini: %.3f' % (gini_predictions, gini_max, ngini))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
